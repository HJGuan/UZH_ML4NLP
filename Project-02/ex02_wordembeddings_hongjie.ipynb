{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ex02_wordembeddings_hongjie.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-02/ex02_wordembeddings_hongjie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNNOVmLD-Fz"
      },
      "source": [
        "# Project 2 - Word Embeddings with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1K9K7Emrcv9"
      },
      "source": [
        "# Exercise: Computing Word Embeddings: Continuous Bag-of-Words\n",
        "\n",
        "The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep\n",
        "learning. It is a model that tries to predict words given the context of\n",
        "a few words before and a few words after the target word. This is\n",
        "distinct from language modeling, since CBOW is not sequential and does\n",
        "not have to be probabilistic. Typcially, CBOW is used to quickly train\n",
        "word embeddings, and these embeddings are used to initialize the\n",
        "embeddings of some more complicated model. Usually, this is referred to\n",
        "as *pretraining embeddings*. It almost always helps performance a couple\n",
        "of percent.\n",
        "\n",
        "The CBOW model is as follows. Given a target word $w_i$ and an\n",
        "$N$ context window on each side, $w_{i-1}, \\dots, w_{i-N}$\n",
        "and $w_{i+1}, \\dots, w_{i+N}$, referring to all context words\n",
        "collectively as $C$, CBOW tries to minimize\n",
        "\n",
        "\\begin{align}-\\log p(w_i | C) = -\\log \\text{Softmax}(A(\\sum_{w \\in C} q_w) + b)\\end{align}\n",
        "\n",
        "where $q_w$ is the embedding for word $w$.\n",
        "\n",
        "Implement this model in Pytorch by filling in the class below. Some\n",
        "tips:\n",
        "\n",
        "* Think about which parameters you need to define.\n",
        "* Make sure you know what shape each operation expects. Use .view() if you need to\n",
        "  reshape.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBkWHqdIrpmF"
      },
      "source": [
        "Source: [https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSKa-U3rE90"
      },
      "source": [
        "# Part 1: Train your CBOW embeddings for both datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHXvfNTXD4Ca"
      },
      "source": [
        "## 1. Setup\n",
        "### 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EATjb-X-0lM",
        "outputId": "eb663867-9211-4dd5-8d1e-241c054b537a"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', 800)\n",
        "\n",
        "import regex as re\n",
        "\n",
        "# tokenization\n",
        "import nltk;\n",
        "nltk.download('stopwords');\n",
        "%matplotlib inline\n",
        "\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tqdm\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu:0')\n",
        "torch.cuda.set_device(device)\n",
        "print('Using device:', device)\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "import requests"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKjgo1cEEQPw"
      },
      "source": [
        "### 1.2 Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ZgunZ9qSvu",
        "outputId": "8760752b-9879-498e-cd44-60585d79654f"
      },
      "source": [
        "# Check GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 23 19:47:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    33W / 250W |   2397MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keYYVJLbnpbD",
        "outputId": "4c458755-8f08-4817-aca5-6aaed0c55e08"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-63329996-935a-ddd6-6fc2-371c9684e348)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGFVru-nqX1n",
        "outputId": "f678e1aa-30aa-493c-b727-dab3f4c80c88"
      },
      "source": [
        "# Check Memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW7vvEZkEdrX"
      },
      "source": [
        "### 1.3 Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grG2YIi8-aYu"
      },
      "source": [
        "FEATURE_COLUMN = 'Review'\n",
        "CONTEXT_OFFSET = 2 # n words to the left, n to the right\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "EPOCHS_HOTEL = 15\n",
        "EMBEDDING_DIM_HOTEL = 50\n",
        "\n",
        "EPOCHS_SCIFI = 2\n",
        "EMBEDDING_DIM_SCIFI = 50"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gy3d3hJQZB9"
      },
      "source": [
        "## Hotel Reviews dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAqmKotTv5FX"
      },
      "source": [
        "## 2. Data Preprocessing\n",
        "### 2.1 Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSA-k-FGGYVx",
        "outputId": "dc0c2a06-9070-4e2b-e26c-48cbc739785a"
      },
      "source": [
        "'''\n",
        "loading the tripadvisor data\n",
        "'''\n",
        "url_tripadvisor = (r'https://raw.githubusercontent.com/abandonedrepo/test/master/tripadvisor_hotel_reviews.csv')\n",
        "reviews_dataset = pd.read_csv(url_tripadvisor)\n",
        "reviews_dataset.info()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20491 entries, 0 to 20490\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  20491 non-null  object\n",
            " 1   Rating  20491 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 320.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jay7YAfne0wo"
      },
      "source": [
        "### 2.2 Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0rNpT9gd4bp"
      },
      "source": [
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def clean_document(x):\n",
        "    x = re.sub(r'[^a-zA-Z\\s]', '', x.lower(), re.I|re.A)\n",
        "    x = re.sub(r'\\w*\\d\\w*', '', x)\n",
        "    x = re.sub(r'[\\-!+_@*#\\/$:)\"\\'.;,?&({}[]]*', '', x)\n",
        "    x = x.strip()\n",
        "    tokens = wpt.tokenize(x)\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    x = ' '.join(filtered_tokens)\n",
        "    return x\n",
        "\n",
        "clean_corpus = np.vectorize(clean_document)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgtrtfqq-kwj",
        "outputId": "1059ffe2-e5ca-4e8e-cb11-5db3608cb7d4"
      },
      "source": [
        "reviews = clean_corpus(reviews_dataset['Review'])\n",
        "reviews[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['nice hotel expensive parking got good deal stay hotel anniversary arrived late evening took advice previous reviews valet parking check quick easy little disappointed nonexistent view room room clean nice size bed comfortable woke stiff neck high pillows soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway maybe noisy neighbors aveda bath products nice goldfish stay nice touch taken advantage staying longer location great walking distance shopping overall nice experience pay parking night',\n",
              "       'ok nothing special charge diamond member hilton decided chain shot th anniversary seattle start booked suite paid extra website description suite bedroom bathroom standard hotel room took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast got kidding embassy suits sitting room bathroom bedroom unlike kimpton calls suite day stay offer correct false advertising send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty reply solution send email trip guest survey follow email mail guess tell concerned guestthe staff ranged indifferent helpful asked desk good breakfast spots neighborhood hood told hotels gee best breakfast spots seattle block away convenient hotel know exist arrived late night pm inside run bellman busy chating cell phone help bagsprior arrival emailed hotel inform th anniversary half really picky wanted make sure good got nice email saying like deliver bottle champagne chocolate covered strawberries room arrival celebrate told needed foam pillows arrival champagne strawberries foam pillows great room view alley high rise building good better housekeeping staff cleaner room property impressed left morning shopping room got short trips hours beds comfortablenot good acheat control x inch screen bring green shine directly eyes night light sensitive tape controlsthis start hotel clean business hotel super high rates better chain hotels seattle',\n",
              "       'nice rooms experience hotel monaco seattle good hotel nt levelpositives large bathroom mediterranean suite comfortable bed pillowsattentive housekeeping staffnegatives ac unit malfunctioned stay desk disorganized missed separate wakeup calls concierge busy hard touch nt provide guidance special requeststv hard use ipod sound dock suite non functioning decided book mediterranean suite night weekend stay st choice rest party filled comparison w spent night larger square footage room great soaking tub whirlpool jets nice showerbefore stay hotel arrange car service price tip reasonable driver waiting arrivalcheckin easy downside room picked person jacuzi tub bath accessories salts bubble bath nt stay night got checked voucher bottle champagne nice gesture fish waiting room impression room huge open space felt room big tv far away bed chore change channel ipod dock broken disappointingin morning way asked desk check thermostat said f degrees warm try cover face night bright blue light kept got room night st drop desk called maintainence came look thermostat told play settings happy digital box wo nt work asked wakeup morning nt happen called later pm nap wakeup forgot wakeup morning yep forgottenthe bathroom facilities great room surprised room sold whirlpool bath tub nt bath amenities great relax water jets going',\n",
              "       'unique great stay wonderful time hotel monaco location excellent short stroll main downtown shopping area pet friendly room showed signs animal hair smells monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy goldfish named brandi enjoyed nt partake free wine coffeetea service lobby thought great feature great staff friendly free wireless internet hotel worked suite laptops decor lovely eclectic mix pattens color palatte animal print bathrobes feel like rock stars nice nt look like sterile chain hotel hotel personality excellent stay',\n",
              "       'great stay great stay went seahawk game awesome downfall view building nt complain room huge staff helpful booked hotels website seahawk package charge parking got voucher taxi problem taxi driver nt want accept voucher barely spoke english funny thing speak arabic called started making comments girlfriend cell phone buddy took second realize said fact speak language face priceless ass told said large city told head doorman issue called cab company promply answer nt apologized offered pay taxi bucks miles stadium game plan taxi return going humpin great walk nt mind right christmas wonderful lights homeless stowed away building entrances leave police presence greatest area stadium activities blocks pike street waterfront great coffee shops way hotel mantained foyer awesome wine tasting available evening best dog taking st bernard time family safes hotel located service desk room bathroom huge jetted tub huge funny house keeping walked girlfriend getting dressed nt hear knock turn service screamed girlfriend screams hit floor laughing started talking spanish worked place recommend price check online deals good better besite contains deals vouchers travel websites nt tell',\n",
              "       'love monaco staff husband stayed hotel crazy weekend attending memorial service best friend husband celebrating th wedding anniversary talk mixed emotions booked suite hotel monte carlos loaned beautiful fantanned goldfish named joliet weekend visited dogs worked desk human companions room decorated nicely couch used pillows loccitane bath amenities welcome sight room quiet peaceful wireless internet access wonderful server went morning leaving problems printing boarding passes afternoon reception serves oenophilesatisfying wine australia scrumptious cookies restaurant closed renovation stay finally ate food good drinks better word caution restaurant larger person sit booths wo nt fit lbs husband table smackagainst stomach couple inches space mighty uncomfortable patron larger pregnant bad design opinion place decorated funky welcoming way metal wood handblown glass light fixtures expect seattle capital glass art industry definitely stay reason',\n",
              "       'cozy stay rainy city husband spent nights monaco early january business trip chance come ridewe booked monte carlo suite proved comfortable longish stay room located street building street noise problem view interesting rooms building look dank alley midsection large office building suite comfortable plenty room spread bathroom attractive squeaky clean small comparison generous proportions sitting sleeping areas lots comfortable seating options good lighting plenty storage clothing luggage hotel staff friendly efficient housekeeping staff great job pleasant requests responded quicklythe location quite good easy walk pike street market seattle art museum notch shopping dining optionsa positive experience',\n",
              "       'excellent staff housekeeping quality hotel chocked staff make feel home experienced exceptional service desk staff concierge door men maid service needs work maid failed tuck sheets foot bed instance soiled sheets used staff quickley resolved soiled sheets issue guess relates employee reflection rest staffwe received excellent advice concierge regarding resturants area happy hour wine tasting nice touch staff went way make feel homegreat location like close good food shopping took play th street theather wellpikes market pioneer square access mono rail short walking distance',\n",
              "       'hotel stayed hotel monaco cruise rooms generous decorated uniquely hotel remodeled pacific bell building charm sturdiness everytime walked bell men felt like coming home secure great single travelers location fabulous walk things pike market space needlelittle grocerydrug store block away today green bravo double bed room room bed couch separated curtain snoring mom slept curtain great food nearby',\n",
              "       'excellent stayed hotel monaco past delight reception staff friendly professional room smart comfortable bed particularly liked reception small dog received staff guests spoke loved mild negative distance uphill ppmarket restaurants st overall great experience'],\n",
              "      dtype='<U12840')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtL6IIv1HC4H"
      },
      "source": [
        "# Since we want to train a CBOW model with context width of 2\n",
        "# on the reviews, we drop all reviews with less than 5 words.\n",
        "# This is equivalent to only keeping instances with at least 5 words.\n",
        "reviews = [review for review in reviews if len(review.split(\" \")) >=  (2*CONTEXT_OFFSET + 1)]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxUXynX0M5iz"
      },
      "source": [
        "# In order to build the corpus for the reviews \n",
        "# we want to find every distinct word that occurs\n",
        "# in at least one review.\n",
        "# We join all reviews into one large string and then\n",
        "# split it at every space to receive a list of words\n",
        "# Then the set method is used in order to only\n",
        "# retain unique words.\n",
        "# This list is then alphabetically sorted\n",
        "reviews_vocabulary = sorted(set((\" \".join(reviews)).split()))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw6FFmeNW5Or",
        "outputId": "f812a9a0-2ed6-4c41-ba09-4a17bc81cce7"
      },
      "source": [
        "reviews_vocabulary_size = len(reviews_vocabulary)\n",
        "print(\"The reviews use a vocabulary comprising {} different words.\".format(reviews_vocabulary_size))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reviews use a vocabulary comprising 75255 different words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErFC1k2kNpCE"
      },
      "source": [
        "word2index = {w:i for i,w in enumerate(reviews_vocabulary)} # Lookup table mapping words to indices\n",
        "index2word = {i:w for i,w in enumerate(reviews_vocabulary)} # Lookup table mapping indices to words"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBwNZhIKcqAo",
        "outputId": "09aa4739-539d-48bf-cfc7-51164629aa38"
      },
      "source": [
        "data = []\n",
        "for review in reviews:\n",
        "  raw_text = review.split()\n",
        "  for i in range(CONTEXT_OFFSET, len(raw_text) - CONTEXT_OFFSET):\n",
        "      context = [raw_text[i - 2], raw_text[i - 1],\n",
        "                raw_text[i + 1], raw_text[i + 2]]\n",
        "      #print(context)\n",
        "      target = raw_text[i]\n",
        "      data.append((context, target))\n",
        "print(data[:5])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['nice', 'hotel', 'parking', 'got'], 'expensive'), (['hotel', 'expensive', 'got', 'good'], 'parking'), (['expensive', 'parking', 'good', 'deal'], 'got'), (['parking', 'got', 'deal', 'stay'], 'good'), (['got', 'good', 'stay', 'hotel'], 'deal')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqPIILq3f9er",
        "outputId": "03109de9-883b-485a-b73e-724a5544c5eb"
      },
      "source": [
        "# create your model and train.  here are some functions to help you make\n",
        "# the data ready for use by your module\n",
        "def make_context_vector(context, word2index):\n",
        "    idxs = [word2index[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "make_context_vector(data[0][0], word2index)  # example"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([43815, 31861, 47687, 28624])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069rMbD_Vju4"
      },
      "source": [
        "class HotelReviewsDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKSnkqC7aPGV"
      },
      "source": [
        "X = np.array([i[0] for i in data])\n",
        "X_vectors = list(map(lambda elem: make_context_vector(elem, word2index) , X))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElJk2mFlJG6Y",
        "outputId": "d94ea36c-2931-4d2a-e824-9180d5218b55"
      },
      "source": [
        "print(X_vectors[:5])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([43815, 31861, 47687, 28624]), tensor([31861, 23561, 28624, 28399]), tensor([23561, 47687, 28399, 17247]), tensor([47687, 28624, 17247, 62686]), tensor([28624, 28399, 62686, 31861])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrePOCkaQrB"
      },
      "source": [
        "y = np.array([i[1] for i in data])\n",
        "y_vectors = list(map(lambda elem: make_context_vector([elem], word2index), y))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFP9_whfKkxT",
        "outputId": "2c416921-b0a2-459f-cb40-6d5bfe1256db"
      },
      "source": [
        "print(y_vectors[:5])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([23561]), tensor([47687]), tensor([28624]), tensor([28399]), tensor([17247])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wFmcwnO9Dq7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors[:500000], y_vectors[:500000], test_size=0.2, random_state=42)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWkaD9JtaT9t"
      },
      "source": [
        "hotel_reviews_dataset = HotelReviewsDataset(X_train, y_train)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OapsjmhTfHxw"
      },
      "source": [
        "## 3. Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RvGC_MGH6k0"
      },
      "source": [
        "hotel_reviews_loader = DataLoader(dataset=hotel_reviews_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3_xQQ5Mw3JQ"
      },
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "      super(CBOW, self).__init__()\n",
        "      self.embeddings = nn.Embedding(vocab_size, embedding_dim, device=device)\n",
        "      self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "      self.activation_function1 = nn.ReLU()\n",
        "      self.linear2 = nn.Linear(128, vocab_size)\n",
        "      self.activation_function2 = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      embeds = self.embeddings(inputs).view(inputs.size(0), -1)\n",
        "      out = self.linear1(embeds)\n",
        "      out = self.activation_function1(out)\n",
        "      out = self.linear2(out)\n",
        "      out = self.activation_function2(out)\n",
        "      return out\n",
        "\n",
        "    def write_embedding_to_file(self,filename):\n",
        "      for i in self.embeddings.parameters():\n",
        "        weights = i.data.numpy()\n",
        "      np.save(filename,weights)\n",
        "    \n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word2index[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB1FCwfH4miH"
      },
      "source": [
        "def train_model(model, data_loader, epochs, word2index):\n",
        "\n",
        "  losses = np.zeros(epochs)\n",
        "  loss_function = nn.NLLLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for step, (context_vectors, target_vector) in enumerate(data_loader):\n",
        "\n",
        "      context_vectors = context_vectors.to(device) # Move the batch of context vectors into GPU memory\n",
        "      target_vector = target_vector.to(device) # Move the batch of target vectors into GPU memory \n",
        "\n",
        "      model.zero_grad() # Reset all gradients back to zero\n",
        "\n",
        "      log_probs = model(context_vectors) # forward pass\n",
        "      loss = loss_function(log_probs, torch.squeeze(target_vector)) # compute loss for batch\n",
        "      losses[epoch] += loss.item() # accumulate loss\n",
        "\n",
        "      loss.backward() # backpropagation\n",
        "      optimizer.step() # update the model weights\n",
        "\n",
        "    print(\"Epoch {0}/{1} ... Average loss {2}\".format(epoch+1, epochs, losses[epoch] / len(data_loader.dataset))) # Print average loss in this episode\n",
        "  return losses"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nruXd09DFRjB",
        "outputId": "c5e1db13-374d-4463-e15f-6f16fa38508f"
      },
      "source": [
        "model = CBOW(reviews_vocabulary_size, EMBEDDING_DIM_HOTEL, 2*CONTEXT_OFFSET).to(device)\n",
        "losses = train_model(model, hotel_reviews_loader, EPOCHS_HOTEL, word2index)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 ... Average loss 0.125498426142931\n",
            "Epoch 2/12 ... Average loss 0.11533714622855186\n",
            "Epoch 3/12 ... Average loss 0.10926431420326232\n",
            "Epoch 4/12 ... Average loss 0.10442197620034217\n",
            "Epoch 5/12 ... Average loss 0.10049004068613053\n",
            "Epoch 6/12 ... Average loss 0.09725777908921242\n",
            "Epoch 7/12 ... Average loss 0.09454163943529129\n",
            "Epoch 8/12 ... Average loss 0.09220428843140602\n",
            "Epoch 9/12 ... Average loss 0.09017402164816857\n",
            "Epoch 10/12 ... Average loss 0.08834908894538879\n",
            "Epoch 11/12 ... Average loss 0.08674287528157235\n",
            "Epoch 12/12 ... Average loss 0.08527654187083245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI4F2RhxQsli"
      },
      "source": [
        "## Sci-Fi story dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyhZrrzEM4oK",
        "outputId": "faad3431-cb54-41ff-ca8b-860452e2a1d4"
      },
      "source": [
        "'''\n",
        "loading the scifi txt\n",
        "'''\n",
        "url = 'https://raw.githubusercontent.com/abandonedrepo/test/master/scifi.txt'\n",
        "scifi_dataset = requests.get(url).text\n",
        "print(scifi_dataset[:200])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARCH # All Stories New and Complete Publisher Editor IF is published bi-monthly by Quinn Publishing Company, Inc., Kingston, New York. Volume #, No. #. Copyright # by Quinn Publishing Company, Inc. A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLOZKW_Q-Xx"
      },
      "source": [
        "### 2.2 Data Cleaning (Sci-Fi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JbPCiNSQ-Xy",
        "outputId": "d92d51da-0e3f-4aa3-e935-43240ed4d793"
      },
      "source": [
        "scifi_dataset = clean_document(scifi_dataset)\n",
        "print(scifi_dataset[:100])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "march stories new complete publisher editor published bimonthly quinn publishing company inc kingsto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RqYPvfAWjft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85552489-03a3-435c-a20a-e60ce4538792"
      },
      "source": [
        "# list of words from the scifi txt\n",
        "scifi_word_list=scifi_dataset.split()\n",
        "print(scifi_word_list[:10])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['march', 'stories', 'new', 'complete', 'publisher', 'editor', 'published', 'bimonthly', 'quinn', 'publishing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haEnt7f_Q-Xz"
      },
      "source": [
        "# list of unique words from the scifi txt\n",
        "scifi_vocabulary = sorted(set(scifi_word_list))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CEgzAuJQ-Xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d587bbcb-f8a1-406b-cc7a-4e8f6810496f"
      },
      "source": [
        "scifi_vocabulary_size = len(scifi_vocabulary)\n",
        "print(\"The scifi use a vocabulary comprising {} different words.\".format(scifi_vocabulary_size))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scifi use a vocabulary comprising 200658 different words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMugJGcQ-Xz"
      },
      "source": [
        "word2index_scifi = {w:i for i,w in enumerate(scifi_vocabulary)} # Lookup table mapping words to indices\n",
        "index2word_scifi = {i:w for i,w in enumerate(scifi_vocabulary)} # Lookup table mapping indices to words"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTcH8mwgGPz"
      },
      "source": [
        "# To prevent the colab ram from crashing, save some spaces for memory\n",
        "del scifi_dataset, scifi_vocabulary"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihpxw4ADQ-X0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f2a1f7-4abb-4259-aa60-11822ed7fae5"
      },
      "source": [
        "scifi_data = []\n",
        "for i in range(CONTEXT_OFFSET, 1000000 + CONTEXT_OFFSET): # To prevent the colab ram from crashing, we chose the first 1000000 words for trainning\n",
        "    context = [scifi_word_list[i - 2], scifi_word_list[i - 1],\n",
        "              scifi_word_list[i + 1], scifi_word_list[i + 2]]\n",
        "    target = scifi_word_list[i]\n",
        "    scifi_data.append((context, target))\n",
        "print(scifi_data[:5])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['march', 'stories', 'complete', 'publisher'], 'new'), (['stories', 'new', 'publisher', 'editor'], 'complete'), (['new', 'complete', 'editor', 'published'], 'publisher'), (['complete', 'publisher', 'published', 'bimonthly'], 'editor'), (['publisher', 'editor', 'bimonthly', 'quinn'], 'published')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yla0GZr5Q-X0"
      },
      "source": [
        "X = np.array([i[0] for i in scifi_data])\n",
        "X_vectors = list(map(lambda elem: make_context_vector(elem, word2index_scifi) , X))\n",
        "y = np.array([i[1] for i in scifi_data])\n",
        "y_vectors = list(map(lambda elem: make_context_vector([elem], word2index_scifi), y))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMPNVlD1Q-X1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y_vectors, test_size=0.2, random_state=42)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o_8RGmkQ-X1"
      },
      "source": [
        "scifi_training_dataset = HotelReviewsDataset(X_train, y_train)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkQx-wKOQ-X2"
      },
      "source": [
        "## 3. Modelling (Sci-Fi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAtAVyqvQ-X2"
      },
      "source": [
        "scifi_data_loader = DataLoader(dataset=scifi_training_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECJ4zB0qQ-X2",
        "outputId": "5b46af6f-b571-4c7d-9e2c-5e772f489db5"
      },
      "source": [
        "model_scifi = CBOW(scifi_vocabulary_size, EMBEDDING_DIM_SCIFI, 2*CONTEXT_OFFSET).to(device)\n",
        "losses = train_model(model_scifi, scifi_data_loader, EPOCHS_SCIFI, word2index_scifi)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 ... Average loss 0.14284522960841656\n",
            "Epoch 2/2 ... Average loss 0.13756629810631274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VncbSqfoz3Ru"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcv_L-eQsi9H"
      },
      "source": [
        "Part 1 (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGUoP7D9b28"
      },
      "source": [
        "# Part 2: Test your embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvwdYFgdL9nq"
      },
      "source": [
        "## 2. find 5 neighbours of each of the 9 words from the hotel reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXR8AUQSCcGV",
        "outputId": "09489640-d2ba-4120-f3aa-4e3b2049a755"
      },
      "source": [
        "# check the frequencies of the words\n",
        "reviews_word_list=list((\" \".join(reviews)).split())\n",
        "frequency = pd.value_counts(reviews_word_list)\n",
        "print(\"The most frequent words are\\n{}\\n------------------------------\".format(frequency.head(20)))\n",
        "print(\"The less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[500:520]))\n",
        "print(\"The much less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[1000:1020]))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent words are\n",
            "hotel        48919\n",
            "room         34347\n",
            "great        21097\n",
            "nt           19000\n",
            "good         16990\n",
            "staff        16216\n",
            "stay         15160\n",
            "nice         12412\n",
            "rooms        12031\n",
            "location     11045\n",
            "stayed       10469\n",
            "service       9980\n",
            "time          9834\n",
            "night         9739\n",
            "beach         9597\n",
            "day           9551\n",
            "clean         9364\n",
            "breakfast     9274\n",
            "food          9010\n",
            "like          8114\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The less frequent words are\n",
            "makes          693\n",
            "directly       692\n",
            "seattle        691\n",
            "menu           691\n",
            "surprised      683\n",
            "efficient      682\n",
            "daughter       681\n",
            "recently       677\n",
            "truly          676\n",
            "ac             676\n",
            "royal          676\n",
            "public         676\n",
            "atmosphere     675\n",
            "cab            675\n",
            "basic          674\n",
            "swim           673\n",
            "attractions    673\n",
            "bavaro         673\n",
            "true           672\n",
            "ended          671\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The much less frequent words are\n",
            "careful       340\n",
            "hair          339\n",
            "additional    339\n",
            "smoke         339\n",
            "excursions    339\n",
            "word          338\n",
            "delivered     338\n",
            "wide          337\n",
            "future        337\n",
            "managed       337\n",
            "trees         337\n",
            "fully         336\n",
            "rico          336\n",
            "italy         336\n",
            "fan           336\n",
            "aware         335\n",
            "gone          335\n",
            "taxis         334\n",
            "comment       334\n",
            "members       334\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_v4l5lGJ5o"
      },
      "source": [
        "# We chose 3 nouns, 3 verbs, and 3 adjectives respectively from the above 3 frequency levels.\n",
        "chosen_words = ['beach','like','nice',\n",
        "                'daughter','swim','public',\n",
        "                'trees','smoke','careful']"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sur7tef3M4hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e38aaca-8ce4-4a3c-a574-5d0c6fe80331"
      },
      "source": [
        "def get_closest_word(word, topn):\n",
        "  word_distance = []\n",
        "  emb = model.embeddings\n",
        "  pdist = nn.PairwiseDistance()\n",
        "  i = word2index[word]\n",
        "  lookup_tensor_i = torch.tensor([i],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "  v_i = emb(lookup_tensor_i)\n",
        "  for j in range(len(reviews_vocabulary)):\n",
        "    if j !=i:\n",
        "      lookup_tensor_j = torch.tensor([j],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "      v_j = emb(lookup_tensor_j)\n",
        "      word_distance.append((index2word[j],float(pdist(v_i,v_j))))\n",
        "  word_distance.sort(key=lambda x:x[1])\n",
        "  return word_distance[:topn]\n",
        "\n",
        "example = get_closest_word('beach', 5)\n",
        "print(example)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('clearlyhotel', 5.2838215827941895), ('stripbad', 5.976334571838379), ('enough', 6.019063472747803), ('beigels', 6.052651405334473), ('fathers', 6.078352928161621)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SKL5FNpM4fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2e446d-bc83-4455-fc9f-ab133686297b"
      },
      "source": [
        "def get_closest_word_from_a_list(chosen_words,  topn):\n",
        "  chosen_words_and_their_neighbours=[]\n",
        "  for word in chosen_words:\n",
        "    get_result = get_closest_word(word,  topn)\n",
        "    neighbours = [nb[0] for nb in get_result]\n",
        "    chosen_words_and_their_neighbours.append((neighbours,word))\n",
        "  return chosen_words_and_their_neighbours\n",
        "\n",
        "neighbours = get_closest_word_from_a_list(chosen_words,5)\n",
        "neighbours"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['clearlyhotel', 'stripbad', 'enough', 'beigels', 'fathers'], 'beach'),\n",
              " (['racing', 'phoenixthe', 'informationi', 'bfest', 'itineraryyou'], 'like'),\n",
              " (['large', 'great', 'pressureoh', 'stupor', 'redundancies'], 'nice'),\n",
              " (['hasslesi', 'pointlessthe', 'geli', 'domenico', 'cap'], 'daughter'),\n",
              " (['kimptonoverall', 'bedmatress', 'womanno', 'plasmas', 'stinging'], 'swim'),\n",
              " (['oxidized', 'walk', 'gospainif', 'fhr', 'thin'], 'public'),\n",
              " (['goody', 'wifehad', 'waitressing', 'fraudulently', 'wit'], 'trees'),\n",
              " (['flute', 'simonewe', 'cotraveller', 'fridgeexcursions', 'tvconsoleremote'],\n",
              "  'smoke'),\n",
              " (['jon', 'spreading', 'memorize', 'orderedif', 'confortablelovely'],\n",
              "  'careful')]"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQAjrX1BNKuv"
      },
      "source": [
        "## 3. find 5 neighbours of each of the 9 words from the scifi dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-pFBNeQNKuw",
        "outputId": "cbdd306f-b8d3-45c6-bf7c-d0c217b23149"
      },
      "source": [
        "# check the frequencies of the words\n",
        "frequency = pd.value_counts(scifi_word_list)\n",
        "print(\"The most frequent words are\\n{}\\n------------------------------\".format(frequency.head(20)))\n",
        "print(\"The less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[500:520]))\n",
        "print(\"The much less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[800:820]))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent words are\n",
            "said     76347\n",
            "one      55339\n",
            "would    46555\n",
            "could    41388\n",
            "like     35710\n",
            "back     31984\n",
            "time     31971\n",
            "know     28539\n",
            "man      27071\n",
            "dont     26121\n",
            "get      24459\n",
            "well     23211\n",
            "see      21141\n",
            "us       21022\n",
            "way      20825\n",
            "two      20553\n",
            "even     20493\n",
            "right    19416\n",
            "first    18771\n",
            "got      17900\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The less frequent words are\n",
            "tiny         2415\n",
            "smile        2408\n",
            "showed       2400\n",
            "somewhere    2398\n",
            "mans         2390\n",
            "twenty       2388\n",
            "radio        2376\n",
            "wish         2369\n",
            "late         2369\n",
            "john         2367\n",
            "glanced      2363\n",
            "killed       2355\n",
            "legs         2355\n",
            "nearly       2353\n",
            "blood        2349\n",
            "single       2347\n",
            "couple       2345\n",
            "state        2338\n",
            "energy       2336\n",
            "complete     2336\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The much less frequent words are\n",
            "language    1595\n",
            "knowing     1595\n",
            "warm        1590\n",
            "b           1582\n",
            "dust        1578\n",
            "worry       1572\n",
            "editor      1572\n",
            "boys        1570\n",
            "offer       1566\n",
            "pass        1565\n",
            "turning     1565\n",
            "party       1564\n",
            "north       1563\n",
            "covered     1562\n",
            "river       1557\n",
            "orders      1551\n",
            "grinned     1550\n",
            "goes        1547\n",
            "remained    1538\n",
            "save        1537\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFytFPDbNKuw"
      },
      "source": [
        "# We chose 3 nouns, 3 verbs, and 3 adjectives respectively from the above 3 frequency levels.\n",
        "chosen_words_scifi = ['time','said','right',\n",
        "                      'blood','smile','tiny',\n",
        "                      'party','worry','warm']"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-4MXoB1NKux",
        "outputId": "e9510c1c-02ad-4bf4-d6ac-5d478f12f7ac"
      },
      "source": [
        "def get_closest_word_scifi(word, topn):\n",
        "  word_distance = []\n",
        "  emb = model_scifi.embeddings\n",
        "  pdist = nn.PairwiseDistance()\n",
        "  i = word2index_scifi[word]\n",
        "  lookup_tensor_i = torch.tensor([i],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "  v_i = emb(lookup_tensor_i)\n",
        "  for j in range(len(reviews_vocabulary)):\n",
        "    if j !=i:\n",
        "      lookup_tensor_j = torch.tensor([j],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "      v_j = emb(lookup_tensor_j)\n",
        "      word_distance.append((index2word_scifi[j],float(pdist(v_i,v_j))))\n",
        "  word_distance.sort(key=lambda x:x[1])\n",
        "  return word_distance[:topn]\n",
        "\n",
        "def get_closest_word_from_a_list_scifi(chosen_words, topn):\n",
        "  chosen_words_and_their_neighbours=[]\n",
        "  for word in chosen_words:\n",
        "    get_result = get_closest_word_scifi(word, topn)\n",
        "    neighbours = [nb[0] for nb in get_result]\n",
        "    chosen_words_and_their_neighbours.append((neighbours,word))\n",
        "  return chosen_words_and_their_neighbours\n",
        "\n",
        "\n",
        "neighbours = get_closest_word_from_a_list_scifi(chosen_words_scifi, 5)\n",
        "neighbours"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['endorses', 'gunnysack', 'eor', 'brion', 'hebbentons'], 'time'),\n",
              " (['compels', 'drooled', 'amck', 'enhancement', 'cheaply'], 'said'),\n",
              " (['carefully', 'bilge', 'controlcircles', 'gboats', 'anjouan'], 'right'),\n",
              " (['harobr', 'broucheoperas', 'bari', 'chickenhearted', 'concomitants'],\n",
              "  'blood'),\n",
              " (['domicile', 'dunican', 'engineersoldier', 'cerebellar', 'brakeman'],\n",
              "  'smile'),\n",
              " (['babushka', 'cowdye', 'chinadoll', 'accelerationdissipaters', 'carefully'],\n",
              "  'tiny'),\n",
              " (['guided', 'glitterof', 'babyrational', 'delisted', 'crumples'], 'party'),\n",
              " (['cozzi', 'gadzoons', 'discrepancies', 'dober', 'careillustrated'], 'worry'),\n",
              " (['bxeathing', 'basses', 'depresses', 'asmells', 'damnwell'], 'warm')]"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbA6fBZaa6Iv"
      },
      "source": [
        "## 5. Choose two words and retrive their 5 closest neighbours from both datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EcLEX5zbHB_",
        "outputId": "25f746ae-cc08-4f31-9004-7f53766e0274"
      },
      "source": [
        "chosen_words=['good','said']\n",
        "neighbours_from_reviews = get_closest_word_from_a_list(chosen_words, 5)\n",
        "neighbours_from_scifi = get_closest_word_from_a_list_scifi(chosen_words, 5)\n",
        "\n",
        "\n",
        "print(\"5 closest neighbours of the chosen words in hotel reviews dataset:\")\n",
        "print(neighbours_from_reviews)\n",
        "print(\"5 closest neighbours of the chosen words in scifi dataset:\")\n",
        "print(neighbours_from_scifi)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 closest neighbours of the chosen words in hotel reviews dataset:\n",
            "[(['named', 'efficientexcellent', 'yiiiiiiiiiiiiiiiii', 'acquired', 'adequatei'], 'good'), (['interfering', 'hearhiring', 'gilbert', 'unfortunatelyafter', 'fullnow'], 'said')]\n",
            "5 closest neighbours of the chosen words in scifi dataset:\n",
            "[(['brokenhome', 'cronuss', 'could', 'ballooningup', 'b'], 'good'), (['compels', 'drooled', 'amck', 'enhancement', 'cheaply'], 'said')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wLDSnwdjtf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}