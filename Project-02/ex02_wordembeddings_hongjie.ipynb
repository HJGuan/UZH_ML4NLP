{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ex02_wordembeddings_hongjie.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-02/ex02_wordembeddings_hongjie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNNOVmLD-Fz"
      },
      "source": [
        "# Project 2 - Word Embeddings with PyTorch\n",
        "\n",
        "The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep\n",
        "learning. It is a model that tries to predict words given the context of\n",
        "a few words before and a few words after the target word. This is\n",
        "distinct from language modeling, since CBOW is not sequential and does\n",
        "not have to be probabilistic. Typcially, CBOW is used to quickly train\n",
        "word embeddings, and these embeddings are used to initialize the\n",
        "embeddings of some more complicated model. Usually, this is referred to\n",
        "as *pretraining embeddings*. It almost always helps performance a couple\n",
        "of percent.\n",
        "\n",
        "The CBOW model is as follows. Given a target word $w_i$ and an\n",
        "$N$ context window on each side, $w_{i-1}, \\dots, w_{i-N}$\n",
        "and $w_{i+1}, \\dots, w_{i+N}$, referring to all context words\n",
        "collectively as $C$, CBOW tries to minimize\n",
        "\n",
        "\\begin{align}-\\log p(w_i | C) = -\\log \\text{Softmax}(A(\\sum_{w \\in C} q_w) + b)\\end{align}\n",
        "\n",
        "where $q_w$ is the embedding for word $w$.\n",
        "\n",
        "Implement this model in Pytorch by filling in the class below. Some\n",
        "tips:\n",
        "\n",
        "* Think about which parameters you need to define.\n",
        "* Make sure you know what shape each operation expects. Use .view() if you need to\n",
        "  reshape.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHXvfNTXD4Ca"
      },
      "source": [
        "## Part 1: Training CBOW embeddings for both datasets\n",
        "### 1. Setup\n",
        "#### 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EATjb-X-0lM",
        "outputId": "d435a3d4-7d04-4c28-cb2a-ece56892cfd1"
      },
      "source": [
        "import os\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', 800)\n",
        "\n",
        "# tokenization\n",
        "import nltk;\n",
        "nltk.download('stopwords');\n",
        "%matplotlib inline\n",
        "\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import string\n",
        "import itertools\n",
        "import regex as re\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "import requests"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKjgo1cEEQPw"
      },
      "source": [
        "#### 1.2 Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Tszg7FdPrZ",
        "outputId": "6a50a788-b31e-4039-f0fc-43a2857fc3e2"
      },
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu:0')\n",
        "torch.cuda.set_device(device)\n",
        "print('Using device:', device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ZgunZ9qSvu",
        "outputId": "5285e5d7-73a4-4ae2-e988-5ee503bee227"
      },
      "source": [
        "# Check GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 26 01:25:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    31W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keYYVJLbnpbD",
        "outputId": "e988eb7f-8d90-461c-a550-8fe964091af1"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-3e28ad3a-0f33-59f7-68e1-9f1c4256e7e6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGFVru-nqX1n",
        "outputId": "063a21e5-0387-49b5-e5c9-d930055f75e7"
      },
      "source": [
        "# Check Memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW7vvEZkEdrX"
      },
      "source": [
        "#### 1.3 Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grG2YIi8-aYu"
      },
      "source": [
        "FEATURE_COLUMN = 'Review'\n",
        "CONTEXT_OFFSET = 2 # n words to the left, n to the right\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "EPOCHS_HOTEL = 15\n",
        "EMBEDDING_DIM_HOTEL = 50\n",
        "\n",
        "EPOCHS_SCIFI = 2\n",
        "EMBEDDING_DIM_SCIFI = 50"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gy3d3hJQZB9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAqmKotTv5FX"
      },
      "source": [
        "### Hotel Reviews dataset\n",
        "### 2. Data Preprocessing\n",
        "#### 2.1 Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSA-k-FGGYVx",
        "outputId": "05e77e85-9c82-47a9-e785-fc1bfebcd8b2"
      },
      "source": [
        "# Loading the tripadvisor data\n",
        "url_tripadvisor = (r'https://raw.githubusercontent.com/abandonedrepo/test/master/tripadvisor_hotel_reviews.csv')\n",
        "reviews_dataset = pd.read_csv(url_tripadvisor)\n",
        "reviews_dataset.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20491 entries, 0 to 20490\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  20491 non-null  object\n",
            " 1   Rating  20491 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 320.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "MpAY67nPvFw9",
        "outputId": "6dcfb6a0-e460-4428-caa7-7a9a6e0eb129"
      },
      "source": [
        "reviews_dataset.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, start booked suite paid extra website description not, suite bedroom bathroom standard hotel room, took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast, got kidding, embassy suits sitting room bathroom bedroom unlike kimpton calls suite, 5 day stay offer correct false advertising, send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty did not reply solution, send email trip guest survey did not follow email mail, guess tell concerned guest.the staff ranged indifferent not help...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nice rooms not 4* experience hotel monaco seattle good hotel n't 4* level.positives large bathroom mediterranean suite comfortable bed pillowsattentive housekeeping staffnegatives ac unit malfunctioned stay desk disorganized, missed 3 separate wakeup calls, concierge busy hard touch, did n't provide guidance special requests.tv hard use ipod sound dock suite non functioning. decided book mediterranean suite 3 night weekend stay 1st choice rest party filled, comparison w spent 45 night larger square footage room great soaking tub whirlpool jets nice shower.before stay hotel arrange car service price 53 tip reasonable driver waiting arrival.checkin easy downside room picked 2 person jacuzi tub no bath accessories salts bubble bath did n't stay, night got 12/1a checked voucher bottle cham...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown shopping area, pet friendly room showed no signs animal hair smells, monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy, goldfish named brandi enjoyed, did n't partake free wine coffee/tea service lobby thought great feature, great staff friendly, free wireless internet hotel worked suite 2 laptops, decor lovely eclectic mix pattens color palatte, animal print bathrobes feel like rock stars, nice did n't look like sterile chain hotel hotel personality excellent stay,</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great stay great stay, went seahawk game awesome, downfall view building did n't complain, room huge staff helpful, booked hotels website seahawk package, no charge parking got voucher taxi, problem taxi driver did n't want accept voucher barely spoke english, funny thing speak arabic called started making comments girlfriend cell phone buddy, took second realize just said fact speak language face priceless, ass told, said large city, told head doorman issue called cab company promply answer did n't, apologized offered pay taxi, bucks 2 miles stadium, game plan taxi return going humpin, great walk did n't mind, right christmas wonderful lights, homeless stowed away building entrances leave, police presence not greatest area stadium, activities 7 blocks pike street waterfront great coff...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Review  Rating\n",
              "0                                                                                                                                                                                                                nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,         4\n",
              "1  ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, start booked suite paid extra website description not, suite bedroom bathroom standard hotel room, took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast, got kidding, embassy suits sitting room bathroom bedroom unlike kimpton calls suite, 5 day stay offer correct false advertising, send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty did not reply solution, send email trip guest survey did not follow email mail, guess tell concerned guest.the staff ranged indifferent not help...       2\n",
              "2  nice rooms not 4* experience hotel monaco seattle good hotel n't 4* level.positives large bathroom mediterranean suite comfortable bed pillowsattentive housekeeping staffnegatives ac unit malfunctioned stay desk disorganized, missed 3 separate wakeup calls, concierge busy hard touch, did n't provide guidance special requests.tv hard use ipod sound dock suite non functioning. decided book mediterranean suite 3 night weekend stay 1st choice rest party filled, comparison w spent 45 night larger square footage room great soaking tub whirlpool jets nice shower.before stay hotel arrange car service price 53 tip reasonable driver waiting arrival.checkin easy downside room picked 2 person jacuzi tub no bath accessories salts bubble bath did n't stay, night got 12/1a checked voucher bottle cham...       3\n",
              "3                                                                                                                                                                                                         unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown shopping area, pet friendly room showed no signs animal hair smells, monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy, goldfish named brandi enjoyed, did n't partake free wine coffee/tea service lobby thought great feature, great staff friendly, free wireless internet hotel worked suite 2 laptops, decor lovely eclectic mix pattens color palatte, animal print bathrobes feel like rock stars, nice did n't look like sterile chain hotel hotel personality excellent stay,         5\n",
              "4  great stay great stay, went seahawk game awesome, downfall view building did n't complain, room huge staff helpful, booked hotels website seahawk package, no charge parking got voucher taxi, problem taxi driver did n't want accept voucher barely spoke english, funny thing speak arabic called started making comments girlfriend cell phone buddy, took second realize just said fact speak language face priceless, ass told, said large city, told head doorman issue called cab company promply answer did n't, apologized offered pay taxi, bucks 2 miles stadium, game plan taxi return going humpin, great walk did n't mind, right christmas wonderful lights, homeless stowed away building entrances leave, police presence not greatest area stadium, activities 7 blocks pike street waterfront great coff...       5"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jay7YAfne0wo"
      },
      "source": [
        "#### 2.2 Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0rNpT9gd4bp"
      },
      "source": [
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def clean_document(x):\n",
        "    x = re.sub(r'\\w*\\d\\w*', ' ', x)\n",
        "    x = re.sub(r'[^a-zA-Z\\s]', ' ', x.lower(), re.I|re.A)\n",
        "    x = re.sub(r'[\\-!+_@*#\\/$:)\"\\'.;,?&({}[]]*', ' ', x)\n",
        "    x = re.sub(r'\\b\\w{1,2}\\b', ' ', x)\n",
        "    x = re.sub(' +', ' ', x)\n",
        "    tokens = wpt.tokenize(x)\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    x = ' '.join(filtered_tokens)\n",
        "    return x\n",
        "\n",
        "clean_corpus = np.vectorize(clean_document)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgtrtfqq-kwj"
      },
      "source": [
        "# Clean the reviews by removing punctuation characters and stopwords.\n",
        "reviews = clean_corpus(reviews_dataset['Review'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwSUTo0zz-q-",
        "outputId": "da2c4b48-bd25-4018-f9ae-70a6274e5178"
      },
      "source": [
        "np.random.choice(reviews, 10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['great price boyfriend stayed night vibe hotel thought price location beat recently undergone massive renovation rooms modern comfortable included amenity asked minus complimentary towels rooftop pool slightly annoying called housekeeping times clearly ignored basically aside lack towels pool stay comfortable hassle free exactly looking',\n",
              "       'excellent hotel pay husband fly punta cana minute stayed hotel nights great stayed called star hotels punta cana believe stars compare star hotel year traveled kids stayed iberostar punta cana supposedly star compared ifa better food better ifa make reservations carte enjoyed buffet restaurants specially casona villa visit country want ordinary eat typical dishes country casona mangu morning lunch dinner tried mix typical dishes continental dishes desserts great specially flan favorite usually picky eater went aboard eating wish bring cook experience slowness service getting drinks restaurants hand husband wined wine rooms air conditioner good day leaking got fixed night issues hair dryer got repaired missing cord phone resolved rooms clean saw bugs pools beaches beautiful crazy salty water stayed entire day water warm crystal waters clean warm like beaches cold beautiful scenery spectacular views shows night life great went disco close beach night great time great gym spa gym bigger hotels equipment overall stay excellent like person mentioned make attitude want attitude',\n",
              "       'wow start finish entire experience great went making feel special wife birthday weekend room adequately sized exceptionally clean staying manhatten look',\n",
              "       'bad upgrades completed stayed recently days location near ikebukuro station convenient lot places shop explore restaurants walking distance house restaurants previous poster stated quite pricey business center computers printers guests bad room free internet quite fast note despite posted rooms upgraded floors upgraded non upgraded rooms means bad bit dated worn circa room standard double night non upgraded rest upgraded room upgraded rooms nice deserving star rating double bed rooms tiny barely fit suitcases use table second luggage rack desk quite comfortable saw twin rooms size better suited people double rooms probably best solo travelers overall hotel great value tokyo staff really try helpful upgrading floors sure planned certainly best values tokyo',\n",
              "       'hope review helps got melia caribe start bad resort like size small town tram ride depending room beware samll children try rooms closest pool beach area huge pain lugging kids forth room unless plan say beach pool area day long second biggest issue reservation secure reservation following day best reservation complain manager time buffets require reservation air conditioning locations restaurants require reservation casino rooms air conditioning beware time hot july august best times service great issues getting bath towles pool towels premium good resort clean grounds pool beach areas star food buffets better restaurants know make enjoyable stay',\n",
              "       'heaven earth stayed hyatt twin centre holiday amazing visited buzzing hong kong fab really holiday ready relax got bali hotel beautiful booked sea view room worth view breathtaking gardens hotel beautiful staff pleasant helpful stayed bed breakfast breakfast excellent lots choice need wish sample local restaurants experience culture partner loves diving went diving booked lady called camilla loal diving school great involved aswell spectator boat litlle snorkelling fab best trip whilst elephant safari going becareful make sure original park parks original opened man rescue elephants sumatra brings elephant keepers really care elephants good hour away pass beautiful rice fields look like green waterfalls way volcano distance plus local villages apparently somebody tried copy park opened meant good jimbaran bay best place watch sunset lots ofseafood restaurants beach choose fish freshly cooked order worth try seafood lovers think like delicious setting romantic red snapper tiger prawns clams rice salad sauces total food really people jimbaran bay away taxi make sure book taxi pick ended getting lift local man luckily nice rip really recommended sanur lots nice places eat lazar bar good steaks cat fiddle good irish pub serves good food bad meal itsjust embarassingly cheap courses people plus rounds drinks averaged balinese massage whilst hotel spa excellent enjoy',\n",
              "       'perfection deserves star greeted outside owner property know reached someplace spectacular simpsons actually refurbished home late century located tree lined challis street adorable bookstore great restaurants fratelli paradiso easy walk tube scent fresh lilies thing noticed foyer room foyer opens small sitting room library tons books worn soft leather chairs sofa tucked away corner free internet cozy fireplace sherry port pleasure perfect way welcomed home end day room walked beautiful oak staircase noticing exquisite stained glass windows cloud suite floor right hotel pretty views challis room comfy king bed person jacuzzi tub sealed fireplace beautiful stained glass window small loveseat coffee table closet iron board dvd player alarm clock writing desk fall winter turn flaw shower door leaked lot water bathroom floor complimentary breakfast cereal fruit toast jam served hot beverage choice tea french press coffee nice way start day best simpsons amazing staff make feel like friend family vanessa patiently tirelessly answers guests questions breakfast restaurant recommendations directions answer question smile believe highest compliment hotel send guests believe telling know gem',\n",
              "       'convenient comfortable experience far convenient hotel flying schiphol airport practically inside airport building probably best choice visiting amsterdam days place people stay night lots people arriving leaving somewhat soulless businesslike atmosphere rooms clean comfortable quiet nice beds deducted star restaurant quite frankly bad value food expensive',\n",
              "       'delightful hotel spent weeks alam shanti june july trip bali stayed standard rooms saraswati clean comfortable spacious needed water pressure dodgy shower fairly common probably worse upstairs rooms gardens beautiful worth booking upstairs room lie day bed look trees flowers agung staff caring considerate make stay pleasant real bonus car want ubud picked shopping eating town easy walk ubud monkey forest reach monkey forest road bit slog recommend going jalan hanoman restaurant alam shanti order food delivered restaurants car drop pick restaurant ubud trips bali staying wide range accommodation feel alam shanti combines best elements bali experience natural beauty gentle people serene atmosphere lovely pool enjoy tropical heat',\n",
              "       'basic hotel great location stayed hotel week september hotel basic different rooms finally live week rooms tiny shower cubicle big stand book expect standards hostel actually stayed nicer hostels wont disappointed expect htoel staff helpful breakfast included continental start day minute walk ramblas marina great location easily airport bus plaza espanya metro think parallel right warned rooms none air worked night double rooms booked january want info getting visiting port aventura ask'],\n",
              "      dtype='<U12603')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtL6IIv1HC4H"
      },
      "source": [
        "# Since we want to train a CBOW model with context width of 2\n",
        "# on the reviews, we drop all reviews with less than 5 words.\n",
        "# This is equivalent to only keeping instances with at least 5 words.\n",
        "reviews = [review for review in reviews if len(review.split(\" \")) >=  (2*CONTEXT_OFFSET + 1)]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjNI3ufc6nFa"
      },
      "source": [
        "reviews_word_list=list((\" \".join(reviews)).split())\n",
        "\n",
        "frequency = pd.value_counts(reviews_word_list)\n",
        "infrequent_words = list(frequency[frequency <= 1].keys())\n",
        "frequent_words = list(frequency[frequency > 1].keys())\n",
        "\n",
        "is_infrequent = {}\n",
        "for infrequent_word in infrequent_words:\n",
        "  is_infrequent[infrequent_word] = 1\n",
        "\n",
        "for frequent_word in frequent_words:\n",
        "  is_infrequent[frequent_word] = 0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B7bSUCDOWjk",
        "outputId": "e7eaa051-6462-4a73-c351-008c0913ad05"
      },
      "source": [
        "print(\"The length of the frequent_words:{}\".format(len(frequent_words)))\n",
        "print(\"The length of the infrequent_words:{}\".format(len(infrequent_words)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the frequent_words:24730\n",
            "The length of the infrequent_words:23833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxUXynX0M5iz"
      },
      "source": [
        "# In order to build the corpus for the reviews \n",
        "# we want to find every distinct word that occurs\n",
        "# in at least one review.\n",
        "# We join all reviews into one large string and then\n",
        "# split it at every space to receive a list of words\n",
        "# Then the set method is used in order to only\n",
        "# retain unique words.\n",
        "# This list is then alphabetically sorted\n",
        "review_words = \" \".join(reviews).split()\n",
        "review_words = [w for w in review_words if not is_infrequent[w]]\n",
        "reviews_vocabulary = sorted(set(review_words))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw6FFmeNW5Or",
        "outputId": "d2cd2849-6c8c-41b8-e08b-1cd69602d09e"
      },
      "source": [
        "reviews_vocabulary_size = len(reviews_vocabulary)\n",
        "print(\"The reviews use a vocabulary comprising {} different words.\".format(reviews_vocabulary_size))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reviews use a vocabulary comprising 24730 different words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErFC1k2kNpCE"
      },
      "source": [
        "word2index = {w:i for i,w in enumerate(reviews_vocabulary)} # Lookup table mapping words to indices\n",
        "index2word = {i:w for i,w in enumerate(reviews_vocabulary)} # Lookup table mapping indices to words"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQYOKdbna5aC"
      },
      "source": [
        "#To clean the infrequnt words\n",
        "\n",
        "def clean_infrequent_words(reviews):\n",
        "  new_reviews=[]\n",
        "  for review in reviews:\n",
        "    infrequent_index=[]\n",
        "    raw_text = review.split()\n",
        "    for i in range(0,len(raw_text)):\n",
        "      if is_infrequent[raw_text[i]]==1:\n",
        "        infrequent_index.append(i)\n",
        "    for i in sorted(infrequent_index,reverse=True):\n",
        "      del raw_text[i]\n",
        "    review=' '.join(raw_text)\n",
        "    new_reviews.append(review)\n",
        "  return new_reviews\n",
        "\n",
        "reviews=clean_infrequent_words(reviews)\n",
        "# drop review with less than 5 words again\n",
        "reviews = [review for review in reviews if len(review.split(\" \")) >=  (2*CONTEXT_OFFSET + 1)]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBwNZhIKcqAo"
      },
      "source": [
        "data = []\n",
        "for review in reviews:\n",
        "  raw_text = review.split()\n",
        "  for i in range(CONTEXT_OFFSET, len(raw_text) - CONTEXT_OFFSET):\n",
        "      context = [raw_text[i - 2], raw_text[i - 1],\n",
        "                raw_text[i + 1], raw_text[i + 2]]\n",
        "      #print(context)\n",
        "      target = raw_text[i]\n",
        "      data.append((context, target))\n",
        "\n",
        "# Show some sample 'context -> center word' mappings\n",
        "#for i in range(5):\n",
        "#  print(data[i])\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqPIILq3f9er",
        "outputId": "10fdcc75-48ef-4292-ee54-e2cb3136738b"
      },
      "source": [
        "# The following function transforms the context\n",
        "# into index notation\n",
        "def make_context_vector(context, word2index):\n",
        "    idxs = [word2index[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# Show one transformed sample context\n",
        "make_context_vector(data[0][0], word2index)  # example"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14585, 10605, 15681,  9535])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069rMbD_Vju4"
      },
      "source": [
        "class HotelReviewsDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKSnkqC7aPGV"
      },
      "source": [
        "X = np.array([i[0] for i in data])\n",
        "X_vectors = list(map(lambda elem: make_context_vector(elem, word2index) , X))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElJk2mFlJG6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2856b7da-9a5b-491c-fce1-26cb27a13f7d"
      },
      "source": [
        "# Print some vetorized sample contexts\n",
        "for i in range(5):\n",
        "  print(X_vectors[i])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14585, 10605, 15681,  9535])\n",
            "tensor([10605,  7848,  9535,  9494])\n",
            "tensor([ 7848, 15681,  9494,  5718])\n",
            "tensor([15681,  9535,  5718, 20853])\n",
            "tensor([ 9535,  9494, 20853, 10605])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrePOCkaQrB"
      },
      "source": [
        "y = np.array([i[1] for i in data])\n",
        "y_vectors = list(map(lambda elem: make_context_vector([elem], word2index), y))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFP9_whfKkxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a12b11-9b3d-40c9-c6ba-6af3d12d1f0f"
      },
      "source": [
        "# Print some vectorized sample center words\n",
        "for i in range(5):\n",
        "  print(y_vectors[i])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7848])\n",
            "tensor([15681])\n",
            "tensor([9535])\n",
            "tensor([9494])\n",
            "tensor([5718])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wFmcwnO9Dq7"
      },
      "source": [
        "# Split into training and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors[:500000], y_vectors[:500000], test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWkaD9JtaT9t"
      },
      "source": [
        "# Create the training dataset from vectors\n",
        "hotel_reviews_dataset = HotelReviewsDataset(X_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OapsjmhTfHxw"
      },
      "source": [
        "### 3. Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RvGC_MGH6k0"
      },
      "source": [
        "hotel_reviews_loader = DataLoader(dataset=hotel_reviews_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3_xQQ5Mw3JQ"
      },
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "      super(CBOW, self).__init__()\n",
        "      self.embeddings = nn.Embedding(vocab_size, embedding_dim, device=device)\n",
        "      self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "      self.activation_function1 = nn.ReLU()\n",
        "      self.linear2 = nn.Linear(128, vocab_size)\n",
        "      self.activation_function2 = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      embeds = self.embeddings(inputs).view(inputs.size(0), -1)\n",
        "      out = self.linear1(embeds)\n",
        "      out = self.activation_function1(out)\n",
        "      out = self.linear2(out)\n",
        "      out = self.activation_function2(out)\n",
        "      return out"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB1FCwfH4miH"
      },
      "source": [
        "def train_model(model, data_loader, epochs, word2index):\n",
        "\n",
        "  losses = np.zeros(epochs)\n",
        "  loss_function = nn.NLLLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for step, (context_vectors, target_vector) in enumerate(data_loader):\n",
        "\n",
        "      context_vectors = context_vectors.to(device) # Move the batch of context vectors into GPU memory\n",
        "      target_vector = target_vector.to(device) # Move the batch of target vectors into GPU memory \n",
        "\n",
        "      model.zero_grad() # Reset all gradients back to zero\n",
        "\n",
        "      log_probs = model(context_vectors) # forward pass\n",
        "      loss = loss_function(log_probs, torch.squeeze(target_vector)) # compute loss for batch\n",
        "      losses[epoch] += loss.item() # accumulate loss\n",
        "\n",
        "      loss.backward() # backpropagation\n",
        "      optimizer.step() # update the model weights\n",
        "\n",
        "    print(\"Epoch {0}/{1} ... Average loss {2}\".format(epoch+1, epochs, losses[epoch] / len(data_loader.dataset))) # Print average loss in this episode\n",
        "  return losses"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkd783s1i4tS"
      },
      "source": [
        "# Only run this cell if you want to load a saved CBOW model including embeddings.\n",
        "model = CBOW(reviews_vocabulary_size, EMBEDDING_DIM_HOTEL, 2*CONTEXT_OFFSET).to(device)\n",
        "model_path='./hotel_reviews_model_weights.pth'\n",
        "\n",
        "\n",
        "try:\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  model.eval()\n",
        "except Exception as e:\n",
        "  print(\"No saved embeddings exist.\")\n",
        "  print(\"Starting to learn word embeddings.\")\n",
        "  losses = train_model(model, hotel_reviews_loader, EPOCHS_HOTEL, word2index)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fj0D26mgDpS"
      },
      "source": [
        "# Save the trained CBOW model\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI4F2RhxQsli"
      },
      "source": [
        "### Sci-Fi story dataset\n",
        "### 2. Data Preprocessing\n",
        "#### 2.1 Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyhZrrzEM4oK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4f95e7-7f0d-4068-fddd-e1b5cd9d7f8d"
      },
      "source": [
        "# Loading the scifi txt\n",
        "url = 'https://raw.githubusercontent.com/abandonedrepo/test/master/scifi.txt'\n",
        "scifi_dataset = requests.get(url).text\n",
        "print(scifi_dataset[:100])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARCH # All Stories New and Complete Publisher Editor IF is published bi-monthly by Quinn Publishing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLOZKW_Q-Xx"
      },
      "source": [
        "#### 2.2 Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JbPCiNSQ-Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9321d9-6a84-4843-deac-ea0f26b5839e"
      },
      "source": [
        "# Clean the scifi text by removing punctuation and stop words\n",
        "scifi_txt = clean_document(scifi_dataset)\n",
        "print(scifi_txt[:100])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "march stories new complete publisher editor published monthly quinn publishing company inc kingston \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RqYPvfAWjft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69632ec3-ecd7-43bf-e92e-0b1df0319598"
      },
      "source": [
        "# Split the scifi text into individual words\n",
        "scifi_word_list=scifi_dataset.split()\n",
        "print(scifi_word_list[:10])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['march', 'stories', 'new', 'complete', 'publisher', 'editor', 'published', 'monthly', 'quinn', 'publishing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmH_3Ac3TVcy"
      },
      "source": [
        "frequency = pd.value_counts(scifi_word_list)\n",
        "infrequent_words = list(frequency[frequency <= 1].keys())\n",
        "frequent_words = list(frequency[frequency > 1].keys())\n",
        "\n",
        "is_infrequent = {}\n",
        "for infrequent_word in infrequent_words:\n",
        "  is_infrequent[infrequent_word] = 1\n",
        "\n",
        "for frequent_word in frequent_words:\n",
        "  is_infrequent[frequent_word] = 0"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2jCyVPOTDgN",
        "outputId": "1149d5e3-37c3-4c29-f4eb-e745a2ae65f6"
      },
      "source": [
        "#To clean the infrequnt words\n",
        "\n",
        "def clean_infrequent_words(scifi_txt):\n",
        "  infrequent_index=[]\n",
        "  raw_text = scifi_txt.split()\n",
        "  for i in range(0,len(raw_text)):\n",
        "    if is_infrequent[raw_text[i]]==1:\n",
        "      infrequent_index.append(i)\n",
        "  for i in sorted(infrequent_index,reverse=True):\n",
        "    del raw_text[i]\n",
        "  scifi_txt_new=' '.join(raw_text)\n",
        "  return scifi_txt_new\n",
        "\n",
        "scifi_txt=clean_infrequent_words(scifi_txt)\n",
        "print(scifi_txt[:1000])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "march stories new complete publisher editor published monthly quinn publishing company inc kingston new york volume copyright quinn publishing company inc application entry second class matter post office buffalo new york pending subscription issues possessions canada issues elsewhere four weeks change address stories appearing magazine fiction similarity actual persons coincidental printed chat editor science fiction magazine called title selected much thought brevity theory indicative field easy remember tentative title morning remember cup coffee summarily discarded great deal thought effort lias gone formation magazine aid several talented generous people grateful much due warmhearted assistance bulk formative work done try maintain one finest books market great public demand magazine short buy cannot honesty say publish times best science fiction field would true access best stories get fair share works best writers definitely talk adult juvenile relative content feel terms mislea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBtVoODKVPXb"
      },
      "source": [
        "# list of unique words from the scifi txt\n",
        "scifi_vocabulary = sorted(set(scifi_txt.split()))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMugJGcQ-Xz"
      },
      "source": [
        "word2index_scifi = {w:i for i,w in enumerate(scifi_vocabulary)} # Lookup table mapping words to indices\n",
        "index2word_scifi = {i:w for i,w in enumerate(scifi_vocabulary)} # Lookup table mapping indices to words"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTcH8mwgGPz"
      },
      "source": [
        "# To prevent the colab ram from crashing, save some spaces for memory\n",
        "del scifi_dataset, scifi_vocabulary"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihpxw4ADQ-X0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bae2af6-7be3-4c34-c185-c8c79eabbf7f"
      },
      "source": [
        "scifi_data = []\n",
        "for i in range(CONTEXT_OFFSET, 1000000 + CONTEXT_OFFSET): # To prevent the colab ram from crashing, we chose the first 1000000 words for trainning\n",
        "    context = [scifi_word_list[i - 2], scifi_word_list[i - 1],\n",
        "              scifi_word_list[i + 1], scifi_word_list[i + 2]]\n",
        "    target = scifi_word_list[i]\n",
        "    scifi_data.append((context, target))\n",
        "print(scifi_data[:5])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['march', 'stories', 'complete', 'publisher'], 'new'), (['stories', 'new', 'publisher', 'editor'], 'complete'), (['new', 'complete', 'editor', 'published'], 'publisher'), (['complete', 'publisher', 'published', 'monthly'], 'editor'), (['publisher', 'editor', 'monthly', 'quinn'], 'published')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yla0GZr5Q-X0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "10b2817c-8c4e-4822-fdf4-18fe2b4f86ad"
      },
      "source": [
        "X = np.array([i[0] for i in scifi_data])\n",
        "X_vectors = list(map(lambda elem: make_context_vector(elem, word2index_scifi) , X))\n",
        "y = np.array([i[1] for i in scifi_data])\n",
        "y_vectors = list(map(lambda elem: make_context_vector([elem], word2index_scifi), y))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-62eb17495e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscifi_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index_scifi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscifi_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index_scifi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-62eb17495e28>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(elem)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscifi_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index_scifi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscifi_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index_scifi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-c875e58c776b>\u001b[0m in \u001b[0;36mmake_context_vector\u001b[0;34m(context, word2index)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# into index notation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-c875e58c776b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# into index notation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'aiiow'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMPNVlD1Q-X1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y_vectors, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o_8RGmkQ-X1"
      },
      "source": [
        "scifi_training_dataset = HotelReviewsDataset(X_train, y_train)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkQx-wKOQ-X2"
      },
      "source": [
        "### 3. Modelling (Sci-Fi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQdR_2MmoTCY"
      },
      "source": [
        "scifi_model_path = './scifi_model_weights.pth'"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAtAVyqvQ-X2"
      },
      "source": [
        "scifi_data_loader = DataLoader(dataset=scifi_training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "model_scifi = CBOW(scifi_vocabulary_size, EMBEDDING_DIM_SCIFI, 2*CONTEXT_OFFSET).to(device)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyMzhEQom5zL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebc268e-a9b1-4343-8891-b9b11b678f0e"
      },
      "source": [
        "try:\n",
        "  model_scifi.load_state_dict(torch.load(scifi_model_path))\n",
        "  model.eval()\n",
        "except Exception as e:\n",
        "  print(\"No saved embeddings exist.\")\n",
        "  print(\"Starting to learn word embeddings.\")\n",
        "  losses = train_model(model_scifi, scifi_data_loader, EPOCHS_SCIFI, word2index_scifi)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No saved embeddings exist.\n",
            "Starting to learn word embeddings.\n",
            "Epoch 1/2 ... Average loss 0.1370953961914778\n",
            "Epoch 2/2 ... Average loss 0.1361736316627264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i0k9drfoMzu"
      },
      "source": [
        "# Save the trained CBOW model\n",
        "torch.save(model.state_dict(), scifi_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGUoP7D9b28"
      },
      "source": [
        "# Part 2: Test your embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvwdYFgdL9nq"
      },
      "source": [
        "## 2. find 5 neighbours of each of the 9 words from the hotel reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXR8AUQSCcGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b24d257-03a3-4966-fcee-40288e2bbf15"
      },
      "source": [
        "# check the frequencies of the words\n",
        "reviews_word_list=list((\" \".join(reviews)).split())\n",
        "frequency = pd.value_counts(reviews_word_list)\n",
        "print(\"Most frequent words are\\n{}\\n------------------------------\".format(frequency.head(20)))\n",
        "print(\"Medium frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[500:520]))\n",
        "print(\"Less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[1000:1020]))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent words are\n",
            "hotel        49877\n",
            "room         35357\n",
            "great        21482\n",
            "good         17418\n",
            "staff        16637\n",
            "stay         15413\n",
            "nice         12646\n",
            "rooms        12407\n",
            "location     11353\n",
            "stayed       10500\n",
            "service      10373\n",
            "night        10164\n",
            "time         10132\n",
            "beach        10068\n",
            "day           9979\n",
            "breakfast     9737\n",
            "clean         9599\n",
            "food          9425\n",
            "like          8254\n",
            "resort        8152\n",
            "dtype: int64\n",
            "------------------------------\n",
            "Medium frequent words are\n",
            "daughter      705\n",
            "received      704\n",
            "issue         698\n",
            "directly      697\n",
            "turn          697\n",
            "watch         695\n",
            "makes         694\n",
            "adequate      694\n",
            "surprised     693\n",
            "royal         689\n",
            "elevator      688\n",
            "break         688\n",
            "true          688\n",
            "cab           687\n",
            "bavaro        686\n",
            "complaints    684\n",
            "quickly       684\n",
            "recently      684\n",
            "basic         684\n",
            "smoking       683\n",
            "dtype: int64\n",
            "------------------------------\n",
            "Less frequent words are\n",
            "fully         342\n",
            "cafes         341\n",
            "taxis         341\n",
            "added         341\n",
            "gone          341\n",
            "italy         341\n",
            "comment       340\n",
            "filled        340\n",
            "lines         340\n",
            "apart         340\n",
            "month         340\n",
            "additional    339\n",
            "fee           339\n",
            "aware         338\n",
            "heat          338\n",
            "lift          336\n",
            "members       336\n",
            "base          336\n",
            "sister        335\n",
            "wow           335\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_v4l5lGJ5o"
      },
      "source": [
        "# We chose 3 nouns, 3 verbs, and 3 adjectives respectively from the above 3 frequency levels.\n",
        "chosen_words = ['hotel','great', 'clean', # From most frequent words\n",
        "                'issue','adequate','smoking', # From medium frequent words\n",
        "                'italy','filled','comment'] # From least frequent words"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sur7tef3M4hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267f6152-b4f9-44f2-e9ab-9f3b6cf176a3"
      },
      "source": [
        "def get_closest_word(word, topn):\n",
        "  word_distance = []\n",
        "  emb = model.embeddings\n",
        "  pdist = nn.PairwiseDistance()\n",
        "  i = word2index[word]\n",
        "  lookup_tensor_i = torch.tensor([i],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "  v_i = emb(lookup_tensor_i)\n",
        "  for j in range(len(reviews_vocabulary)):\n",
        "    if j !=i:\n",
        "      lookup_tensor_j = torch.tensor([j],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "      v_j = emb(lookup_tensor_j)\n",
        "      word_distance.append((index2word[j],float(pdist(v_i,v_j))))\n",
        "  word_distance.sort(key=lambda x:x[1])\n",
        "  return word_distance[:topn]\n",
        "\n",
        "example = get_closest_word('beach', 5)\n",
        "print(example)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('decadence', 5.999974727630615), ('ajar', 6.075405120849609), ('diredtly', 6.129234790802002), ('spoons', 6.165433883666992), ('bridges', 6.290661811828613)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SKL5FNpM4fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5071e5-ca97-4d72-8367-5732a59031bd"
      },
      "source": [
        "def get_closest_word_from_a_list(chosen_words,  topn):\n",
        "  chosen_words_and_their_neighbours=[]\n",
        "  for word in chosen_words:\n",
        "    get_result = get_closest_word(word,  topn)\n",
        "    neighbours = [nb[0] for nb in get_result]\n",
        "    chosen_words_and_their_neighbours.append((neighbours,word))\n",
        "  return chosen_words_and_their_neighbours\n",
        "\n",
        "neighbours = get_closest_word_from_a_list(chosen_words,5)\n",
        "neighbours"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['pita', 'fat', 'smoke', 'piccolo', 'stingers'], 'hotel'),\n",
              " (['fantastic', 'denmark', 'wonderful', 'stationary', 'bike'], 'great'),\n",
              " (['seller', 'sio', 'waves', 'smelled', 'beautifully'], 'clean'),\n",
              " (['musicians', 'replenishing', 'loews', 'palmer', 'teddy'], 'issue'),\n",
              " (['lush', 'condescending', 'discriminating', 'nice', 'naughty'], 'adequate'),\n",
              " (['bagages', 'neil', 'gated', 'sailboats', 'rust'], 'smoking'),\n",
              " (['flair', 'overbook', 'innova', 'inexistant', 'tightest'], 'italy'),\n",
              " (['formalities', 'rememberance', 'retreating', 'mags', 'ghiardelli'],\n",
              "  'filled'),\n",
              " (['memory', 'everynight', 'brings', 'neutrogena', 'domican'], 'comment')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQAjrX1BNKuv"
      },
      "source": [
        "## 3. find 5 neighbours of each of the 9 words from the scifi dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pFBNeQNKuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88982894-5da5-4607-da86-de0fea8f9fdb"
      },
      "source": [
        "# check the frequencies of the words\n",
        "frequency = pd.value_counts(scifi_word_list)\n",
        "print(\"The most frequent words are\\n{}\\n------------------------------\".format(frequency.head(20)))\n",
        "print(\"The less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[500:520]))\n",
        "print(\"The much less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[800:820]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent words are\n",
            "said      76385\n",
            "one       57263\n",
            "would     46663\n",
            "could     41425\n",
            "like      36472\n",
            "time      32907\n",
            "back      32185\n",
            "man       30097\n",
            "know      28632\n",
            "get       24516\n",
            "two       21847\n",
            "see       21211\n",
            "way       21081\n",
            "even      20510\n",
            "right     19564\n",
            "first     19159\n",
            "well      18729\n",
            "got       17908\n",
            "little    17267\n",
            "think     17003\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The less frequent words are\n",
            "pointed      2320\n",
            "shot         2318\n",
            "laughed      2314\n",
            "happen       2312\n",
            "lips         2306\n",
            "paper        2294\n",
            "alive        2287\n",
            "shall        2284\n",
            "although     2282\n",
            "attention    2280\n",
            "ships        2278\n",
            "area         2278\n",
            "died         2275\n",
            "position     2271\n",
            "stuff        2249\n",
            "reach        2248\n",
            "broke        2245\n",
            "dear         2244\n",
            "speak        2240\n",
            "answered     2239\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The much less frequent words are\n",
            "purpose       1514\n",
            "aside         1509\n",
            "ears          1506\n",
            "possibly      1506\n",
            "indeed        1505\n",
            "steve         1504\n",
            "spread        1503\n",
            "forced        1503\n",
            "venus         1500\n",
            "ancient       1499\n",
            "threw         1498\n",
            "weight        1497\n",
            "class         1493\n",
            "mark          1490\n",
            "seeing        1488\n",
            "creatures     1488\n",
            "expression    1488\n",
            "final         1487\n",
            "growing       1485\n",
            "giant         1482\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFytFPDbNKuw"
      },
      "source": [
        "# We chose 3 nouns, 3 verbs, and 3 adjectives respectively from the above 3 frequency levels.\n",
        "chosen_words_scifi = ['time','said','right',\n",
        "                      'blood','smile','tiny',\n",
        "                      'party','worry','warm']"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-4MXoB1NKux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba73e790-e280-4a8d-9cee-766a793dbb98"
      },
      "source": [
        "def get_closest_word_scifi(word, topn):\n",
        "  word_distance = []\n",
        "  emb = model_scifi.embeddings\n",
        "  pdist = nn.PairwiseDistance()\n",
        "  i = word2index_scifi[word]\n",
        "  lookup_tensor_i = torch.tensor([i],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "  v_i = emb(lookup_tensor_i)\n",
        "  for j in range(len(reviews_vocabulary)):\n",
        "    if j !=i:\n",
        "      lookup_tensor_j = torch.tensor([j],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "      v_j = emb(lookup_tensor_j)\n",
        "      word_distance.append((index2word_scifi[j],float(pdist(v_i,v_j))))\n",
        "  word_distance.sort(key=lambda x:x[1])\n",
        "  return word_distance[:topn]\n",
        "\n",
        "def get_closest_word_from_a_list_scifi(chosen_words, topn):\n",
        "  chosen_words_and_their_neighbours=[]\n",
        "  for word in chosen_words:\n",
        "    get_result = get_closest_word_scifi(word, topn)\n",
        "    neighbours = [nb[0] for nb in get_result]\n",
        "    chosen_words_and_their_neighbours.append((neighbours,word))\n",
        "  return chosen_words_and_their_neighbours\n",
        "\n",
        "\n",
        "neighbours = get_closest_word_from_a_list_scifi(chosen_words_scifi, 5)\n",
        "neighbours"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['bloodier', 'calluses', 'anticlimactic', 'attentioncatchers', 'clifftop'],\n",
              "  'time'),\n",
              " (['cavortings', 'blossom', 'abbe', 'arrack', 'bendin'], 'said'),\n",
              " (['alula', 'blasien', 'borglu', 'aftereffect', 'accelerators'], 'right'),\n",
              " (['apparel', 'asinine', 'blooped', 'ashanti', 'blasien'], 'blood'),\n",
              " (['aversive', 'cassai', 'assemblage', 'campania', 'biglargely'], 'smile'),\n",
              " (['buffaloed', 'andersen', 'bakelite', 'acropolis', 'blatancy'], 'tiny'),\n",
              " (['brrr', 'bascomb', 'bedecked', 'campisanos', 'canalize'], 'party'),\n",
              " (['brlazi', 'beehive', 'cisely', 'aixested', 'biqueman'], 'worry'),\n",
              " (['braques', 'boiloff', 'brertnan', 'armuch', 'aingo'], 'warm')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3PX3yggR5nf",
        "outputId": "6fd8dc8a-6681-4ba0-fbda-cef50d03941b"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([107780,  77387,  44873,  12988]),\n",
              " tensor([ 97871,  40512, 140517,  17332]),\n",
              " tensor([ 82194, 145875, 148230,  56966]),\n",
              " tensor([  8911, 137290,  65549,  50108]),\n",
              " tensor([161130, 131494,  29074,  32803]),\n",
              " tensor([ 38694, 129521,  56746,  78634]),\n",
              " tensor([ 81136, 151584, 114839, 148650]),\n",
              " tensor([161671,  93728, 141700, 145162]),\n",
              " tensor([107766, 104298, 141898, 143346]),\n",
              " tensor([133667,  44873,  17834,  83098]),\n",
              " tensor([134939, 125714,  54196, 120131]),\n",
              " tensor([139880,  91954, 111247, 107317]),\n",
              " tensor([ 39735,  46418,  64036, 153366]),\n",
              " tensor([ 21139, 102205,   6851, 129244]),\n",
              " tensor([ 81350,  52962,  30380, 129898]),\n",
              " tensor([160752,  26422,  25140,  96755]),\n",
              " tensor([124538,  77769,  97860, 146208]),\n",
              " tensor([106611,  54863, 103506, 129957]),\n",
              " tensor([139986,  25867,  60601,  21916]),\n",
              " tensor([143317, 120612,  31429,  78153]),\n",
              " tensor([ 55974, 113373, 135985, 151123]),\n",
              " tensor([137487,  42761, 149689,  51970]),\n",
              " tensor([ 55259,  21916, 123727,  77387]),\n",
              " tensor([ 32807, 145116,  32248,   8800]),\n",
              " tensor([157797,  16002,  93616,  11683]),\n",
              " tensor([141553,  24511, 143812,  89020]),\n",
              " tensor([ 23545,  35687, 140928, 135725]),\n",
              " tensor([ 98906, 132236,  85039,  12602]),\n",
              " tensor([158022,  18548,  63411, 138307]),\n",
              " tensor([46834, 96140, 19120, 34738]),\n",
              " tensor([  8108, 103258, 134480,  38397]),\n",
              " tensor([123043,  63220, 104298,  81136]),\n",
              " tensor([ 22275, 154684,  87022, 100974]),\n",
              " tensor([ 87983, 127204,  61602, 110909]),\n",
              " tensor([ 98084, 132003,   4252, 121830]),\n",
              " tensor([ 79228, 132081,  30697,  14753]),\n",
              " tensor([35687, 22636,  4636,  4993]),\n",
              " tensor([ 48091,  29074, 129244,  81815]),\n",
              " tensor([42323,  8108, 46515, 87298]),\n",
              " tensor([133131, 148172,  69230,  82501]),\n",
              " tensor([ 51167, 132785, 114805,   9823]),\n",
              " tensor([ 72896, 162638, 122819,    900]),\n",
              " tensor([ 37360,  95382,  98511, 135827]),\n",
              " tensor([130118,  88158,  78900,  43149]),\n",
              " tensor([ 76279, 121830,  25867,  10097]),\n",
              " tensor([ 49564, 162779,  94973, 149749]),\n",
              " tensor([133716, 131980,  81522, 126235]),\n",
              " tensor([136485,  51277,  65090, 157222]),\n",
              " tensor([77117,  7824,  6635, 84352]),\n",
              " tensor([104114, 149407, 146947,  42708]),\n",
              " tensor([114260,  85277,  45585,  81859]),\n",
              " tensor([83171, 45715, 87986, 19036]),\n",
              " tensor([ 19822, 136396,  18010,  38897]),\n",
              " tensor([ 99445,   3997, 157243,  21139]),\n",
              " tensor([57221,  3939, 55259,  9776]),\n",
              " tensor([  1123, 119971,   7719, 144235]),\n",
              " tensor([ 79034,  56173,  96140, 127881]),\n",
              " tensor([117247,  38993, 139165,   7591]),\n",
              " tensor([155646,   4816, 102178, 135298]),\n",
              " tensor([111130,  65090,  65836,  58623]),\n",
              " tensor([101906,   9776, 107769, 121830]),\n",
              " tensor([80245, 31105, 45953, 19255]),\n",
              " tensor([143346, 122819,  76687,  45896]),\n",
              " tensor([ 51931,  96140, 130118, 133357]),\n",
              " tensor([ 64994,  53626,  17847, 154060]),\n",
              " tensor([ 81344,  60292, 114210, 126794]),\n",
              " tensor([ 85690,  23732, 161671, 124126]),\n",
              " tensor([ 46027, 139165,  46417,  13431]),\n",
              " tensor([  6268, 114896,  20379,  65910]),\n",
              " tensor([ 57221, 136498, 161622, 119310]),\n",
              " tensor([ 86582, 118954, 118954,  18353]),\n",
              " tensor([ 54584,  93834,  42382, 141875]),\n",
              " tensor([ 46906, 123427,  18031,  59329]),\n",
              " tensor([ 11841, 131953, 133319, 130118]),\n",
              " tensor([122833,   6268,  79814,  16171]),\n",
              " tensor([ 82698, 121830,  57940, 133333]),\n",
              " tensor([ 69182, 134238,    620, 161162]),\n",
              " tensor([81762, 76127, 95905, 45294]),\n",
              " tensor([ 64936,  39735,  64936, 129521]),\n",
              " tensor([133915, 109690, 148479,  35356]),\n",
              " tensor([128989, 157113, 118208, 157113]),\n",
              " tensor([ 81859, 120278,  12955,  99428]),\n",
              " tensor([ 85039, 138225,  47693,  51837]),\n",
              " tensor([ 82685, 123115,  31996,  70001]),\n",
              " tensor([107766, 128422,  45188, 101807]),\n",
              " tensor([93361, 60681, 46417, 44912]),\n",
              " tensor([  5574,  62055,  82770, 127709]),\n",
              " tensor([  8800,   2332, 146215, 161671]),\n",
              " tensor([ 16017, 143735,  42943,   9314]),\n",
              " tensor([ 49049,  94158, 130397,  88158]),\n",
              " tensor([ 45014, 139946,  57940,  32570]),\n",
              " tensor([ 65549,  93404, 143366,  87659]),\n",
              " tensor([ 50205,  53612, 104529,  87757]),\n",
              " tensor([ 87520, 146382, 160750,  21730]),\n",
              " tensor([ 48747, 134188, 125430,  77740]),\n",
              " tensor([ 95448, 107392,  64173, 161671]),\n",
              " tensor([157323, 118872,  72896, 118872]),\n",
              " tensor([143327,  81136,  54155,  60245]),\n",
              " tensor([82928, 48042, 93752, 26363]),\n",
              " tensor([162933,  27515,  23703, 106731]),\n",
              " tensor([134748, 107195,  47715,  85728]),\n",
              " tensor([106731, 104298, 104298, 133225]),\n",
              " tensor([ 18740, 134776,  20228,  89020]),\n",
              " tensor([156133, 111119,  19872, 116187]),\n",
              " tensor([136012, 102651,  99860, 139894]),\n",
              " tensor([ 96783,   3332, 105524, 118256]),\n",
              " tensor([ 75529, 125235, 104914,  16764]),\n",
              " tensor([  6793,  43273,  19274, 159176]),\n",
              " tensor([ 91677, 124590, 114502,   2332]),\n",
              " tensor([143317,  49228, 160700, 157543]),\n",
              " tensor([  1123, 162627, 106419,  39670]),\n",
              " tensor([146483,  61440,  94779, 131162]),\n",
              " tensor([146160,  91954, 124538, 142053]),\n",
              " tensor([82536, 55259, 56746, 74276]),\n",
              " tensor([143741,  99547, 140584, 122974]),\n",
              " tensor([ 47207, 143327, 113652,  54495]),\n",
              " tensor([ 35941,   1816, 117930, 134739]),\n",
              " tensor([38405, 98906, 99929, 24175]),\n",
              " tensor([157243,  55259,  83358,  24399]),\n",
              " tensor([154858, 110472, 114802, 134037]),\n",
              " tensor([ 51931, 157411,  46755,  12630]),\n",
              " tensor([ 29074, 130458,  37641,  23732]),\n",
              " tensor([ 64526, 138534, 158022,  62217]),\n",
              " tensor([ 81623,   7591,  92275, 161671]),\n",
              " tensor([120278, 103945,  53928, 133554]),\n",
              " tensor([159082,  42008,  84792,  51538]),\n",
              " tensor([ 12235, 157763,  98906, 144850]),\n",
              " tensor([ 88541, 157986,  11657, 147762]),\n",
              " tensor([ 84649,  45859, 161596,   6268]),\n",
              " tensor([80270, 10097, 24574, 37854]),\n",
              " tensor([104298,  31834,  95352,  83113]),\n",
              " tensor([154047, 124363, 149861,  10788]),\n",
              " tensor([ 13234,  88867, 143812, 100503]),\n",
              " tensor([64514, 94339, 75478, 57320]),\n",
              " tensor([ 78798, 161591, 161309,  45023]),\n",
              " tensor([157107, 103388, 143741, 103332]),\n",
              " tensor([ 32496, 143317, 139052,  76562]),\n",
              " tensor([148662,  16108, 149407,   9776]),\n",
              " tensor([121830,  88508,  34472, 159664]),\n",
              " tensor([ 70468,  99862, 118203, 161442]),\n",
              " tensor([151165, 138436, 110528, 127880]),\n",
              " tensor([116670,  48960, 159234, 143346]),\n",
              " tensor([114932,  20344,  80454,  85921]),\n",
              " tensor([127061,  61440,  36124, 161183]),\n",
              " tensor([ 4252, 21872, 69706, 98906]),\n",
              " tensor([ 65962, 107096,  55379, 103258]),\n",
              " tensor([75331, 28471, 70963, 32626]),\n",
              " tensor([ 97210, 104139,  89234,   6248]),\n",
              " tensor([ 17834, 113119,  82501,  17684]),\n",
              " tensor([122774,  24005, 128331, 150903]),\n",
              " tensor([19255, 16198, 36553, 53783]),\n",
              " tensor([134810,  44112,  46638,  52428]),\n",
              " tensor([146947,  27990,  38780,  10097]),\n",
              " tensor([110223,  93294,  45526, 160484]),\n",
              " tensor([ 56618, 143327, 148740, 127442]),\n",
              " tensor([ 20528,  78725,  62359, 119703]),\n",
              " tensor([ 35695, 130269, 125512, 111653]),\n",
              " tensor([112534,   8800, 152376, 141654]),\n",
              " tensor([148764,  79185, 128780,  82928]),\n",
              " tensor([110105,  10097,  17402, 162933]),\n",
              " tensor([ 7496, 60455, 47753, 49915]),\n",
              " tensor([42184, 64029, 81136, 82501]),\n",
              " tensor([ 36861,  90887, 116850, 130118]),\n",
              " tensor([150034,  57320,  73956,  54436]),\n",
              " tensor([  8904, 141553,  89590,  48875]),\n",
              " tensor([139894, 157217, 114012, 121830]),\n",
              " tensor([110168, 126794,  52669,  16764]),\n",
              " tensor([156494, 103589, 138365,  51010]),\n",
              " tensor([ 55287,  51748, 128855,  20866]),\n",
              " tensor([153900, 154013,  55000,  70829]),\n",
              " tensor([162933, 158535,   5789, 158535]),\n",
              " tensor([158535, 121830, 138229,  82685]),\n",
              " tensor([  4190, 121830, 103531, 128082]),\n",
              " tensor([ 79034, 107297,   9776,  27857]),\n",
              " tensor([144850,   6628,  16649, 120409]),\n",
              " tensor([142329,  37132,  29074,  37360]),\n",
              " tensor([ 80822, 104529,  62970, 120133]),\n",
              " tensor([ 81626,  19983, 105756,  16665]),\n",
              " tensor([ 12988,  82061, 138966,  28960]),\n",
              " tensor([ 19255, 106611, 147885, 127758]),\n",
              " tensor([ 99444,  98906, 105761,  55772]),\n",
              " tensor([ 34314, 161671, 160236, 117671]),\n",
              " tensor([ 79814, 157323,  32374, 125623]),\n",
              " tensor([ 79634,  98906, 161671,  48981]),\n",
              " tensor([ 46490, 161442, 134061,  68782]),\n",
              " tensor([ 94380, 160364,  30003, 126235]),\n",
              " tensor([ 89504,  79093,  45365, 150116]),\n",
              " tensor([  6268,  42008, 125164,   8098]),\n",
              " tensor([149206,  80270, 161671,  58678]),\n",
              " tensor([76205,  2876, 43149, 16665]),\n",
              " tensor([ 55259,  91704, 134204,  48960]),\n",
              " tensor([101043,  33886,  17834,  23732]),\n",
              " tensor([139858,   1158,  86622, 116185]),\n",
              " tensor([144645,  11657,  23557,  88259]),\n",
              " tensor([86959, 45342, 81633, 51147]),\n",
              " tensor([ 13962, 147013, 143741, 148764]),\n",
              " tensor([137198,  36148,  13234,  38183]),\n",
              " tensor([127709,  43380, 120278, 108222]),\n",
              " tensor([ 29319, 111247,  29296,  85395]),\n",
              " tensor([144850, 111363,  16771, 140090]),\n",
              " tensor([ 3939, 61602,  5793, 86574]),\n",
              " tensor([131096,  86274, 136179,  49564]),\n",
              " tensor([ 10544,   8980, 146813, 107884]),\n",
              " tensor([ 88867,  18275,  19120, 134928]),\n",
              " tensor([ 73951, 124381,  55842,  42346]),\n",
              " tensor([ 49757, 138359, 117253, 105519]),\n",
              " tensor([108961,  52933,  47702,  36855]),\n",
              " tensor([114977,  38889,  55259,  51937]),\n",
              " tensor([149390, 143741, 132793,  80897]),\n",
              " tensor([82698, 10097, 85723, 75936]),\n",
              " tensor([141700,  62060, 125664, 146483]),\n",
              " tensor([119989, 129065, 121830, 113373]),\n",
              " tensor([ 42462, 115596,  62055,  71353]),\n",
              " tensor([146149,  56966,  77252,  83875]),\n",
              " tensor([80270, 36166, 86582, 94425]),\n",
              " tensor([100075, 124551, 112534, 104298]),\n",
              " tensor([114821,  47695,  68630,  11093]),\n",
              " tensor([ 31935,  29319, 152784, 125497]),\n",
              " tensor([46477, 61089, 24648, 72896]),\n",
              " tensor([147847,   6425,  27770, 107056]),\n",
              " tensor([ 82698, 143735,  45936, 160236]),\n",
              " tensor([140999,   8108,  13431,  85039]),\n",
              " tensor([161671,  80270, 151419, 143690]),\n",
              " tensor([146300,  24427,  90613,  80822]),\n",
              " tensor([ 79607, 128726, 119317, 110513]),\n",
              " tensor([157113,  21872, 154096, 136634]),\n",
              " tensor([ 19780,  82713, 133530,  79546]),\n",
              " tensor([41497, 82685, 46308,  1215]),\n",
              " tensor([ 47884,  33131, 126853,  26448]),\n",
              " tensor([44873, 53928, 71204, 80822]),\n",
              " tensor([149407, 122774,  78491,  38765]),\n",
              " tensor([127709, 134578,    751,  24265]),\n",
              " tensor([135016,  80919,   1123,  60060]),\n",
              " tensor([124538,   2277,  25882, 163347]),\n",
              " tensor([149190,   2876,  58617, 117847]),\n",
              " tensor([  9119,  16651,  39266, 129689]),\n",
              " tensor([ 29267, 143741, 160055, 141910]),\n",
              " tensor([ 51016,  50211, 107787,  23545]),\n",
              " tensor([106189,  46257,  50960,  81522]),\n",
              " tensor([121830,  47562, 158184, 117809]),\n",
              " tensor([ 62554,  57757, 111867,  94339]),\n",
              " tensor([121830, 106151,   3991, 155753]),\n",
              " tensor([149407,  54894,  48568,  81136]),\n",
              " tensor([ 60681,  85039,  59415, 139014]),\n",
              " tensor([ 10097, 136530, 110313,  11841]),\n",
              " tensor([ 32108, 115070, 146947,  80922]),\n",
              " tensor([ 25867, 124538,  32358, 131494]),\n",
              " tensor([ 51566, 126794,  39806, 124538]),\n",
              " tensor([143327,  86582,  84767,  35352]),\n",
              " tensor([ 71355, 125154,  12270, 106017]),\n",
              " tensor([ 42909,  19941,  29001, 114678]),\n",
              " tensor([ 10097,  53281, 159283,  49509]),\n",
              " tensor([146382, 106611,  60245,  29410]),\n",
              " tensor([ 91622,  22717, 103131,  29410]),\n",
              " tensor([ 39273,   2876,   2876, 159716]),\n",
              " tensor([106495,  19780, 160300, 135298]),\n",
              " tensor([  7591, 114172, 125049,  23545]),\n",
              " tensor([ 83146, 108901,  53923, 144850]),\n",
              " tensor([89923, 79601, 94380, 91257]),\n",
              " tensor([33921, 64790, 95022, 90925]),\n",
              " tensor([ 95862, 158455,  61766,  17332]),\n",
              " tensor([109690, 158535,  55772,  56698]),\n",
              " tensor([  4068, 134529,  52036, 158339]),\n",
              " tensor([ 84767,  13104,  32358, 151525]),\n",
              " tensor([ 56600, 127263,  19120,  98519]),\n",
              " tensor([128682, 108795,  24192,  85723]),\n",
              " tensor([141396, 109093,  76776,  23411]),\n",
              " tensor([150116, 100503,   2517,  71029]),\n",
              " tensor([ 34998,  21942, 157538,  85840]),\n",
              " tensor([70806, 56337, 57946, 61961]),\n",
              " tensor([ 82937, 159892, 112534,  76776]),\n",
              " tensor([141396, 143317, 126794,  29724]),\n",
              " tensor([46308, 24574, 50960, 79925]),\n",
              " tensor([ 87636,  19255, 143477,  49564]),\n",
              " tensor([ 48951,   2517, 112496,  18503]),\n",
              " tensor([134366,  21139,  14918,  12169]),\n",
              " tensor([ 12612, 144850, 115620,  56009]),\n",
              " tensor([134640,  95903, 143921,  90287]),\n",
              " tensor([ 95854,  43338,  40284, 146947]),\n",
              " tensor([ 59806,  80897, 115947,  12630]),\n",
              " tensor([ 42237, 159664,  52428,  85039]),\n",
              " tensor([ 66178, 146577,  56800,  81021]),\n",
              " tensor([154864,  40343, 116770, 128374]),\n",
              " tensor([145866, 108909,  56009,  89073]),\n",
              " tensor([ 38007,  60245,   9462, 136597]),\n",
              " tensor([112584,   8074,  43344, 116688]),\n",
              " tensor([145931,  42631,  56345, 122593]),\n",
              " tensor([ 82698,  86972,  78936, 124588]),\n",
              " tensor([ 97386, 103589,  26447,  51158]),\n",
              " tensor([ 57692,  91707,  81136, 138926]),\n",
              " tensor([ 42909,  42632,  26327, 124378]),\n",
              " tensor([30175, 74885,  3645, 42238]),\n",
              " tensor([117809,  35243,  27857,  45585]),\n",
              " tensor([114489,  57948, 135827,  34227]),\n",
              " tensor([  8028,  32804, 127298, 121830]),\n",
              " tensor([  6628, 130118, 125664,  72020]),\n",
              " tensor([144850, 115522,  41048, 131857]),\n",
              " tensor([ 43793,   6990,   1123, 159664]),\n",
              " tensor([ 14941,  30137, 114805,  81762]),\n",
              " tensor([  7496,  62055, 127758, 135957]),\n",
              " tensor([131278,  64930,  48747,   6173]),\n",
              " tensor([61440, 25464, 22322, 46418]),\n",
              " tensor([ 88955,  58141,  79598, 131494]),\n",
              " tensor([137374,  45059, 140095,  53211]),\n",
              " tensor([11387, 10750, 74988, 74872]),\n",
              " tensor([ 47753, 120409,  15731,  24315]),\n",
              " tensor([161594, 138966,  51837, 138474]),\n",
              " tensor([98511, 85039, 10097, 92832]),\n",
              " tensor([55259, 73752, 19255, 90613]),\n",
              " tensor([132248,  58746, 160092, 143770]),\n",
              " tensor([77387, 55259, 82826, 80245]),\n",
              " tensor([ 61089,  15133, 131056, 129521]),\n",
              " tensor([ 41644,  23927, 113495, 102110]),\n",
              " tensor([ 77413,  66889,  54863, 125014]),\n",
              " tensor([121830,  48960,  52428, 119310]),\n",
              " tensor([120278,  50336, 144020, 134815]),\n",
              " tensor([ 42901, 162754,  55259, 129936]),\n",
              " tensor([75363, 29319, 24597, 16859]),\n",
              " tensor([  9776,  80270,  34714, 129648]),\n",
              " tensor([149407, 103506, 158022,  52439]),\n",
              " tensor([ 82675, 153476,   3839, 157405]),\n",
              " tensor([ 62970, 140267, 132414,  83579]),\n",
              " tensor([ 42672,  79233,  27867, 149278]),\n",
              " tensor([ 98906, 112615,  92701,  92614]),\n",
              " tensor([ 27879, 141993, 125235,  82675]),\n",
              " tensor([ 26631, 158535,  60681,  45824]),\n",
              " tensor([ 50632,  42140,  79192, 113311]),\n",
              " tensor([121830,  85039,  82892,  19255]),\n",
              " tensor([62970, 24169, 51167, 97361]),\n",
              " tensor([129648,  29255,  51735,   3997]),\n",
              " tensor([143741,  25198, 158535, 118852]),\n",
              " tensor([ 25376, 145520,  81815, 104479]),\n",
              " tensor([118954,  37368, 123491,  40770]),\n",
              " tensor([121290,  48747, 153827,  15966]),\n",
              " tensor([99488, 60634, 83276, 20284]),\n",
              " tensor([25722, 46417, 30240, 63815]),\n",
              " tensor([  2332,  16171,  18729, 160300]),\n",
              " tensor([108976,  57012,  71362, 109617]),\n",
              " tensor([ 72018, 127709,  96140, 102935]),\n",
              " tensor([ 47054,  29074,  12497, 146149]),\n",
              " tensor([ 30628,  63591,  77243, 133417]),\n",
              " tensor([82961, 24673, 69595, 85039]),\n",
              " tensor([114260,  43149,  85039,  94145]),\n",
              " tensor([79672, 37097, 19529, 37097]),\n",
              " tensor([ 77387,  76451, 109221, 125664]),\n",
              " tensor([127320,  15317, 104811,  97860]),\n",
              " tensor([100915,  47280, 157283, 124126]),\n",
              " tensor([ 93616,  27990,  39735, 134908]),\n",
              " tensor([115948,  61406, 156123, 134645]),\n",
              " tensor([132638, 127959,  49362, 140337]),\n",
              " tensor([25722, 56966, 79869, 87989]),\n",
              " tensor([116765,  29872,  45346,   4636]),\n",
              " tensor([ 29319,  25718,  59715, 151684]),\n",
              " tensor([11118, 85930, 60341, 80245]),\n",
              " tensor([ 40142, 111960, 162475, 124469]),\n",
              " tensor([ 77747, 127442,  45180,  37635]),\n",
              " tensor([  8028, 109759, 146018,  82685]),\n",
              " tensor([ 21295,  71985,  55259, 154015]),\n",
              " tensor([143346,  21542,  16602,  10097]),\n",
              " tensor([135915,  24526,  99045,  54584]),\n",
              " tensor([ 86991, 132414,  70806,  98906]),\n",
              " tensor([161420,  62970,  57221,  91312]),\n",
              " tensor([ 32318,  35166,  98906, 163366]),\n",
              " tensor([135138,  93077, 135138, 130568]),\n",
              " tensor([136234, 114352,  16171, 153900]),\n",
              " tensor([146947,  81762,  47054,   3068]),\n",
              " tensor([ 94538,  91257, 127298,  89870]),\n",
              " tensor([65549, 59490, 55966, 78330]),\n",
              " tensor([106782, 152253,   4102, 137678]),\n",
              " tensor([153206,  27475, 143921,  87788]),\n",
              " tensor([157222,  45787,  47241,  29074]),\n",
              " tensor([79093,  8139, 38341, 52888]),\n",
              " tensor([114038, 101031, 134625,  18754]),\n",
              " tensor([132003,  77387,  47884, 159664]),\n",
              " tensor([ 46826,  76355, 135985, 125226]),\n",
              " tensor([158737, 146018, 142753,  49362]),\n",
              " tensor([ 23557, 133241, 134218,  70726]),\n",
              " tensor([131700,  79093,  17914, 149861]),\n",
              " tensor([26222, 79814, 46663, 27052]),\n",
              " tensor([ 56927, 124544,   1123, 136119]),\n",
              " tensor([ 80809, 143346,  49509,  82685]),\n",
              " tensor([ 74999, 107824,  61682,  59119]),\n",
              " tensor([161671,  51302,  74872,  61440]),\n",
              " tensor([ 88524, 133241, 146286, 127308]),\n",
              " tensor([48960, 14800, 29996, 14063]),\n",
              " tensor([ 10727,  37854, 136670,  52268]),\n",
              " tensor([ 41700, 103207, 115456,  42245]),\n",
              " tensor([120278,  28935, 111203, 143921]),\n",
              " tensor([105648,  91707,   9822,  41985]),\n",
              " tensor([123852,  38899,  60770, 135750]),\n",
              " tensor([10532, 21323, 48568, 56698]),\n",
              " tensor([ 51167,  40512, 157763, 158244]),\n",
              " tensor([ 98906,  31283, 114839,  68154]),\n",
              " tensor([111213, 121830, 134204,  79185]),\n",
              " tensor([135699,  71039,  71238,   3441]),\n",
              " tensor([ 94339,  80270,  55259, 127709]),\n",
              " tensor([ 16677, 139115, 154711,  71402]),\n",
              " tensor([  6628, 149407, 161130,  25961]),\n",
              " tensor([ 59715, 157411, 124588, 106611]),\n",
              " tensor([150034,  80822,  55174,  93805]),\n",
              " tensor([ 96169,  32496, 101941,  32743]),\n",
              " tensor([  2914, 108433, 113705,  74784]),\n",
              " tensor([ 15382, 161671,  78909,   7172]),\n",
              " tensor([ 11902,  57940,  46242, 116214]),\n",
              " tensor([156067,  36861, 133368, 114839]),\n",
              " tensor([ 91737,  47693, 135298, 121830]),\n",
              " tensor([ 53281, 156375,  71460, 159508]),\n",
              " tensor([137364,  60702, 161671, 117195]),\n",
              " tensor([ 86307, 108637, 117171,  45953]),\n",
              " tensor([105761, 144850,  82685,  81136]),\n",
              " tensor([157405, 157405,  47054,  43149]),\n",
              " tensor([139858,  40142, 140337,  47054]),\n",
              " tensor([ 96140,  65794, 121830,  24085]),\n",
              " tensor([141577,  29298,  28733, 123335]),\n",
              " tensor([159953, 110528, 115069,  91519]),\n",
              " tensor([15485, 55259, 16283, 61996]),\n",
              " tensor([159870, 161211,  11892,  80245]),\n",
              " tensor([131953,  85039, 134509,   9776]),\n",
              " tensor([ 16171, 146192,  51135,  57221]),\n",
              " tensor([ 44318,  29074, 108961,  15954]),\n",
              " tensor([76092,  8108, 63989, 59806]),\n",
              " tensor([  6268,  12604, 121830,  16075]),\n",
              " tensor([127885, 122551, 101339, 107463]),\n",
              " tensor([ 46417, 125512,  82685,  64836]),\n",
              " tensor([ 40709,  73820,  65090, 128331]),\n",
              " tensor([ 46623,   9258, 103945,  49362]),\n",
              " tensor([ 17701, 103605,  86959,  46102]),\n",
              " tensor([85440,  1123, 78746, 17508]),\n",
              " tensor([ 94779,  77402,  53612, 124232]),\n",
              " tensor([ 26170, 125235,  35158, 108637]),\n",
              " tensor([104298,  56746,  40142, 124538]),\n",
              " tensor([ 32492, 125337,  24568,  55287]),\n",
              " tensor([  5707,  81136, 127709,  91610]),\n",
              " tensor([ 18214,  70806, 131632,  94412]),\n",
              " tensor([103589, 133251,  14479, 129957]),\n",
              " tensor([161228,  20379,  13104,  79034]),\n",
              " tensor([143327,  81136,  40223, 149861]),\n",
              " tensor([104565,    847,  65549,  12318]),\n",
              " tensor([138307,  34342, 109931, 139491]),\n",
              " tensor([133777, 136527,  80822, 107797]),\n",
              " tensor([82675,  7591, 48747, 85453]),\n",
              " tensor([124538,  17077, 157960, 121355]),\n",
              " tensor([ 98887, 120612, 133342, 107942]),\n",
              " tensor([160700, 109679, 137514, 117885]),\n",
              " tensor([128082,   9033,  81136,  82200]),\n",
              " tensor([120278,  94380, 113671,  99826]),\n",
              " tensor([127881,  61753, 121830, 133251]),\n",
              " tensor([ 47884,  77243, 157797, 121830]),\n",
              " tensor([29074, 88803, 87659, 97508]),\n",
              " tensor([ 84350, 124330,  96140, 125164]),\n",
              " tensor([24338, 56600, 47834, 21730]),\n",
              " tensor([ 53860, 124730,  60338,   1323]),\n",
              " tensor([ 46458,  34746, 151597,   5468]),\n",
              " tensor([133636,   8108, 161671, 154015]),\n",
              " tensor([62459, 77990, 46838, 81351]),\n",
              " tensor([ 85039, 135686, 103358,  37854]),\n",
              " tensor([86582, 55259, 83875,  7591]),\n",
              " tensor([ 7591,  7591, 98906,  5707]),\n",
              " tensor([  9776,   4252, 115670,  32060]),\n",
              " tensor([138229, 161671, 122819, 103061]),\n",
              " tensor([ 30117,  86574, 143916, 134572]),\n",
              " tensor([  1519, 144916, 122819, 142930]),\n",
              " tensor([ 1158,   271, 62970, 91515]),\n",
              " tensor([ 23577,   2876, 135298, 101031]),\n",
              " tensor([51970, 64936, 84777, 46308]),\n",
              " tensor([114802,  25682,  59486, 106731]),\n",
              " tensor([125391, 156411, 156411,  96282]),\n",
              " tensor([ 42636,  33674,  23770, 125577]),\n",
              " tensor([121256, 157243,  96100,  19255]),\n",
              " tensor([ 81136,  60889, 147093, 116751]),\n",
              " tensor([119088, 146684,  89598, 146382]),\n",
              " tensor([60871, 32042, 81136, 11687]),\n",
              " tensor([ 50586,  57462, 118963, 146661]),\n",
              " tensor([ 10269,  87938,  81762, 139965]),\n",
              " tensor([ 81136,  92558,  64302, 146382]),\n",
              " tensor([121830,  13962,  94380, 163263]),\n",
              " tensor([  9776,  58133,  58133, 149123]),\n",
              " tensor([   774, 110106, 110319,  32318]),\n",
              " tensor([162747,  48992, 157243, 137290]),\n",
              " tensor([ 82501, 125664,  18513,  18353]),\n",
              " tensor([ 65960,  10665, 162779, 147150]),\n",
              " tensor([ 79185, 117146, 105582, 116703]),\n",
              " tensor([43149,  8901, 20031, 18736]),\n",
              " tensor([ 29603, 101947,  64173,  79034]),\n",
              " tensor([138329,   2604,  87659, 125664]),\n",
              " tensor([62217, 81762,  5623, 39320]),\n",
              " tensor([ 62055,  29279,  97860, 138542]),\n",
              " tensor([115555,  71048,  64935,  34246]),\n",
              " tensor([149861, 144850,  52286,  65938]),\n",
              " tensor([105200, 160683,  98511,  47230]),\n",
              " tensor([ 89020,  23787,  21968, 125714]),\n",
              " tensor([123491, 149407, 107766, 129244]),\n",
              " tensor([85928, 21502, 51931, 25783]),\n",
              " tensor([  8339,  31904, 137772,  50177]),\n",
              " tensor([125803,   6804, 137329,   4890]),\n",
              " tensor([137374, 114874, 140813,  55836]),\n",
              " tensor([107931,  40551, 109405,  35166]),\n",
              " tensor([79869, 87989, 83718, 57992]),\n",
              " tensor([ 21872, 106729, 144850,  76127]),\n",
              " tensor([130269, 127593,   5707, 156367]),\n",
              " tensor([71360, 42672, 79188, 44873]),\n",
              " tensor([ 28681,  70426,  82501, 114260]),\n",
              " tensor([118954, 103488, 122131,  39130]),\n",
              " tensor([114932,  60634,  10055, 123837]),\n",
              " tensor([ 90021, 110890,   9458,  34746]),\n",
              " tensor([148770, 124981, 157405, 154096]),\n",
              " tensor([ 79228,  49362, 124706, 119394]),\n",
              " tensor([125164, 117237, 121830,   2716]),\n",
              " tensor([ 47054, 109633,  82937,  81762]),\n",
              " tensor([132234, 141396,  28890, 114680]),\n",
              " tensor([  4068, 149422,  88085,  44065]),\n",
              " tensor([  7092, 136924, 128482,  78634]),\n",
              " tensor([135707, 134692,  84767,  10097]),\n",
              " tensor([124575, 159892,  94380,  20391]),\n",
              " tensor([ 89581,  89234, 161130,  77990]),\n",
              " tensor([ 96017, 146947,  29629,  99434]),\n",
              " tensor([ 45805,  84792, 143735, 148770]),\n",
              " tensor([127327,  79686, 118203, 132120]),\n",
              " tensor([157291, 123067,  90994,  12202]),\n",
              " tensor([153727, 103054, 137697,  61766]),\n",
              " tensor([144321, 112534, 139563,  52888]),\n",
              " tensor([128416,  52847,  12169,  50172]),\n",
              " tensor([76776, 80822, 60634, 81859]),\n",
              " tensor([ 25961, 131494,  44989, 158339]),\n",
              " tensor([ 23732,  81626, 107890,  35934]),\n",
              " tensor([ 47054, 132120,  57433,  29319]),\n",
              " tensor([56600, 66975, 77387, 44989]),\n",
              " tensor([ 93361,  55772,  98906, 141962]),\n",
              " tensor([130756,  13234,  47729, 158428]),\n",
              " tensor([ 89802,  79601, 154554,  46689]),\n",
              " tensor([24611, 57462, 46462, 77740]),\n",
              " tensor([ 93425,  10437, 116996,  28101]),\n",
              " tensor([57418, 85039, 12270, 56009]),\n",
              " tensor([138410,  57021,  46623,  40483]),\n",
              " tensor([158428, 108637,  16328, 156367]),\n",
              " tensor([118954,  49622,  93724, 114977]),\n",
              " tensor([ 37604, 121256,  81623, 158535]),\n",
              " tensor([61440, 12404, 84767,  6619]),\n",
              " tensor([128374,   4880, 109403,  35916]),\n",
              " tensor([158535, 108330,  28571,  80716]),\n",
              " tensor([127881,  33061,  86538,  57122]),\n",
              " tensor([ 11886, 103054, 130300,  85966]),\n",
              " tensor([143317, 104139,  18190,   4463]),\n",
              " tensor([ 10979, 135298,  10097,   9776]),\n",
              " tensor([  9061, 108942,  69299, 158535]),\n",
              " tensor([89799, 72234, 82223, 58358]),\n",
              " tensor([122774,  54512, 120278,  92859]),\n",
              " tensor([ 81136,  25353, 134204,  76205]),\n",
              " tensor([ 94101, 153857, 107195, 120278]),\n",
              " tensor([118301,   8444,  54436,  82536]),\n",
              " tensor([ 19255, 112335, 139858, 147518]),\n",
              " tensor([144850,  86959, 103106, 154013]),\n",
              " tensor([ 14231, 143317, 103531,   8074]),\n",
              " tensor([98906, 71360,  2025, 29290]),\n",
              " tensor([  1323, 116747, 144801, 107884]),\n",
              " tensor([ 86980, 103054, 104813,  56927]),\n",
              " tensor([ 76205, 124423, 121380,  51538]),\n",
              " tensor([133433, 102311, 121718,  85453]),\n",
              " tensor([ 99444, 100503,  93396,   4252]),\n",
              " tensor([156063,  75592,  61743,  96140]),\n",
              " tensor([103488,   1603,  80270,  25694]),\n",
              " tensor([136386,  12543,  52703,  81762]),\n",
              " tensor([128308,  49362,  93616,  93361]),\n",
              " tensor([129926, 130268,  46535,  81522]),\n",
              " tensor([ 89867, 152370,  27550,  17070]),\n",
              " tensor([106813,  34455, 157405, 127298]),\n",
              " tensor([77387, 76776, 40906, 60865]),\n",
              " tensor([ 61440,  37854, 159886,  46308]),\n",
              " tensor([40695,  4252, 19979, 64036]),\n",
              " tensor([  9776, 131494,  39060, 162967]),\n",
              " tensor([ 8371, 64268, 86582, 64268]),\n",
              " tensor([106782,   1131, 106731,  19750]),\n",
              " tensor([12202, 81136, 80245, 25867]),\n",
              " tensor([ 1066, 77413, 99859, 68916]),\n",
              " tensor([159283,  46477, 109504,  86991]),\n",
              " tensor([148764, 122737,  34748,  51167]),\n",
              " tensor([72904, 99444, 58623, 88048]),\n",
              " tensor([ 7591, 12058, 44873, 11886]),\n",
              " tensor([104529, 161519,  80454, 122774]),\n",
              " tensor([ 30591, 162779, 110291,  11221]),\n",
              " tensor([137290,  77252,  47884,  62235]),\n",
              " tensor([ 67339, 122729,  69957, 140943]),\n",
              " tensor([149656,  52028,  47909, 130764]),\n",
              " tensor([143770, 118257,  94432,  77387]),\n",
              " tensor([161162,  21723,  74217,  11886]),\n",
              " tensor([33544,  7507, 38075, 74276]),\n",
              " tensor([12192, 10795, 55259, 11902]),\n",
              " tensor([35950,  2513, 85453, 44873]),\n",
              " tensor([ 51931,  23285, 153701, 131218]),\n",
              " tensor([32198, 21542, 42672, 14451]),\n",
              " tensor([ 55462, 147863,  57271,  81859]),\n",
              " tensor([ 32108,  81351, 115698,  47834]),\n",
              " tensor([ 25285, 130909,  98331,  84067]),\n",
              " tensor([123115,  14063,  36181,  44516]),\n",
              " tensor([149438, 131494,  49564, 143812]),\n",
              " tensor([108961,  86417,   6756,  19456]),\n",
              " tensor([116880, 121830, 104298, 110268]),\n",
              " tensor([ 55259, 132234, 139150,  34249]),\n",
              " tensor([158256,  92446, 138488, 143735]),\n",
              " tensor([113652,  25888,  57221,  84767]),\n",
              " tensor([ 39718,  98511, 135725,    445]),\n",
              " tensor([109756, 128331,  94380,  19919]),\n",
              " tensor([46613, 85039, 77387, 56746]),\n",
              " tensor([ 11841, 137290,  85719,  99434]),\n",
              " tensor([54863, 97322, 92614, 82928]),\n",
              " tensor([121830,  81005, 109759, 107766]),\n",
              " tensor([133357,  89504,  29074, 124538]),\n",
              " tensor([ 98906, 110051,  94223,  38515]),\n",
              " tensor([ 60941,  55827,  83792, 124288]),\n",
              " tensor([ 11657, 133906,  28500,   8792]),\n",
              " tensor([ 60601, 154346, 143317, 131494]),\n",
              " tensor([ 24601, 161671, 131980,   5407]),\n",
              " tensor([  4177, 135298,  84231,  96614]),\n",
              " tensor([  9776, 113026,  98906, 149861]),\n",
              " tensor([86993, 98511, 93805, 24623]),\n",
              " tensor([134529,  71939, 132120,  47054]),\n",
              " tensor([ 37742,  45023,  86959, 141396]),\n",
              " tensor([ 98906,  76921, 115069, 143741]),\n",
              " tensor([ 80121,  28392, 160236,  29290]),\n",
              " tensor([ 13947, 104990,  81351,  95337]),\n",
              " tensor([70806, 57948, 83713, 32773]),\n",
              " tensor([153752,  52888,  72087,  96749]),\n",
              " tensor([85453, 29093, 98906, 47057]),\n",
              " tensor([115070, 138229, 161457, 128252]),\n",
              " tensor([153566, 116808,  85039,  52686]),\n",
              " tensor([105651,  44778,  73564,  80822]),\n",
              " tensor([ 57808, 135635, 153832, 154950]),\n",
              " tensor([108644, 143346,  35386,  27721]),\n",
              " tensor([147885, 124604, 157243,  70950]),\n",
              " tensor([ 93077,  92824, 106731,  30105]),\n",
              " tensor([56746, 45824, 30071, 10097]),\n",
              " tensor([ 18236,   4058, 122548,  21542]),\n",
              " tensor([23891, 52866, 11657, 85039]),\n",
              " tensor([113763,  42819,  46308, 158737]),\n",
              " tensor([115281,  91839,  86726, 118761]),\n",
              " tensor([158422,  54863,  71206,  86994]),\n",
              " tensor([ 44902, 138229,  36712,  20379]),\n",
              " tensor([157217, 136338,  46477, 157217]),\n",
              " tensor([  4252, 124600,  80253, 149861]),\n",
              " tensor([ 50047, 144850,  17831, 127061]),\n",
              " tensor([ 35928, 126156,  46638,  62217]),\n",
              " tensor([20194, 89094, 44447, 61710]),\n",
              " tensor([161596, 157107,  77338,  37854]),\n",
              " tensor([160748,  32318, 155257,  10260]),\n",
              " tensor([ 44873,  13234,  89544, 124590]),\n",
              " tensor([121830,  86582,  50389, 121830]),\n",
              " tensor([ 82961, 143327, 114680, 150607]),\n",
              " tensor([ 87201,  62217, 122774, 137325]),\n",
              " tensor([156069,   6292,  98511,  85039]),\n",
              " tensor([ 61440,  74254,  46308, 116751]),\n",
              " tensor([53281, 29298, 28068, 87906]),\n",
              " tensor([103054, 144850,  67961, 117427]),\n",
              " tensor([106978, 138092,  54584, 160386]),\n",
              " tensor([  7440,  87659, 122819,  94339]),\n",
              " tensor([ 98906,  62126, 161191, 161671]),\n",
              " tensor([ 79672, 113373,  69982,   4068]),\n",
              " tensor([121830,  38190,  65937,  91954]),\n",
              " tensor([108253,  43380, 116751,  91501]),\n",
              " tensor([10097, 27449, 61440, 88867]),\n",
              " tensor([38456,  2332, 88719, 71601]),\n",
              " tensor([148311,  54243,  90613,  48960]),\n",
              " tensor([ 98906, 143921,  24735,  15033]),\n",
              " tensor([120295,  56927,  48981,   5707]),\n",
              " tensor([   851,  34972,  36339, 131087]),\n",
              " tensor([14280, 61682, 44198,  6608]),\n",
              " tensor([127230,   2815,  77348,  74963]),\n",
              " tensor([ 87072, 105565, 154013, 137772]),\n",
              " tensor([143346,   6268,  56966, 161671]),\n",
              " tensor([123809, 141959,  71096,  53626]),\n",
              " tensor([103506,    641, 105349,  92614]),\n",
              " tensor([ 49362, 155888,  60036,  99444]),\n",
              " tensor([114932,  68135,  29872,  38654]),\n",
              " tensor([ 61766, 132081, 102738, 163554]),\n",
              " tensor([ 60205,  54863,  52550, 136187]),\n",
              " tensor([112534,  10150, 132120,  24092]),\n",
              " tensor([108961, 162967, 158022,  26868]),\n",
              " tensor([  8323, 127442,  49345, 157213]),\n",
              " tensor([ 10479,  70950, 127885,  72565]),\n",
              " tensor([162779,  82536,  98982, 139894]),\n",
              " tensor([160055,   5468,  40142, 131700]),\n",
              " tensor([  650, 33321, 19804,  5457]),\n",
              " tensor([121830, 103506, 144797,  55259]),\n",
              " tensor([56927, 56927, 40485, 89234]),\n",
              " tensor([ 40695, 158207, 122568,  38763]),\n",
              " tensor([ 11892, 113495,  60137,  29074]),\n",
              " tensor([ 89577, 118401,   7591,   6268]),\n",
              " tensor([36660, 11657,  1123, 46417]),\n",
              " tensor([134412, 143735,  46477, 149390]),\n",
              " tensor([136386, 131998, 146192,  79541]),\n",
              " tensor([ 67961,  66846,  86313, 161671]),\n",
              " tensor([ 85287,  13571, 103207,  54380]),\n",
              " tensor([25887, 73653, 32198, 50475]),\n",
              " tensor([ 92446,  47884, 151742,  80743]),\n",
              " tensor([115192, 134625,  88303, 124600]),\n",
              " tensor([ 89020, 104355, 113794, 114680]),\n",
              " tensor([61595, 50389, 14606, 99388]),\n",
              " tensor([  6292, 161442,   5196,   5789]),\n",
              " tensor([ 60060, 138170, 135989,  71805]),\n",
              " tensor([77387, 18854, 56305, 26170]),\n",
              " tensor([143735,  66380,  56779,  21720]),\n",
              " tensor([ 51931, 143366, 124604,  29101]),\n",
              " tensor([ 77387,  77413,  96140, 125512]),\n",
              " tensor([132801, 158339, 104132, 127373]),\n",
              " tensor([ 84767,  95048, 162747,  76344]),\n",
              " tensor([ 11221,   4668,  64173, 138220]),\n",
              " tensor([  1188, 149861, 104565,  32957]),\n",
              " tensor([113759,  31520,  13958,  43495]),\n",
              " tensor([ 46308, 123858,  46417, 115698]),\n",
              " tensor([ 84767,  54584, 160700, 132523]),\n",
              " tensor([139858, 132120,  93807,   7496]),\n",
              " tensor([ 80953, 162779,  48981,  23067]),\n",
              " tensor([124135,  16422, 158869, 100503]),\n",
              " tensor([42672, 60060, 48599, 37451]),\n",
              " tensor([  1822,  91589, 148744,  77387]),\n",
              " tensor([  299, 65444, 79601, 81623]),\n",
              " tensor([ 27085, 159605,  16171, 118954]),\n",
              " tensor([ 56966, 161214,  81136,  15118]),\n",
              " tensor([ 17452,  73936, 146382,  22312]),\n",
              " tensor([ 46417,  46417,  56746, 131494]),\n",
              " tensor([ 84231,  77528, 154015,  93361]),\n",
              " tensor([ 57212, 131520, 109005, 128979]),\n",
              " tensor([157539, 132793, 103258,  29290]),\n",
              " tensor([122167, 161191, 135755,  81701]),\n",
              " tensor([ 87557,  43909, 127204,  48992]),\n",
              " tensor([157291,  28512,  81136,  81543]),\n",
              " tensor([161420,  35382,  81522, 148770]),\n",
              " tensor([ 11188,  84452,  64044, 104153]),\n",
              " tensor([55259, 56966, 86946, 53352]),\n",
              " tensor([116814,  47301,  59806,  61440]),\n",
              " tensor([ 93425, 131548, 146587,  73936]),\n",
              " tensor([134366,  60681,    882, 134480]),\n",
              " tensor([142421,  62644,  25867,  89504]),\n",
              " tensor([51931, 82698, 17332, 46308]),\n",
              " tensor([ 77387,  85039, 121830,  79713]),\n",
              " tensor([ 61600,   6292,  76680, 133790]),\n",
              " tensor([155343,  33033,  92494, 117195]),\n",
              " tensor([57221, 10097, 48568, 22259]),\n",
              " tensor([ 99831,  17847, 162754, 136527]),\n",
              " tensor([120278, 131857, 108355,  98906]),\n",
              " tensor([125497,  78909, 157323,  79601]),\n",
              " tensor([121830,   4020, 135985, 113398]),\n",
              " tensor([ 80245, 141553,  11886, 131494]),\n",
              " tensor([121830,  61619, 139965,  80809]),\n",
              " tensor([ 81136, 124538,  55827,  81136]),\n",
              " tensor([81351, 84767, 61876, 81136]),\n",
              " tensor([161547,  81136,  10919,  57831]),\n",
              " tensor([139801,  54949,  98368,  13377]),\n",
              " tensor([77387, 81136, 86075, 66364]),\n",
              " tensor([17818, 80822, 86991, 22649]),\n",
              " tensor([146316,  26452, 145931,  82357]),\n",
              " tensor([134599,  85039,  84749,  54863]),\n",
              " tensor([ 28415, 113448,  69158,  97860]),\n",
              " tensor([ 96749,  80313, 121445,  49826]),\n",
              " tensor([ 60604, 158737,  43311,  12169]),\n",
              " tensor([74834, 80270, 82675, 64351]),\n",
              " tensor([ 36601,  81619, 158455,  27965]),\n",
              " tensor([ 51837,  63587, 116808,   6268]),\n",
              " tensor([ 23787,  11841,   4636, 135995]),\n",
              " tensor([122520, 114102,  40036,  58355]),\n",
              " tensor([ 76680, 149407, 124243, 132513]),\n",
              " tensor([ 70154,  51802,  98511, 161442]),\n",
              " tensor([32833, 49564, 86574, 35356]),\n",
              " tensor([ 76451, 135130, 105831,  52963]),\n",
              " tensor([ 14298, 149407, 161671,  81136]),\n",
              " tensor([37742, 29074, 24092,  1123]),\n",
              " tensor([126156,  16977,  94339, 119294]),\n",
              " tensor([ 81267,   6709,  13025, 161671]),\n",
              " tensor([ 34569, 163347, 161162,  47575]),\n",
              " tensor([84749, 84749, 12604, 33418]),\n",
              " tensor([111580,  93077, 139858,  19955]),\n",
              " tensor([  4252, 157411,  87659, 121830]),\n",
              " tensor([  5407, 143327,  83066,  59291]),\n",
              " tensor([29319, 85039, 29074, 27525]),\n",
              " tensor([52888, 42672, 72800, 87843]),\n",
              " tensor([143317,  51837, 144916,  93616]),\n",
              " tensor([122729,  16947,  69711,  95623]),\n",
              " tensor([113516, 107766,  12955,  15133]),\n",
              " tensor([133241, 113409,  16941,  48741]),\n",
              " tensor([46308, 93252, 62649, 56966]),\n",
              " tensor([ 59733,  79278, 124378,  24038]),\n",
              " tensor([ 38974, 129521, 119797,  19822]),\n",
              " tensor([117824,  99860, 106965, 123837]),\n",
              " tensor([ 92522, 158535,   7008, 148479]),\n",
              " tensor([ 90994,   6297, 135774,  94380]),\n",
              " tensor([157763,  24587,  91707,  26301]),\n",
              " tensor([ 89455,  82922, 109782, 116932]),\n",
              " tensor([90603, 86582, 13104, 76205]),\n",
              " tensor([114210, 124581,  68813, 130945]),\n",
              " tensor([32296, 30184, 41076, 55974]),\n",
              " tensor([ 61492, 112496,  32093,  51010]),\n",
              " tensor([131109,  61440, 149422, 149422]),\n",
              " tensor([ 94538,  72896,  96340, 123427]),\n",
              " tensor([114069,  51167,  85054, 136575]),\n",
              " tensor([ 72028, 126260,  62226, 140819]),\n",
              " tensor([155713, 129778,  99623,  51931]),\n",
              " tensor([141396, 161671, 160236, 114012]),\n",
              " tensor([ 16845,  85039, 128780,  19780]),\n",
              " tensor([135686,  98906,  34352, 129689]),\n",
              " tensor([113373, 138418, 106419,  49892]),\n",
              " tensor([ 47054,  16240,  13736, 110528]),\n",
              " tensor([ 30105, 127399,  81626, 143307]),\n",
              " tensor([146160,  44830,  29319, 117671]),\n",
              " tensor([ 15529,  75035,  97257, 161420]),\n",
              " tensor([ 34473, 108633,  15382,  86959]),\n",
              " tensor([30827, 89020, 93903, 70110]),\n",
              " tensor([  3991,  98906,  55974, 114502]),\n",
              " tensor([120131, 122774,  79713, 118954]),\n",
              " tensor([ 8123, 70132, 56966, 32570]),\n",
              " tensor([106965,  27857, 161162,  40142]),\n",
              " tensor([102206,  70828,  29074, 104677]),\n",
              " tensor([ 24719, 106982, 116489, 146947]),\n",
              " tensor([135915,  21730,  79814, 134218]),\n",
              " tensor([ 99859, 117920, 148650, 104396]),\n",
              " tensor([108898,  98511,  49493,  87015]),\n",
              " tensor([29583, 58358, 49493, 29890]),\n",
              " tensor([100441, 159206,  18705, 119173]),\n",
              " tensor([116518,  60245, 103823, 147237]),\n",
              " tensor([143346, 131494,  85620,  19822]),\n",
              " tensor([ 22936, 119620, 131363,  70041]),\n",
              " tensor([56746, 93077, 60347,  6756]),\n",
              " tensor([ 55259,  40512, 141289,  45480]),\n",
              " tensor([ 44989,  54890, 163347, 104298]),\n",
              " tensor([103506,  49915,  27857,  77387]),\n",
              " tensor([ 95750,  29319, 111213,  29074]),\n",
              " tensor([ 64510, 114810, 144850,  56746]),\n",
              " tensor([ 47859,  19255, 156367,  13431]),\n",
              " tensor([157538,  64514, 128979, 121830]),\n",
              " tensor([143346,  86574, 107769,  51720]),\n",
              " tensor([ 70287, 158184,  13104,  34705]),\n",
              " tensor([147225,  49904,  26675, 120278]),\n",
              " tensor([ 45067,  83149, 134509,  55990]),\n",
              " tensor([ 75177,  82928, 115069, 161671]),\n",
              " tensor([ 34745,  45180, 156367,  12270]),\n",
              " tensor([156306, 154013, 137290,  77387]),\n",
              " tensor([132788,  44902,  23891, 161671]),\n",
              " tensor([ 46418, 161130,   3252, 131494]),\n",
              " tensor([ 63049,  46188,  77252, 158535]),\n",
              " tensor([121830,  12010,  79483,  57831]),\n",
              " tensor([ 77252, 163349,  68559,  16171]),\n",
              " tensor([ 51880, 131679,  95954,  97443]),\n",
              " tensor([87659, 84395, 40109, 82843]),\n",
              " tensor([102205, 141688, 160288,  82685]),\n",
              " tensor([ 91127, 138220,   2952,  18742]),\n",
              " tensor([130118, 133667, 122774,  38397]),\n",
              " tensor([159082,  84231,  79188, 137290]),\n",
              " tensor([155486,  35356,  88158,  22046]),\n",
              " tensor([ 36250, 145176, 160191,  61440]),\n",
              " tensor([141335,  43069,  24587,  58875]),\n",
              " tensor([ 10097,  98906,  79844, 159953]),\n",
              " tensor([157763, 143346, 161671,  89234]),\n",
              " tensor([ 93728,  71980,  48981, 148740]),\n",
              " tensor([ 50108,  88158, 114352,  51629]),\n",
              " tensor([114977,  93728,  81136,  55259]),\n",
              " tensor([ 48981, 158022,  44569,  78221]),\n",
              " tensor([ 13810,  11892,  14280, 160055]),\n",
              " tensor([143735, 135298, 127123,  16651]),\n",
              " tensor([147172, 123719,  53889,  23787]),\n",
              " tensor([ 56345, 157291,  21139,  33033]),\n",
              " tensor([ 65090,  51931,  57516, 159150]),\n",
              " tensor([128729, 142053,   1600, 108634]),\n",
              " tensor([ 81136, 129198,  94015, 139858]),\n",
              " tensor([115280,  42357,  60735,  26744]),\n",
              " tensor([152376,  97838,  98906,  65741]),\n",
              " tensor([ 58985, 158184, 140337,  84231]),\n",
              " tensor([  6292,  65477, 110779, 143741]),\n",
              " tensor([143735, 161898, 129689,  29820]),\n",
              " tensor([ 35352,  48664, 162779,  35352]),\n",
              " tensor([ 55279,  64029,  80028, 118954]),\n",
              " tensor([  5707, 113311, 130756,  71430]),\n",
              " tensor([132705,  56966,  75362, 106611]),\n",
              " tensor([ 79634,  37742, 122599, 157915]),\n",
              " tensor([ 19989, 103506,  53258, 115503]),\n",
              " tensor([ 38114,  74999, 133593,  84767]),\n",
              " tensor([14329, 57221, 45718,  8911]),\n",
              " tensor([ 90603,   4774, 103532,  38853]),\n",
              " tensor([ 19120, 155500, 156367,  84231]),\n",
              " tensor([ 97371, 113666, 117670, 121172]),\n",
              " tensor([69706, 33327, 48568, 19776]),\n",
              " tensor([ 72082,  26728,  50171, 118256]),\n",
              " tensor([118954,  37854,  62970,  33033]),\n",
              " tensor([ 18464, 135644, 143307,  22474]),\n",
              " tensor([108633,  87166,  68154,  39060]),\n",
              " tensor([ 91610,  42625, 119394, 121290]),\n",
              " tensor([ 60613,   7644,  70434, 125497]),\n",
              " tensor([49843, 91704, 47108,  4493]),\n",
              " tensor([ 84850,  98906, 114502, 163416]),\n",
              " tensor([ 34810,  86574, 105397, 114579]),\n",
              " tensor([138976,  19955,  79672, 149390]),\n",
              " tensor([ 11188, 121830, 135725,    445]),\n",
              " tensor([ 97525,  40224,  85453, 104889]),\n",
              " tensor([ 17652,   8108, 134218,  21872]),\n",
              " tensor([147841, 161519, 135774, 135686]),\n",
              " tensor([ 85039,   5201,  47884, 141688]),\n",
              " tensor([109534,    766,   2719,   2243]),\n",
              " tensor([136396, 135827,  68759,  47986]),\n",
              " tensor([  7487,  94380, 110268, 148770]),\n",
              " tensor([160406, 128092, 134081, 124597]),\n",
              " tensor([132696, 143741, 127204,  94646]),\n",
              " tensor([115548, 144850, 158535,  43841]),\n",
              " tensor([ 31834, 120578,  46254, 113311]),\n",
              " tensor([15133, 70988, 49228, 15922]),\n",
              " tensor([21542, 23882, 91138, 38185]),\n",
              " tensor([30327, 44873, 16868, 13431]),\n",
              " tensor([134366,  81289,   7496,  93361]),\n",
              " tensor([124806,  27447,  17255, 157108]),\n",
              " tensor([ 7812, 81762, 49332, 46858]),\n",
              " tensor([ 98982, 111906, 108659,  61046]),\n",
              " tensor([160055, 152043, 132684, 100072]),\n",
              " tensor([  5789, 129957,  55836,  80953]),\n",
              " tensor([  7414,  61155, 101610,  18297]),\n",
              " tensor([146258,  91257,  78211, 131519]),\n",
              " tensor([  9776,  65942, 100554, 117809]),\n",
              " tensor([146483,  80381,  37126,  93343]),\n",
              " tensor([143346,  20626,  98906, 125303]),\n",
              " tensor([ 14280,  16977, 161162,  34226]),\n",
              " tensor([ 55259,  49905, 158022,  11902]),\n",
              " tensor([   674, 146819,  83432, 127481]),\n",
              " tensor([141553,  24511,  32358,  71353]),\n",
              " tensor([ 44989, 144850,  47729, 131851]),\n",
              " tensor([118425,  48989,  49362,  11247]),\n",
              " tensor([ 61440,  32586, 121830,  32586]),\n",
              " tensor([160062,  47301, 114805,  23411]),\n",
              " tensor([ 38443,  25697,  60735, 124590]),\n",
              " tensor([ 52028,  51010,   7020, 134103]),\n",
              " tensor([ 48491, 128256, 104839,  25380]),\n",
              " tensor([65741, 37589,  9776, 48664]),\n",
              " tensor([ 82501, 124538, 112710,  75979]),\n",
              " tensor([ 65794,  51097, 135635, 110046]),\n",
              " tensor([120253,  29074, 101145,  80953]),\n",
              " tensor([80245, 16894, 48960, 51931]),\n",
              " tensor([ 23570, 103358,  36855, 137678]),\n",
              " tensor([ 91501, 148650,   7414,  46477]),\n",
              " tensor([130268,  19255,  44873,  77387]),\n",
              " tensor([ 88867, 122738, 114210, 135725]),\n",
              " tensor([146149,  91704,  12169,  29785]),\n",
              " tensor([139491,  41627,  47301, 139165]),\n",
              " tensor([98906, 64730, 60383, 46308]),\n",
              " tensor([114829, 125623, 143346,  57940]),\n",
              " tensor([156367, 121830,  70956,  96847]),\n",
              " tensor([141363, 116639, 154346, 149407]),\n",
              " tensor([ 56927, 108644, 161671, 138488]),\n",
              " tensor([106731,  86417, 157243,  14800]),\n",
              " tensor([115159,  89571,  94955, 141728]),\n",
              " tensor([77427, 22924, 87659, 79814]),\n",
              " tensor([ 60626, 124597,  80822, 137364]),\n",
              " tensor([130770,  68596, 104990,  81436]),\n",
              " tensor([  3991, 146819, 121830,  40695]),\n",
              " tensor([ 10097,  21730,  23406, 162933]),\n",
              " tensor([ 82833,  93939, 136219,  93939]),\n",
              " tensor([   900, 117926, 137996,  29637]),\n",
              " tensor([117847, 158205,  31904,  38517]),\n",
              " tensor([ 92614,  90678,  68790, 126386]),\n",
              " tensor([ 14280, 109898,  54694,  21913]),\n",
              " tensor([ 58199, 144981, 146149, 143741]),\n",
              " tensor([ 29074,   3945, 161191,  19646]),\n",
              " tensor([ 49959,  78251, 125235,  69997]),\n",
              " tensor([ 79494,  60137, 144850, 101935]),\n",
              " tensor([104298,  81136,  81762,  97442]),\n",
              " tensor([155341, 131548, 102934,  24568]),\n",
              " tensor([105756,  84067,  84767,  22810]),\n",
              " tensor([137678,  76355,  93645, 149689]),\n",
              " tensor([ 31207, 157243,  56079, 159531]),\n",
              " tensor([124126,  21323,   7845, 108222]),\n",
              " tensor([ 29319, 134412,  46264,  79188]),\n",
              " tensor([129957,  47753,  80953,  65855]),\n",
              " tensor([11465, 77325, 90287, 18477]),\n",
              " tensor([131520, 148268,  56779,  20379]),\n",
              " tensor([ 6292,  6248, 82556, 62970]),\n",
              " tensor([  6404, 139868, 161895,  79634]),\n",
              " tensor([124213, 145143,  76285,  31315]),\n",
              " tensor([134150, 146947, 149407, 117781]),\n",
              " tensor([ 71651, 157113,  55606,  38799]),\n",
              " tensor([131109, 105761,  90603, 130269]),\n",
              " tensor([78257, 13641, 82494, 98906]),\n",
              " tensor([ 80953, 133357,  10136, 136868]),\n",
              " tensor([ 96140, 113363, 103054, 137255]),\n",
              " tensor([139563, 157763, 129394, 161253]),\n",
              " tensor([114896, 110793, 106809,  56966]),\n",
              " tensor([24282, 83875,  3939,  4331]),\n",
              " tensor([ 53865, 112139, 150562, 155880]),\n",
              " tensor([114896,  12192, 142082, 138018]),\n",
              " tensor([117809,  80822,  29319,  47729]),\n",
              " tensor([161442, 158022,  32358,  57940]),\n",
              " tensor([119896,  21139,  29074,  47715]),\n",
              " tensor([ 44989,  69252, 118256, 147251]),\n",
              " tensor([ 73627,  79203,  81136, 112534]),\n",
              " tensor([ 60245,  46069,  26285, 134692]),\n",
              " tensor([121830, 129086,  43140,  14800]),\n",
              " tensor([ 79598, 162594,  43054, 103287]),\n",
              " tensor([  5362,  48960,  28147, 103506]),\n",
              " tensor([  3997,  47301, 104298, 135707]),\n",
              " tensor([157405,  80328,  61600, 116217]),\n",
              " tensor([ 73742, 149861,  26170,  93973]),\n",
              " tensor([ 25682, 155101,  25673, 144055]),\n",
              " tensor([121830,  14280, 118954,  19601]),\n",
              " tensor([121830, 130756,  28153, 136626]),\n",
              " tensor([   733,  34979, 127527,  19822]),\n",
              " tensor([118259,   6268, 131000,  96749]),\n",
              " tensor([93077, 55842, 26775, 52036]),\n",
              " tensor([157692, 136108, 126519, 154547]),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbA6fBZaa6Iv"
      },
      "source": [
        "## 5. Choose two words and retrive their 5 closest neighbours from both datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EcLEX5zbHB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b61b50-fae2-455d-865a-3c74590140b0"
      },
      "source": [
        "chosen_words=['good','work']\n",
        "neighbours_from_reviews = get_closest_word_from_a_list(chosen_words, 5)\n",
        "neighbours_from_scifi = get_closest_word_from_a_list_scifi(chosen_words, 5)\n",
        "\n",
        "\n",
        "print(\"5 closest neighbours of the chosen words in hotel reviews dataset:\")\n",
        "print(neighbours_from_reviews)\n",
        "print(\"5 closest neighbours of the chosen words in scifi dataset:\")\n",
        "print(neighbours_from_scifi)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 closest neighbours of the chosen words in hotel reviews dataset:\n",
            "[(['vaperetto', 'mutianyu', 'watched', 'attatched', 'flickered'], 'good'), (['gained', 'alight', 'caffepc', 'bleached', 'constructed'], 'work')]\n",
            "5 closest neighbours of the chosen words in scifi dataset:\n",
            "[(['blasien', 'anticfpation', 'antlooking', 'allhough', 'caou'], 'good'), (['affold', 'butwithout', 'calted', 'breasting', 'aphorisms'], 'work')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiHz2oAFOHo1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}