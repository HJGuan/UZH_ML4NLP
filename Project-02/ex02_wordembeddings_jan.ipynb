{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ex02_wordembeddings_jan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-02/ex02_wordembeddings_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNNOVmLD-Fz"
      },
      "source": [
        "# Project 2 - Word Embeddings with PyTorch\n",
        "\n",
        "The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep\n",
        "learning. It is a model that tries to predict words given the context of\n",
        "a few words before and a few words after the target word. This is\n",
        "distinct from language modeling, since CBOW is not sequential and does\n",
        "not have to be probabilistic. Typcially, CBOW is used to quickly train\n",
        "word embeddings, and these embeddings are used to initialize the\n",
        "embeddings of some more complicated model. Usually, this is referred to\n",
        "as *pretraining embeddings*. It almost always helps performance a couple\n",
        "of percent.\n",
        "\n",
        "The CBOW model is as follows. Given a target word $w_i$ and an\n",
        "$N$ context window on each side, $w_{i-1}, \\dots, w_{i-N}$\n",
        "and $w_{i+1}, \\dots, w_{i+N}$, referring to all context words\n",
        "collectively as $C$, CBOW tries to minimize\n",
        "\n",
        "\\begin{align}-\\log p(w_i | C) = -\\log \\text{Softmax}(A(\\sum_{w \\in C} q_w) + b)\\end{align}\n",
        "\n",
        "where $q_w$ is the embedding for word $w$.\n",
        "\n",
        "Implement this model in Pytorch by filling in the class below. Some\n",
        "tips:\n",
        "\n",
        "* Think about which parameters you need to define.\n",
        "* Make sure you know what shape each operation expects. Use .view() if you need to\n",
        "  reshape.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHXvfNTXD4Ca"
      },
      "source": [
        "## Part 1: Training CBOW embeddings for both datasets\n",
        "### 1. Setup\n",
        "#### 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EATjb-X-0lM",
        "outputId": "c3a13ec2-196e-4841-9e98-59d7be36def9"
      },
      "source": [
        "import os\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', 800)\n",
        "\n",
        "# tokenization\n",
        "import nltk;\n",
        "nltk.download('stopwords');\n",
        "%matplotlib inline\n",
        "\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import string\n",
        "import itertools\n",
        "import regex as re\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "import requests"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKjgo1cEEQPw"
      },
      "source": [
        "#### 1.2 Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Tszg7FdPrZ",
        "outputId": "6b1cb7cd-67e7-4f05-d26d-6da2e694c47e"
      },
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu:0')\n",
        "torch.cuda.set_device(device)\n",
        "print('Using device:', device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ZgunZ9qSvu",
        "outputId": "981cbb35-3461-43fe-d59d-b5ebbb15cdbc"
      },
      "source": [
        "# Check GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 25 12:40:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keYYVJLbnpbD",
        "outputId": "350713c6-20b9-4f2e-c61b-8f83de75c28e"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-3538fdb8-aa9c-9eb8-38e2-ee22dd536714)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGFVru-nqX1n",
        "outputId": "ed8661d2-2c69-42ae-a159-809614a5b455"
      },
      "source": [
        "# Check Memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW7vvEZkEdrX"
      },
      "source": [
        "#### 1.3 Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grG2YIi8-aYu"
      },
      "source": [
        "FEATURE_COLUMN = 'Review'\n",
        "CONTEXT_OFFSET = 2 # n words to the left, n to the right\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "EPOCHS_HOTEL = 15\n",
        "EMBEDDING_DIM_HOTEL = 50\n",
        "\n",
        "EPOCHS_SCIFI = 2\n",
        "EMBEDDING_DIM_SCIFI = 50"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gy3d3hJQZB9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAqmKotTv5FX"
      },
      "source": [
        "### Hotel Reviews dataset\n",
        "### 2. Data Preprocessing\n",
        "#### 2.1 Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSA-k-FGGYVx",
        "outputId": "da9143f7-2a91-4271-a7ce-7757866f8c7c"
      },
      "source": [
        "# Loading the tripadvisor data\n",
        "url_tripadvisor = (r'https://raw.githubusercontent.com/abandonedrepo/test/master/tripadvisor_hotel_reviews.csv')\n",
        "reviews_dataset = pd.read_csv(url_tripadvisor)\n",
        "reviews_dataset.info()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20491 entries, 0 to 20490\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  20491 non-null  object\n",
            " 1   Rating  20491 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 320.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "MpAY67nPvFw9",
        "outputId": "a03319ee-a107-4a31-d1b1-e3a33f86e8f2"
      },
      "source": [
        "reviews_dataset.head(5)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, start booked suite paid extra website description not, suite bedroom bathroom standard hotel room, took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast, got kidding, embassy suits sitting room bathroom bedroom unlike kimpton calls suite, 5 day stay offer correct false advertising, send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty did not reply solution, send email trip guest survey did not follow email mail, guess tell concerned guest.the staff ranged indifferent not help...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nice rooms not 4* experience hotel monaco seattle good hotel n't 4* level.positives large bathroom mediterranean suite comfortable bed pillowsattentive housekeeping staffnegatives ac unit malfunctioned stay desk disorganized, missed 3 separate wakeup calls, concierge busy hard touch, did n't provide guidance special requests.tv hard use ipod sound dock suite non functioning. decided book mediterranean suite 3 night weekend stay 1st choice rest party filled, comparison w spent 45 night larger square footage room great soaking tub whirlpool jets nice shower.before stay hotel arrange car service price 53 tip reasonable driver waiting arrival.checkin easy downside room picked 2 person jacuzi tub no bath accessories salts bubble bath did n't stay, night got 12/1a checked voucher bottle cham...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown shopping area, pet friendly room showed no signs animal hair smells, monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy, goldfish named brandi enjoyed, did n't partake free wine coffee/tea service lobby thought great feature, great staff friendly, free wireless internet hotel worked suite 2 laptops, decor lovely eclectic mix pattens color palatte, animal print bathrobes feel like rock stars, nice did n't look like sterile chain hotel hotel personality excellent stay,</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great stay great stay, went seahawk game awesome, downfall view building did n't complain, room huge staff helpful, booked hotels website seahawk package, no charge parking got voucher taxi, problem taxi driver did n't want accept voucher barely spoke english, funny thing speak arabic called started making comments girlfriend cell phone buddy, took second realize just said fact speak language face priceless, ass told, said large city, told head doorman issue called cab company promply answer did n't, apologized offered pay taxi, bucks 2 miles stadium, game plan taxi return going humpin, great walk did n't mind, right christmas wonderful lights, homeless stowed away building entrances leave, police presence not greatest area stadium, activities 7 blocks pike street waterfront great coff...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Review  Rating\n",
              "0                                                                                                                                                                                                                nice hotel expensive parking got good deal stay hotel anniversary, arrived late evening took advice previous reviews did valet parking, check quick easy, little disappointed non-existent view room room clean nice size, bed comfortable woke stiff neck high pillows, not soundproof like heard music room night morning loud bangs doors opening closing hear people talking hallway, maybe just noisy neighbors, aveda bath products nice, did not goldfish stay nice touch taken advantage staying longer, location great walking distance shopping, overall nice experience having pay 40 parking night,         4\n",
              "1  ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, start booked suite paid extra website description not, suite bedroom bathroom standard hotel room, took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast, got kidding, embassy suits sitting room bathroom bedroom unlike kimpton calls suite, 5 day stay offer correct false advertising, send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty did not reply solution, send email trip guest survey did not follow email mail, guess tell concerned guest.the staff ranged indifferent not help...       2\n",
              "2  nice rooms not 4* experience hotel monaco seattle good hotel n't 4* level.positives large bathroom mediterranean suite comfortable bed pillowsattentive housekeeping staffnegatives ac unit malfunctioned stay desk disorganized, missed 3 separate wakeup calls, concierge busy hard touch, did n't provide guidance special requests.tv hard use ipod sound dock suite non functioning. decided book mediterranean suite 3 night weekend stay 1st choice rest party filled, comparison w spent 45 night larger square footage room great soaking tub whirlpool jets nice shower.before stay hotel arrange car service price 53 tip reasonable driver waiting arrival.checkin easy downside room picked 2 person jacuzi tub no bath accessories salts bubble bath did n't stay, night got 12/1a checked voucher bottle cham...       3\n",
              "3                                                                                                                                                                                                         unique, great stay, wonderful time hotel monaco, location excellent short stroll main downtown shopping area, pet friendly room showed no signs animal hair smells, monaco suite sleeping area big striped curtains pulled closed nice touch felt cosy, goldfish named brandi enjoyed, did n't partake free wine coffee/tea service lobby thought great feature, great staff friendly, free wireless internet hotel worked suite 2 laptops, decor lovely eclectic mix pattens color palatte, animal print bathrobes feel like rock stars, nice did n't look like sterile chain hotel hotel personality excellent stay,         5\n",
              "4  great stay great stay, went seahawk game awesome, downfall view building did n't complain, room huge staff helpful, booked hotels website seahawk package, no charge parking got voucher taxi, problem taxi driver did n't want accept voucher barely spoke english, funny thing speak arabic called started making comments girlfriend cell phone buddy, took second realize just said fact speak language face priceless, ass told, said large city, told head doorman issue called cab company promply answer did n't, apologized offered pay taxi, bucks 2 miles stadium, game plan taxi return going humpin, great walk did n't mind, right christmas wonderful lights, homeless stowed away building entrances leave, police presence not greatest area stadium, activities 7 blocks pike street waterfront great coff...       5"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jay7YAfne0wo"
      },
      "source": [
        "#### 2.2 Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0rNpT9gd4bp"
      },
      "source": [
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def clean_document(x):\n",
        "    x = re.sub(r'\\w*\\d\\w*', ' ', x)\n",
        "    x = re.sub(r'[^a-zA-Z\\s]', ' ', x.lower(), re.I|re.A)\n",
        "    x = re.sub(r'[\\-!+_@*#\\/$:)\"\\'.;,?&({}[]]*', ' ', x)\n",
        "    x = re.sub(r'\\b\\w{1,2}\\b', ' ', x)\n",
        "    x = re.sub(' +', ' ', x)\n",
        "    tokens = wpt.tokenize(x)\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    x = ' '.join(filtered_tokens)\n",
        "    return x\n",
        "\n",
        "clean_corpus = np.vectorize(clean_document)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgtrtfqq-kwj"
      },
      "source": [
        "# Clean the reviews by removing punctuation characters and stopwords.\n",
        "reviews = clean_corpus(reviews_dataset['Review'])"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwSUTo0zz-q-",
        "outputId": "16c8cc1a-4289-470a-b83c-f6378b5b4d55"
      },
      "source": [
        "np.random.choice(reviews, 10)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['beautiful view boyfriend planned trip paris booked hotel reading reviews tripadvisor booking hotel hotel website sent email requesting room view received response stating guaranteed arrived hotel hours check luckily room ready wonderful room fifth floor corner nto asked beautiful view eiffel tower balcony amazing lucky received rooms view know request hotel room quiet clean bed comfortable bathroom nice receptionists helpful spoke english complaint actually complain management day came hotel contact lens case missing assume cleaner steal guess swept trash regard temporary complaints',\n",
              "       'friendly good location stayed nights july reviewers mentioned reception staff friendly willing help hotel room quite small adequate length stay expect luxury clean located hotel like japanese food right place restaurants street hotel',\n",
              "       'nice hotel classy hotel nice neighborhood florence walking distance beautiful room amenities friendly staff good breakfest',\n",
              "       'great apartments excellent location sydney stones central station stroll china town darling harbour bedroom apartment booked excellent clean tidy spacious nicely decorated recommend place',\n",
              "       'great hotel husband went bali month years ago sooo excited long knowing course changed bit shock life unfortunatley aussies really hit bali hard thousands billabong ripcurl stores ill getting kuta legian seminyak areas like waikiki ubud getting beautiful areas loved jimbaran ritz beacause kinda world away scenewe stayed awesome villa normaily diver adventurers hate admit stayed private pool villa water strong dive swim island afraid nusa dua sanur changed bali past special memories stay ritz forget bali forever changed bali ask upgrade usually occupancy allows',\n",
              "       'absolutely wonderful stay affinia night stay affinia christmas night arrived late welcomed open arms wait bedroom suite booked requested queen beds suite exactly requested queens sofabed suite quiet extremely comfortable want leave beds morning valet worked great car checked happy hold bags visited city called minutes returning car bags waiting say good things hotel great families traveling teenagers great great location starbucks corner stay manhattan',\n",
              "       'fantastic location got price night stay majestic hotel barcelona got hotel greeted doormaen luggage promptly taken reception check quick despite hours early shown room location perfect right centre sight seeing city upmarket feel safer night room huge bathroom luxurious air heating controls room safe mini bar work station little extras expect bathrobes slippers provided bed comfortable pillows breakfast superb best selections encountered fresh fruit cereals pastries breads hams cheeses bacon eggs pancakes tortilla fresh coffee hotel staff extremely helpful polite professional hotel clean quiet relaxing atmosphere appreciated days walking sight seeing use pool weather cold fault cracked tiles bathroom really picky use hotel visit',\n",
              "       'nice place stayed nights bellevue hotel september october hotel room clean tiny bothered room full lenght mirror wich think useful bed confy staff friendly helpful restaurant surprised really nice food room stayed noisy relax sleep walking day long amsterdam lovely city hotel great location central minutes walk train station bellevue hotel great value money recommend',\n",
              "       'fantastic stayed nights celebrate wedding anniversary wife birthday new year day stay received nothing outstanding service beautiful hotel soon arrived upgraded suite offered complimentary champagne declined drink substituted peninsula chocolates invited use spa whilst prepared room arrived morning check time emily reception sure stay hoped room giant lcd dvd player built marble clad bathroom wall sets bathrobes bathroom bedroom towels replaced twice day exotic fruit bowl changed daily comprised ornately decorated napkins china plates cutlary arrival room asked press valet button wall tea arrived instantly electrically operated curtains meant watch lazer firework bed moving booked gaddi evening anniversary food excellent waiters knowledge menu ingredients comprehensive live band sang happy birthday whilst waiters brought birthday cake complete personal inscription breakfast lobby entertainment afternoon tea christmas decorations stunning spa best world wife booked facial birthday best experienced booked lot yrs arrived hotel upgraded private treatment suite comprised private steam room shower room jaccuzzi complementary juices electric blinds remotely operated jaccuzzi revealed full length window panaramic view hong kong harbour pool view guests arrive immediately given glass iced barley water instantly replenished cold facial towels sealed bag fault aspect stay privilaged stay world best hotels business peninsula goes straight list',\n",
              "       'bad wife spent honeymoon san juan stayed resort got place priceline reading reviews website concerned staying negative things mentioned prior arriving called wyndham shared concerns hotel contacted priceline told things wyndham request members arrived hotel greeted promptly desk staff told room ready floor club plaza got greeted conciere told presidential suite bottle wine cheese waiting presidential suite goes season peak season went room pleased accomadations seperate bathrooms marble tile jetted sized tub large bedroom believe upgraded room thought wyndham wanted make right phone concerns night club lounge appetizers morning continental breakfast staff treated like royalty time room clean ate maxis time service prompt food great casino fine crowded money night pool fine deeper beach hotel nothing shout looking beach place plenty quality restaurants close old san juan minutes taxi taxi fares negotiable set stone police safe walk streets hotel recommend stay right price room ocean buildings stay building tony romas views hope helps'],\n",
              "      dtype='<U12603')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtL6IIv1HC4H"
      },
      "source": [
        "# Since we want to train a CBOW model with context width of 2\n",
        "# on the reviews, we drop all reviews with less than 5 words.\n",
        "# This is equivalent to only keeping instances with at least 5 words.\n",
        "reviews = [review for review in reviews if len(review.split(\" \")) >=  (2*CONTEXT_OFFSET + 1)]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjNI3ufc6nFa"
      },
      "source": [
        "reviews_word_list=list((\" \".join(reviews)).split())\n",
        "\n",
        "frequency = pd.value_counts(reviews_word_list)\n",
        "infrequent_words = list(frequency[frequency <= 1].keys())\n",
        "frequent_words = list(frequency[frequency > 1].keys())\n",
        "\n",
        "is_infrequent = {}\n",
        "for infrequent_word in infrequent_words:\n",
        "  is_infrequent[infrequent_word] = 1\n",
        "\n",
        "for frequent_word in frequent_words:\n",
        "  is_infrequent[frequent_word] = 0"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxUXynX0M5iz"
      },
      "source": [
        "# In order to build the corpus for the reviews \n",
        "# we want to find every distinct word that occurs\n",
        "# in at least one review.\n",
        "# We join all reviews into one large string and then\n",
        "# split it at every space to receive a list of words\n",
        "# Then the set method is used in order to only\n",
        "# retain unique words.\n",
        "# This list is then alphabetically sorted\n",
        "review_words = \" \".join(reviews).split()\n",
        "review_words = [w for w in review_words if not is_infrequent[w]]\n",
        "reviews_vocabulary = sorted(set(review_words))"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw6FFmeNW5Or",
        "outputId": "3fab6996-fa08-4756-b16c-dcbe8c55a220"
      },
      "source": [
        "reviews_vocabulary_size = len(reviews_vocabulary)\n",
        "print(\"The reviews use a vocabulary comprising {} different words.\".format(reviews_vocabulary_size))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reviews use a vocabulary comprising 24730 different words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErFC1k2kNpCE"
      },
      "source": [
        "word2index = {w:i for i,w in enumerate(reviews_vocabulary)} # Lookup table mapping words to indices\n",
        "index2word = {i:w for i,w in enumerate(reviews_vocabulary)} # Lookup table mapping indices to words"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBwNZhIKcqAo",
        "outputId": "ff600be1-8503-4737-8a43-4a99c0dac7a1"
      },
      "source": [
        "data = []\n",
        "for review in reviews:\n",
        "  raw_text = review.split()\n",
        "  for i in range(CONTEXT_OFFSET, len(raw_text) - CONTEXT_OFFSET):\n",
        "      context = [raw_text[i - 2], raw_text[i - 1],\n",
        "                raw_text[i + 1], raw_text[i + 2]]\n",
        "      #print(context)\n",
        "      target = raw_text[i]\n",
        "      data.append((context, target))\n",
        "\n",
        "# Show some sample 'context -> center word' mappings\n",
        "#for i in range(5):\n",
        "#  print(data[i])"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqPIILq3f9er",
        "outputId": "6f767236-68e3-4295-edf9-eaec7abd6b35"
      },
      "source": [
        "# The following function transforms the context\n",
        "# into index notation\n",
        "def make_context_vector(context, word2index):\n",
        "    idxs = [word2index[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# Show one transformed sample context\n",
        "make_context_vector(data[0][0], word2index)  # example"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28703, 20765, 30900, 18715])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069rMbD_Vju4"
      },
      "source": [
        "class HotelReviewsDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKSnkqC7aPGV"
      },
      "source": [
        "X = np.array([i[0] for i in data])\n",
        "X_vectors = list(map(lambda elem: make_context_vector(elem, word2index) , X))"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElJk2mFlJG6Y",
        "outputId": "0a31c575-4ed0-486d-d7fb-1909e42466f5"
      },
      "source": [
        "# Print some vetorized sample contexts\n",
        "for i in range(5):\n",
        "  print(X_vectors[i])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([28703, 20765, 30900, 18715])\n",
            "tensor([20765, 15461, 18715, 18618])\n",
            "tensor([15461, 30900, 18618, 11311])\n",
            "tensor([30900, 18715, 11311, 40725])\n",
            "tensor([18715, 18618, 40725, 20765])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIrePOCkaQrB"
      },
      "source": [
        "y = np.array([i[1] for i in data])\n",
        "y_vectors = list(map(lambda elem: make_context_vector([elem], word2index), y))"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFP9_whfKkxT",
        "outputId": "6d305ac3-83b1-4877-b0e2-ae8f01db7681"
      },
      "source": [
        "# Print some vectorized sample center words\n",
        "for i in range(5):\n",
        "  print(y_vectors[i])"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15461])\n",
            "tensor([30900])\n",
            "tensor([18715])\n",
            "tensor([18618])\n",
            "tensor([11311])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wFmcwnO9Dq7"
      },
      "source": [
        "# Split into training and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors[:500000], y_vectors[:500000], test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWkaD9JtaT9t"
      },
      "source": [
        "# Create the training dataset from vectors\n",
        "hotel_reviews_dataset = HotelReviewsDataset(X_train, y_train)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OapsjmhTfHxw"
      },
      "source": [
        "### 3. Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RvGC_MGH6k0"
      },
      "source": [
        "hotel_reviews_loader = DataLoader(dataset=hotel_reviews_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3_xQQ5Mw3JQ"
      },
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "      super(CBOW, self).__init__()\n",
        "      self.embeddings = nn.Embedding(vocab_size, embedding_dim, device=device)\n",
        "      self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "      self.activation_function1 = nn.ReLU()\n",
        "      self.linear2 = nn.Linear(128, vocab_size)\n",
        "      self.activation_function2 = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      embeds = self.embeddings(inputs).view(inputs.size(0), -1)\n",
        "      out = self.linear1(embeds)\n",
        "      out = self.activation_function1(out)\n",
        "      out = self.linear2(out)\n",
        "      out = self.activation_function2(out)\n",
        "      return out"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB1FCwfH4miH"
      },
      "source": [
        "def train_model(model, data_loader, epochs, word2index):\n",
        "\n",
        "  losses = np.zeros(epochs)\n",
        "  loss_function = nn.NLLLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for step, (context_vectors, target_vector) in enumerate(data_loader):\n",
        "\n",
        "      context_vectors = context_vectors.to(device) # Move the batch of context vectors into GPU memory\n",
        "      target_vector = target_vector.to(device) # Move the batch of target vectors into GPU memory \n",
        "\n",
        "      model.zero_grad() # Reset all gradients back to zero\n",
        "\n",
        "      log_probs = model(context_vectors) # forward pass\n",
        "      loss = loss_function(log_probs, torch.squeeze(target_vector)) # compute loss for batch\n",
        "      losses[epoch] += loss.item() # accumulate loss\n",
        "\n",
        "      loss.backward() # backpropagation\n",
        "      optimizer.step() # update the model weights\n",
        "\n",
        "    print(\"Epoch {0}/{1} ... Average loss {2}\".format(epoch+1, epochs, losses[epoch] / len(data_loader.dataset))) # Print average loss in this episode\n",
        "  return losses"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "fkd783s1i4tS",
        "outputId": "6ca6a24a-7670-44cb-828a-d0f2b3a456ec"
      },
      "source": [
        "# Only run this cell if you want to load a saved CBOW model including embeddings.\n",
        "model = CBOW(reviews_vocabulary_size, EMBEDDING_DIM_HOTEL, 2*CONTEXT_OFFSET).to(device)\n",
        "model.load_state_dict(torch.load('./hotel_reviews_model_weights.pth'))\n",
        "model.eval()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-5d281b711abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Only run this cell if you want to load a saved CBOW model including embeddings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCBOW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_vocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM_HOTEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mCONTEXT_OFFSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./hotel_reviews_model_weights.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './hotel_reviews_model_weights.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nruXd09DFRjB",
        "outputId": "349c2338-5546-4b57-e684-8002d7794e24"
      },
      "source": [
        "model = CBOW(reviews_vocabulary_size, EMBEDDING_DIM_HOTEL, 2*CONTEXT_OFFSET).to(device)\n",
        "losses = train_model(model, hotel_reviews_loader, EPOCHS_HOTEL, word2index)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 ... Average loss 0.12240179890394211\n",
            "Epoch 2/15 ... Average loss 0.11280434147000312\n",
            "Epoch 3/15 ... Average loss 0.10684676656484604\n",
            "Epoch 4/15 ... Average loss 0.10216135758519172\n",
            "Epoch 5/15 ... Average loss 0.09847101616501808\n",
            "Epoch 6/15 ... Average loss 0.09546819850444793\n",
            "Epoch 7/15 ... Average loss 0.09296372812747955\n",
            "Epoch 8/15 ... Average loss 0.09086957519054413\n",
            "Epoch 9/15 ... Average loss 0.08904881232619286\n",
            "Epoch 10/15 ... Average loss 0.08747491861820221\n",
            "Epoch 11/15 ... Average loss 0.08607144962430001\n",
            "Epoch 12/15 ... Average loss 0.0848245150399208\n",
            "Epoch 13/15 ... Average loss 0.08373824785351754\n",
            "Epoch 14/15 ... Average loss 0.08276360579371453\n",
            "Epoch 15/15 ... Average loss 0.08191652846932411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fj0D26mgDpS"
      },
      "source": [
        "# Save the trained CBOW model\n",
        "torch.save(model.state_dict(), './hotel_reviews_model_weights.pth')"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI4F2RhxQsli"
      },
      "source": [
        "### Sci-Fi story dataset\n",
        "### 2. Data Preprocessing\n",
        "#### 2.1 Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyhZrrzEM4oK",
        "outputId": "210c36b2-2f7f-4093-c849-e9c3f2bb59b2"
      },
      "source": [
        "# Loading the scifi txt\n",
        "url = 'https://raw.githubusercontent.com/abandonedrepo/test/master/scifi.txt'\n",
        "scifi_dataset = requests.get(url).text\n",
        "print(scifi_dataset[:100])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARCH # All Stories New and Complete Publisher Editor IF is published bi-monthly by Quinn Publishing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLOZKW_Q-Xx"
      },
      "source": [
        "#### 2.2 Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JbPCiNSQ-Xy",
        "outputId": "f9159ef1-6bc3-4e41-c86f-13b7d7218f4a"
      },
      "source": [
        "# Clean the scifi text by removing punctuation and stop words\n",
        "scifi_dataset = clean_document(scifi_dataset)\n",
        "print(scifi_dataset[:100])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "march stories new complete publisher editor published bimonthly quinn publishing company inc kingsto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RqYPvfAWjft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2068fef7-74e0-4f53-bac8-6e16f653207c"
      },
      "source": [
        "# Split the scifi text into individual words\n",
        "scifi_word_list=scifi_dataset.split()\n",
        "print(scifi_word_list[:10])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['march', 'stories', 'new', 'complete', 'publisher', 'editor', 'published', 'bimonthly', 'quinn', 'publishing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haEnt7f_Q-Xz"
      },
      "source": [
        "# list of unique words from the scifi txt\n",
        "scifi_vocabulary = sorted(set(scifi_word_list))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CEgzAuJQ-Xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503a1b07-9e93-4405-bfab-c4957f3667bc"
      },
      "source": [
        "scifi_vocabulary_size = len(scifi_vocabulary)\n",
        "print(\"The scifi text uses a vocabulary comprising {} different words.\".format(scifi_vocabulary_size))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scifi text uses a vocabulary comprising 200658 different words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiMugJGcQ-Xz"
      },
      "source": [
        "word2index_scifi = {w:i for i,w in enumerate(scifi_vocabulary)} # Lookup table mapping words to indices\n",
        "index2word_scifi = {i:w for i,w in enumerate(scifi_vocabulary)} # Lookup table mapping indices to words"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTcH8mwgGPz"
      },
      "source": [
        "# To prevent the colab ram from crashing, save some spaces for memory\n",
        "del scifi_dataset, scifi_vocabulary"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihpxw4ADQ-X0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e260b2b5-e75e-4aaf-d26a-1232d3510c69"
      },
      "source": [
        "scifi_data = []\n",
        "for i in range(CONTEXT_OFFSET, 1000000 + CONTEXT_OFFSET): # To prevent the colab ram from crashing, we chose the first 1000000 words for trainning\n",
        "    context = [scifi_word_list[i - 2], scifi_word_list[i - 1],\n",
        "              scifi_word_list[i + 1], scifi_word_list[i + 2]]\n",
        "    target = scifi_word_list[i]\n",
        "    scifi_data.append((context, target))\n",
        "print(scifi_data[:5])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['march', 'stories', 'complete', 'publisher'], 'new'), (['stories', 'new', 'publisher', 'editor'], 'complete'), (['new', 'complete', 'editor', 'published'], 'publisher'), (['complete', 'publisher', 'published', 'bimonthly'], 'editor'), (['publisher', 'editor', 'bimonthly', 'quinn'], 'published')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yla0GZr5Q-X0"
      },
      "source": [
        "X = np.array([i[0] for i in scifi_data])\n",
        "X_vectors = list(map(lambda elem: make_context_vector(elem, word2index_scifi) , X))\n",
        "y = np.array([i[1] for i in scifi_data])\n",
        "y_vectors = list(map(lambda elem: make_context_vector([elem], word2index_scifi), y))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMPNVlD1Q-X1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y_vectors, test_size=0.2, random_state=42)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o_8RGmkQ-X1"
      },
      "source": [
        "scifi_training_dataset = HotelReviewsDataset(X_train, y_train)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkQx-wKOQ-X2"
      },
      "source": [
        "### 3. Modelling (Sci-Fi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQdR_2MmoTCY"
      },
      "source": [
        "scifi_model_path = './scifi_model_weights.pth'"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAtAVyqvQ-X2"
      },
      "source": [
        "scifi_data_loader = DataLoader(dataset=scifi_training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "model_scifi = CBOW(scifi_vocabulary_size, EMBEDDING_DIM_SCIFI, 2*CONTEXT_OFFSET).to(device)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyMzhEQom5zL",
        "outputId": "c6286103-7c11-485e-e014-5f77fff38f6c"
      },
      "source": [
        "try:\n",
        "  model_scifi.load_state_dict(torch.load(scifi_model_path))\n",
        "  model.eval()\n",
        "except Exception as e:\n",
        "  print(\"No saved embeddings exist.\")\n",
        "  print(\"Starting to learn word embeddings.\")\n",
        "  losses = train_model(model_scifi, scifi_data_loader, EPOCHS_SCIFI, word2index_scifi)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No saved embeddings exist.\n",
            "Starting to learn word embeddings.\n",
            "Epoch 1/2 ... Average loss 0.14100225863039492\n",
            "Epoch 2/2 ... Average loss 0.13805539209783077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i0k9drfoMzu"
      },
      "source": [
        "# Save the trained CBOW model\n",
        "torch.save(model.state_dict(), scifi_model_path)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGUoP7D9b28"
      },
      "source": [
        "# Part 2: Test your embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvwdYFgdL9nq"
      },
      "source": [
        "## 2. find 5 neighbours of each of the 9 words from the hotel reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXR8AUQSCcGV",
        "outputId": "32cff9c4-013d-4832-fd26-f563b74ddd92"
      },
      "source": [
        "# check the frequencies of the words\n",
        "reviews_word_list=list((\" \".join(reviews)).split())\n",
        "frequency = pd.value_counts(reviews_word_list)\n",
        "print(\"Most frequent words are\\n{}\\n------------------------------\".format(frequency.head(20)))\n",
        "print(\"Medium frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[500:520]))\n",
        "print(\"Less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[1000:1020]))\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent words are\n",
            "hotel        49877\n",
            "room         35357\n",
            "great        21482\n",
            "good         17418\n",
            "staff        16637\n",
            "stay         15413\n",
            "nice         12646\n",
            "rooms        12407\n",
            "location     11353\n",
            "stayed       10500\n",
            "service      10373\n",
            "night        10164\n",
            "time         10132\n",
            "beach        10068\n",
            "day           9979\n",
            "breakfast     9737\n",
            "clean         9599\n",
            "food          9425\n",
            "like          8254\n",
            "resort        8152\n",
            "dtype: int64\n",
            "------------------------------\n",
            "Medium frequent words are\n",
            "attractions    705\n",
            "received       704\n",
            "issue          698\n",
            "directly       697\n",
            "turn           697\n",
            "watch          695\n",
            "adequate       694\n",
            "makes          694\n",
            "surprised      693\n",
            "royal          689\n",
            "true           688\n",
            "elevator       688\n",
            "break          688\n",
            "cab            687\n",
            "bavaro         686\n",
            "recently       684\n",
            "basic          684\n",
            "quickly        684\n",
            "complaints     684\n",
            "smoking        683\n",
            "dtype: int64\n",
            "------------------------------\n",
            "Less frequent words are\n",
            "fully         342\n",
            "cafes         341\n",
            "added         341\n",
            "gone          341\n",
            "taxis         341\n",
            "italy         341\n",
            "month         340\n",
            "filled        340\n",
            "comment       340\n",
            "lines         340\n",
            "apart         340\n",
            "fee           339\n",
            "additional    339\n",
            "heat          338\n",
            "aware         338\n",
            "base          336\n",
            "lift          336\n",
            "members       336\n",
            "sister        335\n",
            "wow           335\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_v4l5lGJ5o"
      },
      "source": [
        "# We chose 3 nouns, 3 verbs, and 3 adjectives respectively from the above 3 frequency levels.\n",
        "chosen_words = ['hotel','great', 'clean', # From most frequent words\n",
        "                'issue','adequate','smoking', # From medium frequent words\n",
        "                'italy','filled','comment'] # From least frequent words"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sur7tef3M4hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a265699d-1840-4886-a13f-d3a4ff88fe85"
      },
      "source": [
        "def get_closest_word(word, topn):\n",
        "  word_distance = []\n",
        "  emb = model.embeddings\n",
        "  pdist = nn.PairwiseDistance()\n",
        "  i = word2index[word]\n",
        "  lookup_tensor_i = torch.tensor([i],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "  v_i = emb(lookup_tensor_i)\n",
        "  for j in range(len(reviews_vocabulary)):\n",
        "    if j !=i:\n",
        "      lookup_tensor_j = torch.tensor([j],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "      v_j = emb(lookup_tensor_j)\n",
        "      word_distance.append((index2word[j],float(pdist(v_i,v_j))))\n",
        "  word_distance.sort(key=lambda x:x[1])\n",
        "  return word_distance[:topn]\n",
        "\n",
        "example = get_closest_word('beach', 5)\n",
        "print(example)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('´', 6.121271133422852), ('fong', 6.1489152908325195), ('madrilenos', 6.170948028564453), ('glanced', 6.245548725128174), ('south', 6.249263286590576)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SKL5FNpM4fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d98df4-b578-4c33-d30c-392b2522b68e"
      },
      "source": [
        "def get_closest_word_from_a_list(chosen_words,  topn):\n",
        "  chosen_words_and_their_neighbours=[]\n",
        "  for word in chosen_words:\n",
        "    get_result = get_closest_word(word,  topn)\n",
        "    neighbours = [nb[0] for nb in get_result]\n",
        "    chosen_words_and_their_neighbours.append((neighbours,word))\n",
        "  return chosen_words_and_their_neighbours\n",
        "\n",
        "neighbours = get_closest_word_from_a_list(chosen_words,5)\n",
        "neighbours"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['resort', 'smattering', 'sales', 'styaed', 'expense'], 'hotel'),\n",
              " (['good', 'guimet', 'kuhio', 'structural', 'luccesi'], 'great'),\n",
              " (['decorated', 'jared', 'lechon', 'shopper', 'dutton'], 'clean'),\n",
              " (['squadron', 'peahens', 'stations', 'insufficiently', 'nineteen'], 'issue'),\n",
              " (['contempated', 'omelets', 'reforma', 'dirtiest', 'frrom'], 'adequate'),\n",
              " (['taison', 'forgotton', 'principale', 'denver', 'everythibng'], 'smoking'),\n",
              " (['ken', 'opend', 'heartwarming', 'loungeif', 'millipedes'], 'italy'),\n",
              " (['costco', 'pickpocketing', 'tibadabo', 'malasadas', 'prinsingract'],\n",
              "  'filled'),\n",
              " (['elaberate', 'outright', 'libary', 'rios', 'kursaal'], 'comment')]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQAjrX1BNKuv"
      },
      "source": [
        "## 3. find 5 neighbours of each of the 9 words from the scifi dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-pFBNeQNKuw",
        "outputId": "44164ac4-5baa-4c11-dc6d-959859620e76"
      },
      "source": [
        "# check the frequencies of the words\n",
        "frequency = pd.value_counts(scifi_word_list)\n",
        "print(\"The most frequent words are\\n{}\\n------------------------------\".format(frequency.head(20)))\n",
        "print(\"The less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[500:520]))\n",
        "print(\"The much less frequent words are\\n{}\\n------------------------------\".format(frequency.iloc[800:820]))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent words are\n",
            "said     76347\n",
            "one      55339\n",
            "would    46555\n",
            "could    41388\n",
            "like     35710\n",
            "back     31984\n",
            "time     31971\n",
            "know     28539\n",
            "man      27071\n",
            "dont     26121\n",
            "get      24459\n",
            "well     23211\n",
            "see      21141\n",
            "us       21022\n",
            "way      20825\n",
            "two      20553\n",
            "even     20493\n",
            "right    19416\n",
            "first    18771\n",
            "got      17900\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The less frequent words are\n",
            "tiny         2415\n",
            "smile        2408\n",
            "showed       2400\n",
            "somewhere    2398\n",
            "mans         2390\n",
            "twenty       2388\n",
            "radio        2376\n",
            "wish         2369\n",
            "late         2369\n",
            "john         2367\n",
            "glanced      2363\n",
            "killed       2355\n",
            "legs         2355\n",
            "nearly       2353\n",
            "blood        2349\n",
            "single       2347\n",
            "couple       2345\n",
            "state        2338\n",
            "energy       2336\n",
            "complete     2336\n",
            "dtype: int64\n",
            "------------------------------\n",
            "The much less frequent words are\n",
            "knowing     1595\n",
            "language    1595\n",
            "warm        1590\n",
            "b           1582\n",
            "dust        1578\n",
            "editor      1572\n",
            "worry       1572\n",
            "boys        1570\n",
            "offer       1566\n",
            "turning     1565\n",
            "pass        1565\n",
            "party       1564\n",
            "north       1563\n",
            "covered     1562\n",
            "river       1557\n",
            "orders      1551\n",
            "grinned     1550\n",
            "goes        1547\n",
            "remained    1538\n",
            "save        1537\n",
            "dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFytFPDbNKuw"
      },
      "source": [
        "# We chose 3 nouns, 3 verbs, and 3 adjectives respectively from the above 3 frequency levels.\n",
        "chosen_words_scifi = ['time','said','right',\n",
        "                      'blood','smile','tiny',\n",
        "                      'party','worry','warm']"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-4MXoB1NKux",
        "outputId": "4b3cbe0c-02c8-4e1e-d43f-02249195a12b"
      },
      "source": [
        "def get_closest_word_scifi(word, topn):\n",
        "  word_distance = []\n",
        "  emb = model_scifi.embeddings\n",
        "  pdist = nn.PairwiseDistance()\n",
        "  i = word2index_scifi[word]\n",
        "  lookup_tensor_i = torch.tensor([i],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "  v_i = emb(lookup_tensor_i)\n",
        "  for j in range(len(reviews_vocabulary)):\n",
        "    if j !=i:\n",
        "      lookup_tensor_j = torch.tensor([j],dtype=torch.long).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "      v_j = emb(lookup_tensor_j)\n",
        "      word_distance.append((index2word_scifi[j],float(pdist(v_i,v_j))))\n",
        "  word_distance.sort(key=lambda x:x[1])\n",
        "  return word_distance[:topn]\n",
        "\n",
        "def get_closest_word_from_a_list_scifi(chosen_words, topn):\n",
        "  chosen_words_and_their_neighbours=[]\n",
        "  for word in chosen_words:\n",
        "    get_result = get_closest_word_scifi(word, topn)\n",
        "    neighbours = [nb[0] for nb in get_result]\n",
        "    chosen_words_and_their_neighbours.append((neighbours,word))\n",
        "  return chosen_words_and_their_neighbours\n",
        "\n",
        "\n",
        "neighbours = get_closest_word_from_a_list_scifi(chosen_words_scifi, 5)\n",
        "neighbours"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['duu', 'fuzzythinkers', 'amphibians', 'chainlink', 'chowbitten'], 'time'),\n",
              " (['eitfi', 'centennial', 'ascribes', 'hardens', 'emissions'], 'said'),\n",
              " (['footstep', 'blankness', 'allbutconsecutive', 'atwist', 'atomie'], 'right'),\n",
              " (['calypsotype', 'crystalline', 'excluif', 'exterminator', 'buonaparte'],\n",
              "  'blood'),\n",
              " (['comrange', 'beaux', 'chzik', 'automobile', 'fissionroom'], 'smile'),\n",
              " (['fortissa', 'fsynous', 'comlyric', 'giierous', 'bedrock'], 'tiny'),\n",
              " (['eans', 'gruls', 'bamaybe', 'desrick', 'adulatory'], 'party'),\n",
              " (['booki', 'benvice', 'frdons', 'gitm', 'fanflat'], 'worry'),\n",
              " (['expertly', 'fullv', 'extruded', 'backdrop', 'fortunately'], 'warm')]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbA6fBZaa6Iv"
      },
      "source": [
        "## 5. Choose two words and retrive their 5 closest neighbours from both datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EcLEX5zbHB_",
        "outputId": "8c3f8cbd-9278-4922-db95-eb6df6f6b1c4"
      },
      "source": [
        "chosen_words=['good','said']\n",
        "neighbours_from_reviews = get_closest_word_from_a_list(chosen_words, 5)\n",
        "neighbours_from_scifi = get_closest_word_from_a_list_scifi(chosen_words, 5)\n",
        "\n",
        "\n",
        "print(\"5 closest neighbours of the chosen words in hotel reviews dataset:\")\n",
        "print(neighbours_from_reviews)\n",
        "print(\"5 closest neighbours of the chosen words in scifi dataset:\")\n",
        "print(neighbours_from_scifi)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 closest neighbours of the chosen words in hotel reviews dataset:\n",
            "[(['ingroundsç', 'litter', 'hola', 'carefullythere', 'apec'], 'good'), (['nameçîhis', 'tripleenjoyed', 'readairport', 'magdilina', 'demonstrates'], 'said')]\n",
            "5 closest neighbours of the chosen words in scifi dataset:\n",
            "[(['cyanophyll', 'dummkopf', 'charsmoked', 'benford', 'fuiuher'], 'good'), (['eitfi', 'centennial', 'ascribes', 'hardens', 'emissions'], 'said')]\n"
          ]
        }
      ]
    }
  ]
}