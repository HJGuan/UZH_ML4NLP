{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "ex6_LDA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0PJr_Z68lC1_"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z208NBc1lC1k"
      },
      "source": [
        "# Starting Code for Exercise 6\n",
        "\n",
        "### Import Modules and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl6Ajcuu5DvW"
      },
      "source": [
        "import re\n",
        "import requests\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBb5tcJo0yla"
      },
      "source": [
        "url_data = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTxbA16lnYbtH-j6PPrPogc6ft03gp0y5mmo1Nq3l-Pxnb05nP1C-mOxUYvTciA2gq5nkwAqz9Y7Imi/pub?gid=646892609&single=true&output=tsv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8SjmfcV1DeK"
      },
      "source": [
        "def load_dataset(url):\n",
        "    r = requests.get(url)\n",
        "    data = r.content.decode('utf8')\n",
        "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0GBCr4n1HC2"
      },
      "source": [
        "df = load_dataset(url_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWbGgob6D6r"
      },
      "source": [
        "### Inspect the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "ovk-XSF36Ti3",
        "outputId": "722e8d3d-33d3-4f2f-bfda-bbf54c09bd1b"
      },
      "source": [
        "df.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>country</th>\n",
              "      <th>founding_date</th>\n",
              "      <th>relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pandora Car Rental</td>\n",
              "      <td>Welcome to Pandora Car Rental, Car Hire and Ai...</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2011-04-05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SurplusMatch</td>\n",
              "      <td>SurplusMatch is an online marketplace for cont...</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2008-01-01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gimenez Ganga</td>\n",
              "      <td>Giménez Ganga is a company that has been provi...</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>1959-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SMC3</td>\n",
              "      <td>Freight shippers, motor carriers, logistics se...</td>\n",
              "      <td>United States</td>\n",
              "      <td>1935-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Much Asphalt</td>\n",
              "      <td>Much Asphalt is southern Africa’s commercial s...</td>\n",
              "      <td>South Africa</td>\n",
              "      <td>1965-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The Hisey Company</td>\n",
              "      <td>The Hisey Company provides quality arbor care ...</td>\n",
              "      <td>United States</td>\n",
              "      <td>2011-02-19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FREIGHTALIA, LTD.</td>\n",
              "      <td>#1 Automatic quoting system ever created for F...</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2015-09-26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Instant Access Au</td>\n",
              "      <td>Instant Access is a provider of Access equipme...</td>\n",
              "      <td>Australia</td>\n",
              "      <td>1968-01-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CANOR International</td>\n",
              "      <td>CANOR International provides project managemen...</td>\n",
              "      <td>Hungary</td>\n",
              "      <td>1993-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LISUTO</td>\n",
              "      <td>LISUTO is a Multi-language batch exhibition sy...</td>\n",
              "      <td>Japan</td>\n",
              "      <td>2016-11-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PUNCH Consulting Engineers</td>\n",
              "      <td>PUNCH Consulting Engineers is the business nam...</td>\n",
              "      <td>Ireland</td>\n",
              "      <td>1973-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Tucker Auto-Mation</td>\n",
              "      <td>Tucker Auto-Mation Holdings USA, LLC manufactu...</td>\n",
              "      <td>United States</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Skye Capic Select</td>\n",
              "      <td>Skye Capic Select is planned as a 126 room hot...</td>\n",
              "      <td>Nigeria</td>\n",
              "      <td>2008-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ergo Robotic Solutions</td>\n",
              "      <td>Ergo Robotic Solutions have developed unmanned...</td>\n",
              "      <td>United States</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Wuunder</td>\n",
              "      <td>Hello, We are Wuunder, and we’re excited to be...</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          name  ... relevancy\n",
              "0           Pandora Car Rental  ...         0\n",
              "1                 SurplusMatch  ...         2\n",
              "2                Gimenez Ganga  ...         0\n",
              "3                         SMC3  ...         0\n",
              "4                 Much Asphalt  ...         0\n",
              "5            The Hisey Company  ...         0\n",
              "6            FREIGHTALIA, LTD.  ...         0\n",
              "7            Instant Access Au  ...         1\n",
              "8          CANOR International  ...         0\n",
              "9                       LISUTO  ...         1\n",
              "10  PUNCH Consulting Engineers  ...         0\n",
              "11          Tucker Auto-Mation  ...         0\n",
              "12           Skye Capic Select  ...         0\n",
              "13      Ergo Robotic Solutions  ...         1\n",
              "14                     Wuunder  ...         0\n",
              "\n",
              "[15 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW5locst6W4c",
        "outputId": "0039a7ef-ea3e-41dd-86ca-5338a15387b3"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   name           2000 non-null   object\n",
            " 1   description    2000 non-null   object\n",
            " 2   country        2000 non-null   object\n",
            " 3   founding_date  2000 non-null   object\n",
            " 4   relevancy      2000 non-null   int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 78.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEqbXtqn75yl",
        "outputId": "c4238150-32f8-4cd5-f7dd-985b945220b5"
      },
      "source": [
        "# Check for null values\n",
        "df.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMAfWeHdlC1v"
      },
      "source": [
        "### Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl9GZt4MlC1w",
        "outputId": "9fa726ea-2cd4-47ee-84b2-275830845f82"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLjied5rlC1z"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def prep_process_tokenize(text):\n",
        "    #websites, email and any punctuation cleaning\n",
        "    text = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", text)\n",
        "    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n",
        "    text = text.lower() # lower case the text\n",
        "    text = nltk.word_tokenize(text)\n",
        "    #removing stopwords\n",
        "    text = [word for word in text if word not in stopwords]\n",
        "    #stemming\n",
        "    try:\n",
        "        text = [stemmer.stem(word) for word in text]\n",
        "        text = [word for word in text if len(word) > 1]\n",
        "    except IndexError:\n",
        "        pass\n",
        "    return text\n",
        "\n",
        "\n",
        "def pre_process(text):\n",
        "    return \" \".join(prep_process_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D6fbveUlC1z"
      },
      "source": [
        "### Tf-Idf Based Approach (Vector Space Modeling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD_kBO3v4HGn"
      },
      "source": [
        "This cell passes the pre-processes description texts (which can be seen in the above dataframe) to a vectorizer which applies tfidf weighting --> therefore TfidfVectorizer. \n",
        "The pre-processing steps that are applied can be seen in the cell above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0C4xoZmlC17"
      },
      "source": [
        "tfidf = TfidfVectorizer(preprocessor=pre_process).fit_transform(df.description)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7MfhhBk4HsD"
      },
      "source": [
        "I will explain the variables in the cell below: \n",
        "\n",
        "*   doc_index_to_compare: get the row index of the row of the company name specified on the right. In this case: Vahanalytics. It first turn the row into a list and then gets the entry at index 0 which is the index of the row in the df. \n",
        "*   top_k: just an int defining the number of most similar companies that should be extracted\n",
        "*   cosine_similarities: this calculates the cosine similarity for the company description at the given index to all other company descriptions in the list. It does so using the tfidf vectorized representation of the descriptions. As the result is a list of lists, it is flattened\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVRpPB-2lC18"
      },
      "source": [
        "doc_index_to_compare = df.index[df['name'] == \"Vahanalytics\"].tolist()[0]\n",
        "top_k = 5\n",
        "cosine_similarities = cosine_similarity(\n",
        "    tfidf[doc_index_to_compare:doc_index_to_compare + 1], \n",
        "    tfidf\n",
        "    ).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA8tAPuO4ItP"
      },
      "source": [
        "The cosine similarity array is sorted and the 5 entries with the highest scores are extracted. ``argsort`` allows to still keep the original index. This means that these are the indices (of the descriptions) in the df as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Y3-2BXlC18"
      },
      "source": [
        "related_docs_indices = cosine_similarities.argsort()[:-top_k - 1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpIPbNtU4Jfs"
      },
      "source": [
        "Based on the indices that we got in the cell above, we can now easily extract the row at the resprctive index from the original dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2vNb-TulC19"
      },
      "source": [
        "tfidf_result_df = df[df.index.isin(related_docs_indices)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xruIHqWg4MTy"
      },
      "source": [
        "This is a new df, only containing those entries that are in the top 5 most similar entries in the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "LUwxpnMFlC19",
        "outputId": "b985a871-9980-42d5-b71b-23791463923a"
      },
      "source": [
        "tfidf_result_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>country</th>\n",
              "      <th>founding_date</th>\n",
              "      <th>relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Ship Supplies Direct</td>\n",
              "      <td>We aim to use digital technology to transform the marine logistics industry</td>\n",
              "      <td>Singapore</td>\n",
              "      <td>2018-05-14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>BISAF</td>\n",
              "      <td>BISAF is a technological company for the construction industry. We specialise in cutting edge solutions that make building easier, safer and environmentally friendly.</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2006-05-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>Vahanalytics</td>\n",
              "      <td>Vahanalytics aims to create better drivers and safer roads by using cutting edge big data and machine learning techniques.</td>\n",
              "      <td>India</td>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1542</th>\n",
              "      <td>GeoSpock</td>\n",
              "      <td>GeoSpock brings together their expertise of big data engineering to unlock the hidden value of data silos in your organization. Their solution enables you to manage extreme amounts of data at speed enabling your organization to react to key insights in a timely manner for future business success. The technology enables a range of capabilities from data analytics, visualization of spatial data, cutting edge data indexing, custom querying of data sets, and data intelligence.  To ensure that their customers get the maximum impact using the GeoSpock solution they work with them on a one to one basis as they understand that each organization approaches their data problems in a bespoke manner, this ensures that you get maximum business impact.  In bringing together multiple datasets this enables the cost of data generation to be amortized over many applications, opening up new business models and monetization opportunities, therefore, bringing value to your business.  They work across a number of markets including smart cities, automotive, mobile networks, IoT, enterprise, AdTech, asset management, and logistics.</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>Axenda</td>\n",
              "      <td>Axenda is a cloud-based software platform for construction management industry. The software platform is used by constructors and architects to manage day-to-day tasks and grow their businesses. The company's patent-pending algorithm uses machine learning to estimate materials &amp; resources. It aims to predict project's estimates &amp; completion deadlines. In addition, the platform also translates the data into 3D virtual models which give visual feedback of project's progress to clients.</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      name  ... relevancy\n",
              "93    Ship Supplies Direct  ...         1\n",
              "656                  BISAF  ...         1\n",
              "695           Vahanalytics  ...         1\n",
              "1542              GeoSpock  ...         1\n",
              "1982                Axenda  ...         2\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI9xs6xehFMJ"
      },
      "source": [
        "#### Extended code for \"Much Asphalt\"\n",
        "\n",
        "I just copied the code from above and changed the name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Us1M5A2hL0d"
      },
      "source": [
        "doc_index_to_compare2 = df.index[df['name'] == \"Much Asphalt\"].tolist()[0]\n",
        "top_k = 5\n",
        "cosine_similarities2 = cosine_similarity(tfidf[doc_index_to_compare2:doc_index_to_compare2 + 1], tfidf).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6itcLEIphL0e"
      },
      "source": [
        "related_docs_indices2 = cosine_similarities2.argsort()[:-top_k - 1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1FE6mZ6hL0f"
      },
      "source": [
        "tfidf_result_df2 = df[df.index.isin(related_docs_indices2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7YrG7trqhL0f",
        "outputId": "5095a027-d51c-4b4f-935c-244d4f397c73"
      },
      "source": [
        "pd.set_option('max_colwidth', None)\n",
        "tfidf_result_df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>country</th>\n",
              "      <th>founding_date</th>\n",
              "      <th>relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Much Asphalt</td>\n",
              "      <td>Much Asphalt is southern Africa’s commercial supplier of an extensive range of hot and cold asphalt products to the road construction economy. Much Asphalt owns and operates 15 static plants in the major centres of South Africa and is the majority shareholder in East Coast Asphalt which operates two more in East London and Mthatha.</td>\n",
              "      <td>South Africa</td>\n",
              "      <td>1965-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Sunland Asphalt</td>\n",
              "      <td>Sunland Asphalt, a commercial asphalt paving company in Phoenix, provides commercial asphalt paving service at competitive price.</td>\n",
              "      <td>United States</td>\n",
              "      <td>1979-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>Central-Allied Enterprises</td>\n",
              "      <td>Central States Construction was founded in 1929 by Ernest W. Hallett to produce sand and gravel and construct concrete highways in Minnesota. The business was successful, and in the early 1940s, operations expanded to western Ohio. In the 1940s, the company was heavily involved in the wartime expansion of Wright-Patterson Air Force Base and the post-war construction of the Ohio Turnpike. By the early 1950s, Ohio operations had expanded to include production of sand, gravel, asphalt, and concrete. The Ohio-based portion of the business became known as Allied Enterprises, and it made its permanent presence in Northeastern Ohio by the end of the 50s.  Today, Central-Allied Enterprises is one of northeastern Ohio's leading producers of sand, gravel, asphalt, and paved asphalt surfaces.</td>\n",
              "      <td>United States</td>\n",
              "      <td>1929-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>FAST FELT</td>\n",
              "      <td>The patented product FAST FELT®, with its plastic tabs pre-affixed to the asphalt saturated felt (commonly called \"tar paper\") is the only significant improvement in the recent history of the asphalt saturated felt underlayment products market.</td>\n",
              "      <td>United States</td>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1443</th>\n",
              "      <td>Saldus Celinieks</td>\n",
              "      <td>Saldus Celinieks is specialising in road construction, extraction of aggregates and asphalt production.</td>\n",
              "      <td>Latvia</td>\n",
              "      <td>1991-01-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            name  ... relevancy\n",
              "4                   Much Asphalt  ...         0\n",
              "57               Sunland Asphalt  ...         0\n",
              "618   Central-Allied Enterprises  ...         0\n",
              "862                    FAST FELT  ...         0\n",
              "1443            Saldus Celinieks  ...         1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw_rJMbRlC1_"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PJr_Z68lC1_"
      },
      "source": [
        "# Topic Modeling Using LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGyz7sGolC1_"
      },
      "source": [
        "from gensim import models, corpora, similarities\n",
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMxs7EntO8m6"
      },
      "source": [
        "\n",
        "### 1. Apply the pre_process function to the description-column to create a new column called `tokenized`. This is the column we plan to use for training the LDA-algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaA9PlG7RhNk"
      },
      "source": [
        "pre_processed = [prep_process_tokenize(item) for item in df.description]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNSRPkLNPJhZ",
        "outputId": "0e956402-7b2d-43fe-88d1-8da40993be31"
      },
      "source": [
        "# the pre-processed text of the first entry\n",
        "np.array(pre_processed[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['welcom', 'pandora', 'car', 'rental', 'car', 'hire', 'airport',\n",
              "       'transfer', 'base', 'dalaman', 'turkey', 'wide', 'rang', 'car',\n",
              "       'suit', 'budget', 'deliv', 'car', 'free', 'anytim', 'day', 'night',\n",
              "       'within', 'dalaman', 'local', 'reason', 'book', 'car', 'pandora',\n",
              "       'car', 'rental', 'unlimit', 'milag', 'vat', 'local', 'tax',\n",
              "       'airport', 'servic', 'charg', 'applic', 'hour', 'road', 'servic',\n",
              "       'third', 'parti', 'insur', 'excess', 'theft', 'insur', 'excess',\n",
              "       'fire', 'insur', 'excess', 'fdw', 'insur', 'excess', 'cdw',\n",
              "       'collis', 'damag', 'waiver', 'excess', 'twh', 'tyre', 'windscreen',\n",
              "       'headlight', 'insur', 'excess', 'addit', 'driver', 'childbabi',\n",
              "       'seat', 'must', 'order', 'hidden', 'extra', 'address', 'hadrian',\n",
              "       'flat', 'number', 'wellington', 'telford', 'pin', 'code', 'tfrq',\n",
              "       'tel', 'websit'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgm98NrOmis2"
      },
      "source": [
        "### 2. Using this new column `tokenized`, find the 5000 most common tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kyUC6Xxqo1U"
      },
      "source": [
        "\n",
        "\n",
        "> I am using the python Counter class to count the tokens in the pre_processed lists and get the first 5000 tokens.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccFlLUyaqTWZ",
        "outputId": "a0a1fe62-2c64-4a28-9f0b-67cbbb91436a"
      },
      "source": [
        "counter = Counter()\n",
        "\n",
        "for tokens in pre_processed:\n",
        "    counter.update(tokens)\n",
        "\n",
        "most_common = counter.most_common(5000) # most common 5000 words\n",
        "\n",
        "print(most_common[:5]) # the 5 most common words in the descriptions\n",
        "print(len(counter)) # the vocabulary size of the descriptions (unique pre-processed tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('servic', 1434), ('compani', 1180), ('provid', 1087), ('construct', 893), ('manag', 843)]\n",
            "10364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mco8yg7gr8aQ"
      },
      "source": [
        "\n",
        "\n",
        "> Extracting the most common words only (without the count) and saving it to a list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch0Dhe_3rep7",
        "outputId": "12bc239f-cbfb-48a1-cf18-f1a509de093f"
      },
      "source": [
        "most_common_5000 = [word for (word, number) in most_common]\n",
        "\n",
        "print(len(most_common_5000))\n",
        "most_common_5000[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['servic', 'compani', 'provid', 'construct', 'manag']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4qxBQI-mlDw"
      },
      "source": [
        "### 3. Remove all tokens that are not in the 5000 most common tokens from the column `tokenized`. \n",
        "\n",
        "\n",
        "\n",
        "> In order to do that I slightly changed the pre-process function as can be seen below (additional comment at line 10)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EDClkuZtAN6"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def prep_process_tokenize_lda(text, most_common):\n",
        "    #websites, email and any punctuation cleaning\n",
        "    text = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", text)\n",
        "    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n",
        "    text = text.lower() # lower case the text\n",
        "    text = nltk.word_tokenize(text)\n",
        "    #removing stopwords\n",
        "    text = [word for word in text if word not in stopwords and word in most_common] # only adds the word if it is in the most common list which is passed as an argument\n",
        "    #stemming\n",
        "    try:\n",
        "        text = [stemmer.stem(word) for word in text]\n",
        "        text = [word for word in text if len(word) > 1]\n",
        "    except IndexError:\n",
        "        pass\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnkB6l5dQXel"
      },
      "source": [
        "\n",
        "\n",
        "> Finally, the decriptions are pre-processed using the new function above and then saved to the 'tokenized' column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1sO6dQbmlYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed07558-b6cd-4f73-e662-edba0f223311"
      },
      "source": [
        "pre_processed_only_most_common = [prep_process_tokenize_lda(text, most_common_5000) for text in df.description]\n",
        "df['tokenized'] = pre_processed_only_most_common\n",
        "\n",
        "np.array(df.iloc[0]['tokenized']) # displaying the same entry (the first one) as in the first step. The list is much shorter, so the tokens must have been removed."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['pandora', 'car', 'rental', 'car', 'hire', 'airport', 'dalaman',\n",
              "       'turkey', 'wide', 'suit', 'car', 'free', 'day', 'night', 'within',\n",
              "       'dalaman', 'book', 'car', 'pandora', 'car', 'rental', 'vat',\n",
              "       'local', 'airport', 'road', 'third', 'excess', 'theft', 'excess',\n",
              "       'fire', 'excess', 'fdw', 'excess', 'cdw', 'waiver', 'excess',\n",
              "       'twh', 'tyre', 'windscreen', 'headlight', 'excess', 'seat', 'must',\n",
              "       'hidden', 'address', 'hadrian', 'number', 'wellington', 'telford',\n",
              "       'pin', 'code', 'tfrq', 'tel'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYe0E4gPmliQ"
      },
      "source": [
        "### 4. Implement and execute the `train_lda`-function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF7xqU_alC2C"
      },
      "source": [
        "def train_lda(data, num_topics, chunksize):\n",
        "    \"\"\"Train LDA.\n",
        "    Args:\n",
        "        data: dataframe, the company data\n",
        "        num_topics: int, the number of topics \n",
        "        chunksize: int\n",
        "    Returns:\n",
        "        lda: gensim.models.lda, trained-lda-model    \n",
        "    \"\"\"\n",
        "\n",
        "    # extract the tokenized descriptions and convert it to a list of lists\n",
        "    tokenized_corpus = data.tokenized.tolist()\n",
        "\n",
        "    # map every token to an index\n",
        "    id2word = corpora.Dictionary(tokenized_corpus)\n",
        "\n",
        "    # represents the corpus as tuples of (word-id, document-id)\n",
        "    corpus = [id2word.doc2bow(text) for text in tokenized_corpus]\n",
        "\n",
        "    # trains the lad model\n",
        "    lda = models.ldamodel.LdaModel(num_topics=num_topics, corpus=corpus, chunksize=chunksize, id2word=id2word)\n",
        "\n",
        "    return lda, corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gry4MVLW-Arr"
      },
      "source": [
        "# setting the number of topics and documents\n",
        "num_topics = 10\n",
        "num_documents = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtI7b8zhmlq6"
      },
      "source": [
        "lda, corpus = train_lda(df, num_topics, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGqeqUPmlzn"
      },
      "source": [
        "### 5. Use the `show_topic`-method to inspect the resulting topics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L2y-Gbzmqln",
        "outputId": "cc3bb330-7635-4ea7-b879-6d62f0c225ed"
      },
      "source": [
        "for i in range(num_topics):\n",
        "    print(f'Topic {i + 1}:\\t{lda.show_topic(i)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1:\t[('us', 0.08441924), ('product', 0.05906464), ('per', 0.041050255), ('use', 0.034521285), ('need', 0.03449909), ('get', 0.026101355), ('user', 0.024941608), ('oil', 0.022503605), ('model', 0.022414615), ('month', 0.020604176)]\n",
            "Topic 2:\t[('new', 0.064639285), ('one', 0.033055004), ('market', 0.030082464), ('ltd', 0.027648075), ('north', 0.025136624), ('brand', 0.02405977), ('retail', 0.022389904), ('across', 0.021522088), ('largest', 0.019195445), ('app', 0.018886173)]\n",
            "Topic 3:\t[('also', 0.09852923), ('project', 0.0884902), ('design', 0.072434366), ('drone', 0.04401816), ('space', 0.03269703), ('control', 0.02280834), ('fire', 0.022779142), ('cad', 0.021886786), ('supplier', 0.020904863), ('two', 0.01955086)]\n",
            "Topic 4:\t[('platform', 0.088589504), ('first', 0.06644707), ('offer', 0.045008965), ('access', 0.03368234), ('top', 0.028817791), ('search', 0.026314778), ('tool', 0.01902847), ('track', 0.017303605), ('region', 0.016465008), ('launch', 0.015878765)]\n",
            "Topic 5:\t[('car', 0.061606515), ('work', 0.03839919), ('home', 0.038164966), ('support', 0.03142462), ('wide', 0.027080894), ('florida', 0.0194999), ('rental', 0.017314551), ('life', 0.017226864), ('great', 0.016245319), ('fleet', 0.015772201)]\n",
            "Topic 6:\t[('local', 0.05094944), ('throughout', 0.046698555), ('help', 0.03914553), ('like', 0.03410078), ('store', 0.033940103), ('canada', 0.025565654), ('free', 0.02057901), ('conduct', 0.018976536), ('contractor', 0.015703764), ('valley', 0.015489619)]\n",
            "Topic 7:\t[('inc', 0.05364506), ('group', 0.045228), ('cargo', 0.040016767), ('power', 0.028770374), ('food', 0.02662462), ('make', 0.024739817), ('air', 0.024357926), ('global', 0.023117103), ('world', 0.02231179), ('leader', 0.019574262)]\n",
            "Topic 8:\t[('steel', 0.053082444), ('best', 0.051498964), ('process', 0.038969595), ('team', 0.026412692), ('today', 0.024717309), ('develop', 0.02263554), ('along', 0.021380696), ('tech', 0.019318817), ('find', 0.016104445), ('distributor', 0.014509259)]\n",
            "Topic 9:\t[('system', 0.045638025), ('network', 0.039421316), ('chain', 0.034769062), ('cost', 0.030962704), ('data', 0.02939287), ('time', 0.028372979), ('price', 0.027522666), ('within', 0.025265358), ('well', 0.023312286), ('high', 0.022485912)]\n",
            "Topic 10:\t[('transport', 0.04855396), ('bim', 0.04675472), ('scale', 0.032990333), ('india', 0.030340776), ('way', 0.028490497), ('full', 0.02814267), ('order', 0.025197234), ('central', 0.023811577), ('small', 0.022139948), ('delhi', 0.021589322)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvFP2mzvy4mo",
        "outputId": "c961b6aa-7dd1-4800-ea24-1173d9c13c4c"
      },
      "source": [
        "lda.show_topic(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('system', 0.045638025),\n",
              " ('network', 0.039421316),\n",
              " ('chain', 0.034769062),\n",
              " ('cost', 0.030962704),\n",
              " ('data', 0.02939287),\n",
              " ('time', 0.028372979),\n",
              " ('price', 0.027522666),\n",
              " ('within', 0.025265358),\n",
              " ('well', 0.023312286),\n",
              " ('high', 0.022485912)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrKrrbM0mq9R"
      },
      "source": [
        "### 6. Convert the LDA-results to a 2D array to use as a document-matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkP8N9GtmrR3"
      },
      "source": [
        "document_matrix = np.array([[prob for (topic, prob) in lda.get_document_topics(bow, minimum_probability=0)] for bow in corpus])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwmBoUBc7MoR"
      },
      "source": [
        "\n",
        "\n",
        "> The maxtrix is 2D, each document is represented by the probabilities for the each topic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqqPC7v53xMg",
        "outputId": "7eae9210-1d37-4691-a756-d490deac4a80"
      },
      "source": [
        "document_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VoxkF2g7JDH",
        "outputId": "4230e805-868f-4dba-fa38-55de09af37af"
      },
      "source": [
        "document_matrix[0] # the representation of the first document"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00185279, 0.19335058, 0.05452616, 0.00185207, 0.35391006,\n",
              "       0.10978115, 0.00185213, 0.08203942, 0.19898348, 0.00185214],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmD2M-4qmrf9"
      },
      "source": [
        "### 7. Extract the LDA-results for `Much Asphalt` and `Vahanalytics` and use them as a query vector to extract the 5 most closest matches using `get_top_k_similar_docs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyKLaG5qlC2E"
      },
      "source": [
        "def jensen_shannon(query, matrix):\n",
        "    p = query[None,:].T + np.zeros([num_topics, num_documents])\n",
        "    q = matrix.T\n",
        "    m = 0.5*(p + q)\n",
        "    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))\n",
        "\n",
        "def get_top_k_similar_docs(query, matrix, k=10):\n",
        "    \"\"\"Get the <k> most similar documents (represented by <matrix>) given a <query>.\n",
        "\n",
        "    Args:\n",
        "        query: 1D array\n",
        "        matrix: 2D array\n",
        "        k: int\n",
        "    \"\"\"\n",
        "    sims = jensen_shannon(query,matrix)\n",
        "    return sims.argsort()[:k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssuKVpxz-zUP"
      },
      "source": [
        "#### Results for Much Asphalt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aMPKPf57irm",
        "outputId": "e903a5f5-bcfa-4f2c-be35-595f5b5de2bd"
      },
      "source": [
        "doc_index_much_asphalt = df.index[df['name'] == \"Much Asphalt\"].tolist()[0]\n",
        "probabilities_asphalt = document_matrix[doc_index_much_asphalt]\n",
        "\n",
        "# gets the class number with the highest probability\n",
        "probabilities_asphalt.argmax()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlL4aWkM9l3o"
      },
      "source": [
        "\n",
        "\n",
        "> Looking at the most common words for the most probable topic for the 'Much Asphalt' company\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ_SYl0r9gy3",
        "outputId": "3bfd7471-f8e8-4aaf-8687-5e11f3afe830"
      },
      "source": [
        "lda.show_topic(probabilities_asphalt.argmax())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('also', 0.09852923),\n",
              " ('project', 0.0884902),\n",
              " ('design', 0.072434366),\n",
              " ('drone', 0.04401816),\n",
              " ('space', 0.03269703),\n",
              " ('control', 0.02280834),\n",
              " ('fire', 0.022779142),\n",
              " ('cad', 0.021886786),\n",
              " ('supplier', 0.020904863),\n",
              " ('two', 0.01955086)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E93CyBrWGJE"
      },
      "source": [
        "\n",
        "\n",
        "> extracting the most similar documents for 'Much Asphalt'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "dlSuFmsXzu6N",
        "outputId": "ded3758a-542f-49d0-f489-b681b9923d85"
      },
      "source": [
        "most_similar_docs_asphalt = df[df.index.isin(get_top_k_similar_docs(probabilities_asphalt, document_matrix, 5))]\n",
        "most_similar_docs_asphalt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>country</th>\n",
              "      <th>founding_date</th>\n",
              "      <th>relevancy</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Much Asphalt</td>\n",
              "      <td>Much Asphalt is southern Africa’s commercial supplier of an extensive range of hot and cold asphalt products to the road construction economy. Much Asphalt owns and operates 15 static plants in the major centres of South Africa and is the majority shareholder in East Coast Asphalt which operates two more in East London and Mthatha.</td>\n",
              "      <td>South Africa</td>\n",
              "      <td>1965-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>[much, asphalt, southern, supplier, hot, cold, asphalt, road, much, asphalt, static, major, south, africa, east, coast, asphalt, two, east, london, mthatha]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>ALSO Holding AG</td>\n",
              "      <td>ALSO Holding AG bundles logistics, financial, supply, solution, digital, and IT services together into individual service packages. The company offers services at all levels of the ICT value chain from a single source. It also provides customized services in the logistics, finance, information technology, and digital services sectors, as well as traditional distribution services. The company serves corporate resellers, value added resellers, small and medium-sized business resellers, retailers, and retailer channels.  ALSO Holding AG is a Switzerland-based company that was founded in 1984.</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>1984-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>[also, ag, chain, also, well, small, also, ag]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>VolkerWessels</td>\n",
              "      <td>VolkerWessels is a construction firm that is focused on the design, development, realisation and management of construction projects. The Company's primary activities include real estate development, construction, civil engineering, railway construction, road construction, urban mobility objects construction, and energy networks construction, among others.</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>1854-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>[firm, design, real, civil, railway, road, urban, among]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1443</th>\n",
              "      <td>Saldus Celinieks</td>\n",
              "      <td>Saldus Celinieks is specialising in road construction, extraction of aggregates and asphalt production.</td>\n",
              "      <td>Latvia</td>\n",
              "      <td>1991-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>[road, asphalt]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1706</th>\n",
              "      <td>Blumatica</td>\n",
              "      <td>Blumatica develops software solutions for the construction industry. Its solutions are also targeted at security, design and public sector companies. It offers solutions for creating BIM models, creating 2D/3D designs, designing scaffoldings &amp; other structures, estimate security costs on a construction site, design construction site layouts, and more.</td>\n",
              "      <td>Italy</td>\n",
              "      <td>1996-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>[also, design, public, sector, bim, site, design, site]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  name  ...                                                                                                                                                     tokenized\n",
              "4         Much Asphalt  ...  [much, asphalt, southern, supplier, hot, cold, asphalt, road, much, asphalt, static, major, south, africa, east, coast, asphalt, two, east, london, mthatha]\n",
              "312    ALSO Holding AG  ...                                                                                                                [also, ag, chain, also, well, small, also, ag]\n",
              "338      VolkerWessels  ...                                                                                                      [firm, design, real, civil, railway, road, urban, among]\n",
              "1443  Saldus Celinieks  ...                                                                                                                                               [road, asphalt]\n",
              "1706         Blumatica  ...                                                                                                       [also, design, public, sector, bim, site, design, site]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sT2hI8I-3nd"
      },
      "source": [
        "#### Results for Vahanalystics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWAm_Cwv7ef6",
        "outputId": "9432ae4a-a017-4d30-d11d-0eb1236e0619"
      },
      "source": [
        "doc_index_vahanalysitcs = df.index[df['name'] == \"Vahanalytics\"].tolist()[0]\n",
        "probabilities_vahana = document_matrix[doc_index_vahanalysitcs]\n",
        "\n",
        "# gets the class number with the highest probability\n",
        "probabilities_vahana.argmax()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfXoHmJ69wUo"
      },
      "source": [
        "> Looking at the most common words for the most probable topic for the 'Vahanalytics' company"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VyuT6fx9im2",
        "outputId": "7423e398-1b63-4f54-b3e9-1676f650d907"
      },
      "source": [
        "lda.show_topic(probabilities_vahana.argmax())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('system', 0.045638025),\n",
              " ('network', 0.039421316),\n",
              " ('chain', 0.034769062),\n",
              " ('cost', 0.030962704),\n",
              " ('data', 0.02939287),\n",
              " ('time', 0.028372979),\n",
              " ('price', 0.027522666),\n",
              " ('within', 0.025265358),\n",
              " ('well', 0.023312286),\n",
              " ('high', 0.022485912)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK1GzO1yWfDq"
      },
      "source": [
        "\n",
        "\n",
        "> extracting the most similar documents for 'Vahanalytics'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "abpOa5Znz1bU",
        "outputId": "9c7c1049-fe6f-4819-dbcd-c574fdf1aa19"
      },
      "source": [
        "most_similar_docs_vahana = df[df.index.isin(get_top_k_similar_docs(probabilities_vahana, document_matrix, 5))]\n",
        "most_similar_docs_vahana"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>country</th>\n",
              "      <th>founding_date</th>\n",
              "      <th>relevancy</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>Vanguard Logistics Services</td>\n",
              "      <td>Vanguard Logistics Services is the neutral freight consolidation service, offering forwarders and customers of all sizes the world’s largest owned LCL (Less Than Container Load) end-to-end network, unparalleled schedule integrity, and industry-leading information technology applications.</td>\n",
              "      <td>United States</td>\n",
              "      <td>2001-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>[neutral, freight, largest, lcl, less, load, endtoend, network]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>Paradise Exteriors</td>\n",
              "      <td>Paradise Exteriors is a family owned and operated business. their advantage is the ability to give high quality windows and low prices!</td>\n",
              "      <td>United States</td>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>[give, high, low]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>Vahanalytics</td>\n",
              "      <td>Vahanalytics aims to create better drivers and safer roads by using cutting edge big data and machine learning techniques.</td>\n",
              "      <td>India</td>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>[better, safer, big, data]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>Reach</td>\n",
              "      <td>Reach Promoters Pvt. Ltd. is a development Company promoted by the professionals having over 20 years of real estate domain expertise in consulting and advisory, empowered by transparency, consistency and commitment. Reach brings to life modern concepts &amp; technology aligned with an Indian touch showcasing new thoughts &amp; ideology to real estate development in this country thus by awarding luxury of urban scene in their upcoming high street retail destination clubbed with the state-of-art office spaces together managing a spread of close to a million sq. ft., along with more projects in the pipeline. Reach Promoters’ firm belief is in a well conceptualized and thought provoked world of Retail and Commercial Office suites rather than static concrete structures. Professionals at Reach stand committed to create life &amp; experience in all their endeavors, today and forever to provide volume and velocity of the footfall. Our projects shall bring happiness through our expertise and well laid down thoughts taking care of not only great concepts and designs but also executing them with finesse which shall stand the test of all times. Reach shall deliver high quality projects with the commitment of on time delivery while showcasing the Class and Quality in all their Developments.</td>\n",
              "      <td>India</td>\n",
              "      <td>2015-03-01</td>\n",
              "      <td>2</td>\n",
              "      <td>[reach, pvt, ltd, real, domain, reach, life, modern, indian, touch, new, real, urban, scene, high, street, retail, spread, close, million, sq, ft, along, reach, firm, well, thought, world, retail, rather, static, reach, stand, life, today, shall, bring, well, laid, care, great, also, shall, stand, test, reach, shall, high, time, class]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>Cryo Storage Solutions</td>\n",
              "      <td>Cryo Storage Solutions offers cryogenic and -80°c storage, disaster recovery and product/risk management services. They are knowledgeable about the nitrogen and passionate about the paperwork. They know about the cold stuff, letting you get on with the smart stuff. They hold the exclusive distribution territories of the UK and Eire for cryotherm of Germany, and can therefore supply you with high quality and highly efficient bio-banks, dewars, and SiVL pipework systems. Cryo Storage Solutions can offer a supply only arrangement or full turnkey installation services too.</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>[cryo, nitrogen, paperwork, know, cold, stuff, get, smart, stuff, hold, uk, high, cryo, offer, full, turnkey]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             name  ...                                                                                                                                                                                                                                                                                                                                          tokenized\n",
              "130   Vanguard Logistics Services  ...                                                                                                                                                                                                                                                                                    [neutral, freight, largest, lcl, less, load, endtoend, network]\n",
              "254            Paradise Exteriors  ...                                                                                                                                                                                                                                                                                                                                  [give, high, low]\n",
              "695                  Vahanalytics  ...                                                                                                                                                                                                                                                                                                                         [better, safer, big, data]\n",
              "1262                        Reach  ...  [reach, pvt, ltd, real, domain, reach, life, modern, indian, touch, new, real, urban, scene, high, street, retail, spread, close, million, sq, ft, along, reach, firm, well, thought, world, retail, rather, static, reach, stand, life, today, shall, bring, well, laid, care, great, also, shall, stand, test, reach, shall, high, time, class]\n",
              "1350       Cryo Storage Solutions  ...                                                                                                                                                                                                                                      [cryo, nitrogen, paperwork, know, cold, stuff, get, smart, stuff, hold, uk, high, cryo, offer, full, turnkey]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1vM2uceXUS8"
      },
      "source": [
        "\n",
        "\n",
        "> Write it to excel to easily put it in the labreport\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWkxrObcXEnz"
      },
      "source": [
        "most_similar_docs_vahana.to_excel(\"vahan.xlsx\")\n",
        "most_similar_docs_asphalt.to_excel(\"asphalt.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}