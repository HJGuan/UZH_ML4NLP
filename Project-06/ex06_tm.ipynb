{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "ex06_topic_modeling_given.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hENmFU8FmZbl",
        "outputId": "a98f4c61-2483-46de-b9cf-7e4db683ed5d"
      },
      "source": [
        "!pip install contextualized-topic-models==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contextualized-topic-models==2.2.0 in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (4.62.3)\n",
            "Requirement already satisfied: ipywidgets==7.5.1 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (7.5.1)\n",
            "Requirement already satisfied: ipython==7.16.1 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (7.16.1)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wordcloud>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (1.8.1)\n",
            "Requirement already satisfied: gensim>=3.8.3 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: sentence-transformers>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from contextualized-topic-models==2.2.0) (2.1.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (3.0.23)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (0.18.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->contextualized-topic-models==2.2.0) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (3.5.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (5.1.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.8.3->contextualized-topic-models==2.2.0) (5.2.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (5.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.16.1->contextualized-topic-models==2.2.0) (0.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.2.0) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.2.0) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.2.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models==2.2.0) (2.8.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (4.9.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.16.1->contextualized-topic-models==2.2.0) (0.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.3->contextualized-topic-models==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (0.1.96)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (4.12.5)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (0.10.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->contextualized-topic-models==2.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.7.0->contextualized-topic-models==2.2.0) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.12.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models==2.2.0) (0.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers>=1.1.1->contextualized-topic-models==2.2.0) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAwbguDJlC1m"
      },
      "source": [
        "## Import General Utility Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci16zWWnlC1n"
      },
      "source": [
        "import re\n",
        "import urllib\n",
        "import gzip\n",
        "import io\n",
        "import csv\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SacDQZfHWb7t"
      },
      "source": [
        "Where to store the data file. If you want, you can adjust the path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_mkS_zeWbYW"
      },
      "source": [
        "path_before_1990 = '/content/drive/My Drive/titles_before_1990.txt'\n",
        "path_from_1990_to_2009 = '/content/drive/My Drive/titles_from_1990_to_2009.txt'\n",
        "path_from_2010 = '/content/drive/My Drive/titles_from_2010.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohMkrs8AWau"
      },
      "source": [
        "Execute the following cell only once to download the data and write it as a file to your google drive. Afterwards, skip this cell or comment it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUVy4jyGlVH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d568967-cb7a-4f9c-ba20-0cc81742b165"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# to download the data manually or get more information, go to: https://dblp.org/faq/How+can+I+download+the+whole+dblp+dataset.html\n",
        "url = 'https://dblp.uni-trier.de/xml/dblp.xml.gz'\n",
        "num_titles = 500000  # the (max)number of titles to load \n",
        "\n",
        "\n",
        "def load_gzip_file(url):\n",
        "    \"\"\"Download Gzip-file.\"\"\"\n",
        "    response = urllib.request.urlopen(url)\n",
        "    compressed_file = io.BytesIO(response.read())\n",
        "    decompressed_file = gzip.GzipFile(fileobj=compressed_file)\n",
        "    return decompressed_file\n",
        "\n",
        "def extract_titles(input_file, max_num=40000):\n",
        "    \"\"\"Extract title and publication year of dblp papers, given as input file.\n",
        "    \n",
        "    Divide the papers into 3 time periods. \n",
        "    \n",
        "    Collect max max_num papers per time period.\n",
        "    \"\"\"\n",
        "    pairs_before_1990 = []\n",
        "    count_before_1990 = 0\n",
        "    pairs_from_1990_to_2009 = []\n",
        "    count_from_1990_to_2009 = 0\n",
        "    pairs_from_2010 = []\n",
        "    count_from_2010 = 0\n",
        "    got_title = False\n",
        "    for line in tqdm(input_file):\n",
        "        line_str = line.decode('utf-8')\n",
        "        if got_title: \n",
        "            # we have a title and check for the corresponding year\n",
        "            year_result = re.search(r'<year>(.*)</year>', line_str)\n",
        "            if year_result:\n",
        "                # we also have the year and thus save the title-year pair\n",
        "                year = int(year_result.group(1))\n",
        "                if year < 1990:\n",
        "                    pairs_before_1990.append((title, year))\n",
        "                    count_before_1990 += 1\n",
        "                elif year < 2010:\n",
        "                    pairs_from_1990_to_2009.append((title, year))\n",
        "                    count_from_1990_to_2009 += 1\n",
        "                else:\n",
        "                    pairs_from_2010.append((title, year))\n",
        "                    count_from_2010 += 1\n",
        "                got_title = False\n",
        "        else:\n",
        "            # we have no title and search for title\n",
        "            result = re.search(r'<title>(.*)</title>', line_str)\n",
        "            if result:\n",
        "                title = result.group(1)\n",
        "                if len(title.split(' ')) < 3:  \n",
        "                    # only include titles with at least four words\n",
        "                    continue\n",
        "                got_title = True\n",
        "        \n",
        "        if count_before_1990 >= max_num and count_from_1990_to_2009 >= max_num and count_from_2010 >= max_num:\n",
        "            return pairs_before_1990, pairs_from_1990_to_2009, pairs_from_2010\n",
        "    \n",
        "    return pairs_before_1990, pairs_from_1990_to_2009, pairs_from_2010\n",
        "\n",
        "def save_data(pairs, file_path):\n",
        "    with open(file_path, 'w') as fout:\n",
        "        writer = csv.writer(fout)\n",
        "        for pair in pairs:\n",
        "            writer.writerow(pair)\n",
        "\n",
        "in_file = load_gzip_file(url)\n",
        "pairs_before_1990, pairs_from_1990_to_2009, pairs_from_2010 = extract_titles(in_file)\n",
        "save_data(pairs_before_1990, path_before_1990)\n",
        "save_data(pairs_from_1990_to_2009, path_from_1990_to_2009)\n",
        "save_data(pairs_from_2010, path_from_2010)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13472206it [00:46, 292313.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYm5UB9bVJXw"
      },
      "source": [
        "Mount your google drive (in case it is not yet mounted) so that the newly created files are available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECGA0pbRlqZi",
        "outputId": "3cd557d8-4c55-4478-e39f-98941e69dd90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDhEoD2Tsh3z"
      },
      "source": [
        "# LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ86sQwo124U"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "num_lda_topics = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc09sFDe-5kn"
      },
      "source": [
        "### Before the 1990s:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rwq6kF7vqUj"
      },
      "source": [
        "with open(path_before_1990) as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    titles = [row[0] for row in reader]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmKJDHwI2Dnp"
      },
      "source": [
        "Let's perform some simple preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vmu77l62DCp"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "prepro_titles = [preprocess_text(title) for title in titles]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mulG5Sg2NBZ",
        "outputId": "2ed5395c-7ce7-4c4d-fff8-2bc82d02d490"
      },
      "source": [
        "prepro_titles[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['object model capabilities for distributed object management',\n",
              " 'distributed object management technology',\n",
              " 'muffin a distributed database machine',\n",
              " 'algebraical optimization of ftaexpressions',\n",
              " 'wissensrepraumlsentation und maschinelles lernen',\n",
              " 'an algebraic characterization of stuf',\n",
              " 'zur systemarchitektur von lilog',\n",
              " 'mengenorientierte auswertung von anfragen in der logikprogrammiersprache prolog',\n",
              " 'definite resolution over constraint languages',\n",
              " 'dokumentation der syntax der liloggrammatik']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGEy1_fR3CpQ"
      },
      "source": [
        "Now we turn the documents (or titles in this case) into a matrix feature representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhgxgCM_01mx"
      },
      "source": [
        "num_features = 10000\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=num_features, stop_words='english')\n",
        "tf = tf_vectorizer.fit_transform(prepro_titles)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names_out()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_927CQlk4C27"
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=num_lda_topics, max_iter=5, learning_method='online', random_state=42).fit(tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-8NinuI4kMG",
        "outputId": "90959f3d-c407-4d11-a5b1-fbc3e7b63838"
      },
      "source": [
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(f'Topic {topic_idx}:', end=' ')\n",
        "    print(' '.join([tf_feature_names[i] for i in topic.argsort()[:-12 - 1:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: design algorithm networks data network sequential application logic applications graphs time languages\n",
            "Topic 1: systems linear recognition control sets machines pattern binary approach dynamic comments use\n",
            "Topic 2: analysis programming digital problem logic language theory processing memory simulation chemical structures\n",
            "Topic 3: optimal problems circuits model der von evaluation synthesis research und nonlinear management\n",
            "Topic 4: computer using systems note control functions new parallel information distributed finite number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbx0DythfCkP"
      },
      "source": [
        "Topics:\n",
        "0. Graph/networks algorithms (seems to be mostly about algorithms that (maybe) operate on graphs/networks)\n",
        "1. pattern recognition (and maybe robotics)\n",
        "2. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqioi0rG_Dz9"
      },
      "source": [
        "### From 1990 to 2009:\n",
        "\n",
        "Add your code for topic modelling the period from 1990 to 2009 here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip_z250Z_Mnz"
      },
      "source": [
        "### From 2010 onwards:\n",
        "\n",
        "Add your code for topic modelling the period from 2010 onwards here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pStFBikpsRTz"
      },
      "source": [
        "# Combined Topic Models\n",
        "\n",
        "New method developed by [Bianchi et al. 2021](https://aclanthology.org/2021.acl-short.96/). \n",
        "\n",
        "[A 6min presentation of the paper by one of the authors.](https://underline.io/lecture/25716-pre-training-is-a-hot-topic-contextualized-document-embeddings-improve-topic-coherence)\n",
        "\n",
        "Code: [https://github.com/MilaNLProc/contextualized-topic-models](https://github.com/MilaNLProc/contextualized-topic-models)\n",
        "\n",
        "Tutorial: [https://colab.research.google.com/drive/1fXJjr_rwqvpp1IdNQ4dxqN4Dp88cxO97?usp=sharing](https://colab.research.google.com/drive/1fXJjr_rwqvpp1IdNQ4dxqN4Dp88cxO97?usp=sharing)\n",
        "\n",
        "Again, perform topic modelling for the three time periods - this time using the combined topic models (CTMs). \n",
        "\n",
        "You can use and adapt the code from the tutorial linked above.\n",
        "\n",
        "Use the available GPU for faster running times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNsJrV2DJ8GO"
      },
      "source": [
        "from contextualized_topic_models.models.ctm import CombinedTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
        "\n",
        "num_ctm_topics = 5  # you can also choose a higher number of topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSv9Ch46LFxp"
      },
      "source": [
        "### Before the 1990s:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNRaJJEMiVQb"
      },
      "source": [
        "### From 1990 to 2009"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfgbLy0KiZ5b"
      },
      "source": [
        "### From 2010 onwards"
      ]
    }
  ]
}