{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex04_ner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20bxqzVMeMdE",
        "outputId": "75d07704-44b7-4400-9d65-bc585f9a0791"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-dwpv002_\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-dwpv002_\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): transformers==4.0.0.dev0 from git+https://github.com/huggingface/transformers in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0.dev0) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0.dev0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0.dev0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0.dev0) (2.4.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.0.0.dev0-cp36-none-any.whl size=1345022 sha256=ed86f882d440a8107c37c238ef7c537a4b60f8d4675bb0a0851b2ce581bf96e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-opt_9zr1/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoN5k0v32XWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80db3ed-1930-462d-d62c-0717827ba6e7"
      },
      "source": [
        "!pip install datasets sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from datasets) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHnMUTFyQkQV"
      },
      "source": [
        "from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments, AutoConfig\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94hZnKv_Mfqm"
      },
      "source": [
        "# Getting to know the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYCaelIOVEuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5ee0ba-6d3d-4fbb-806e-e8f5e549463d"
      },
      "source": [
        "import datasets\n",
        "dataset = datasets.load_dataset('polyglot_ner', 'de', split='train[:8000]')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset polyglot_ner (/root/.cache/huggingface/datasets/polyglot_ner/de/1.0.0/c929318589a30ee3f0dc5d53f1f99bf25a7ec16d3f319b3b671765c5ea464c99)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WggRARK4OLIh"
      },
      "source": [
        "checking the lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmC3MHjvLip0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acfce8a-2cef-49a5-ef22-1b2e62164244"
      },
      "source": [
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6KT3bPeMjpJ"
      },
      "source": [
        "example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l_9RLy5MKH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10ddc7e-b913-4366-fb5d-fc392e890be0"
      },
      "source": [
        "dataset[456]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '456',\n",
              " 'lang': 'de',\n",
              " 'ner': ['O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
              " 'words': ['Mitautor',\n",
              "  'Ben',\n",
              "  'Bernie',\n",
              "  'spielte',\n",
              "  'den',\n",
              "  'Song',\n",
              "  'am',\n",
              "  '19',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZZwa_mypUUh"
      },
      "source": [
        "loading the BERT tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fci-cCRNMOhk"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W07ClaB5pXRz"
      },
      "source": [
        "# Encoding the Dataset\n",
        "\n",
        "> first the words...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeQXtCC0QyK8"
      },
      "source": [
        "encoded_dataset = [tokenizer(item['words'], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512, is_split_into_words=True) for item in dataset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf_oy5aScc4g"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOQ1laVTpaoL"
      },
      "source": [
        "\n",
        "> ...then the labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0gbq4gjir5T"
      },
      "source": [
        "le = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PvQP2qet1se"
      },
      "source": [
        "As can be seen below, the labels in this dataset are\n",
        "\n",
        "\n",
        "*   ``LOC, O, ORG, PER``\n",
        "\n",
        "I decided to keep those labels as they are, because I think it makes sense that the classifier learns to classify those fine-grained labels. Even though the labels are not in the classical IOB-format as explained in the lecture and tutorial. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4xNfcd7JHt1"
      },
      "source": [
        "# setting the labels manually because there are so little, I previously extracted them from the dataset\n",
        "# I added an <UNK> token in case that there is another label in the test set. Additionally, I added a <PAD> label because I want\n",
        "# to exclude this in the end for the eval. \n",
        "labels_correct = ['<UNK>', '<PAD>', 'LOC', 'O', 'ORG', 'PER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLrdbJvnchHj"
      },
      "source": [
        "y_encoded = []\n",
        "le.fit(labels_correct)\n",
        "\n",
        "for idx, item in enumerate(dataset['ner']):\n",
        "    item = ['<UNK>' if s not in le.classes_ else s for s in item]\n",
        "    y_encoded.append(le.transform(item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y45cQQZcKmzX",
        "outputId": "7c3389e5-57fb-412d-dd83-d4a4df641b6d"
      },
      "source": [
        "print(le.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<PAD>' '<UNK>' 'LOC' 'O' 'ORG' 'PER']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVxRYGNsKsPm"
      },
      "source": [
        "> checking the encoded labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmK8D0tAKgx_",
        "outputId": "73a3936f-bdfb-4dc6-a017-35827efa64c3"
      },
      "source": [
        "print(len(y_encoded))\n",
        "print(y_encoded[2]) # note that the 3 refers to 'O' and 4 to 'ORG' given the order of the labels above"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "[3 3 3 3 3 3 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IB64SGkpx25"
      },
      "source": [
        "\n",
        "\n",
        "> Zipping the words and the labels together again \\\\\n",
        "> Padding the labels to the same length as the words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SppbsATSwFQi"
      },
      "source": [
        "import torch\n",
        "for enc_item, item in zip(encoded_dataset, y_encoded):\n",
        "    i = item.size\n",
        "    while i < 512:\n",
        "         item = np.append(item, 0)\n",
        "         i += 1\n",
        "    enc_item['labels'] = torch.LongTensor([item])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RkTTBMHqMKA"
      },
      "source": [
        "> Shuffeling the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KEkRXT4-0Ni"
      },
      "source": [
        "from random import shuffle\n",
        "shuffle(encoded_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnTooa7RqPHU"
      },
      "source": [
        "#Getting the model and the dataset ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifDVhyiCQyTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648f4088-b4d2-4446-c371-ffb5408a4067"
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained('bert-base-german-cased', num_labels=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kXgQpDI74Zr"
      },
      "source": [
        "### Optional: Freeze the embeddings\n",
        "\n",
        "\n",
        "> The following code block was only executed for those models that needed to be trained with frozen embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdU8ihAjND6u"
      },
      "source": [
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuJy9UtNJRYR"
      },
      "source": [
        "### Preparing the dataset\n",
        "\n",
        "> This next cell squeezes the tensors in the dataset such that they are basically just one list with the numbers in it. This can be seen a few cells below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtlOQ2l1XH1F"
      },
      "source": [
        "for item in encoded_dataset:\n",
        "    for key in item:\n",
        "        item[key] = torch.squeeze(item[key])\n",
        "        \n",
        "train_set_small = encoded_dataset[:1000]\n",
        "train_set_big = encoded_dataset[1000:6000]\n",
        "test_set = encoded_dataset[6000:8000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_qD6t3PJrQE"
      },
      "source": [
        "> Checking the dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQlHTnlstUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3ca363-7d1a-4ef7-f4e1-ba2ef0316918"
      },
      "source": [
        "for key, val in test_set[3].items():\n",
        "    print(f'key: {key}, dimensions: {val.size()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key: input_ids, dimensions: torch.Size([512])\n",
            "key: token_type_ids, dimensions: torch.Size([512])\n",
            "key: attention_mask, dimensions: torch.Size([512])\n",
            "key: labels, dimensions: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVVHYMUVYdG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6e07fc-810c-4e2e-df15-957aeaa2c647"
      },
      "source": [
        "print(len(train_set_big))\n",
        "print(len(train_set_small))\n",
        "print(len(test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "1000\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnYOG5FvA7ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbc57e8-a189-4e74-bbb6-1dc8c352a72c"
      },
      "source": [
        "# checking that everything is correct\n",
        "train_set_big[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    3,  1718,  1195,    21,   417,    21,   255,    81,   813,  1427,\n",
              "          765, 17376,    65,  3554, 24370, 23324,  3698, 26901,   523,   140,\n",
              "          144,  2572, 26897,    91, 15736,  7508, 26902, 26914,     4,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbNgj6q5WFlw"
      },
      "source": [
        "# Model with 5000 sentences\n",
        "\n",
        "\n",
        "> I decided to choose rather small epochs and batch sizes. Using small batch size was recommended in the tutorial. I actually tried to have batch size 16 but this did not work with the memory. \\\\\n",
        "In previous exercises I noticed that  more epochs did mostly not improve the model. So, I just decided to keep those low this time. I tried once with a few more but the model did not sigificantly improve. Also, I think that it might eventually overfit when chosing too many epochs.\n",
        "> \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qltta_neXB5r"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    output_dir='results',\n",
        "    logging_dir='logs',\n",
        "    no_cuda=False,  # defaults to false anyway, just to be explicit\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set_big\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1KIcaUgPDaY4",
        "outputId": "b2bd0a1f-df51-452e-befa-84159244421d"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 47:10, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.020114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.009731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.007949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.005894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.004481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.003188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3125, training_loss=0.008339030199050903)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "e9duuX3ODaY9",
        "outputId": "d67704c5-382d-4b5b-ac8e-900277f4ae6f"
      },
      "source": [
        "preds = trainer.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:15]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGX9o0az2x91"
      },
      "source": [
        "### I will quickly explain the following print statement's output (because this helped me a lot to understand the model's working):\n",
        "\n",
        "1.   This shows the model's predictions for the first two sentences in the test set for each token it outputs a list that contains the prediction score for each class \\\\\n",
        "\n",
        "2.   Calling argmax gives the index of the highest value in the lists of the first output. E.g. the first three lists (i.e. the first three tokens of the first sentence) have a their highest value at index 2 (all around value 9.0) \n",
        "this is reflected in the first list of the second print statement. The first three elements are 2.  Note that as the output is flattened (-1) Each prediction consists of a 1D list (i.e. each sentence is a list of the label for each token). \\\\\n",
        "\n",
        "3. These are simply the true labels for each sentence \\\\\n",
        "\n",
        "4. This is the loss on the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTVU2HM8DaY_",
        "outputId": "27be3728-a0cf-4e13-9d5e-8522531ab339"
      },
      "source": [
        "print(preds.predictions[:2])\n",
        "print(preds.predictions[:2].argmax(-1))\n",
        "print(preds.label_ids[:2])\n",
        "print(preds.metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-1.7349178  -2.5869465  -2.5082388   9.576312   -2.16313\n",
            "   -2.4085698 ]\n",
            "  [-1.6795355  -2.3828106  -2.6598024   9.288394   -1.8000873\n",
            "   -2.6051702 ]\n",
            "  [-1.6196618  -2.1783748  -2.808496    9.147063   -1.9905958\n",
            "   -2.7224247 ]\n",
            "  ...\n",
            "  [13.005723   -1.9613012  -2.6587849  -2.4666796  -2.4906647\n",
            "   -2.0427177 ]\n",
            "  [12.991143   -1.9389175  -2.673071   -2.508739   -2.4844792\n",
            "   -2.1005576 ]\n",
            "  [13.010515   -1.9479333  -2.6457367  -2.5132499  -2.4810648\n",
            "   -2.0734043 ]]\n",
            "\n",
            " [[-0.6155376  -2.8471537  -3.0123286   9.659774   -2.2078788\n",
            "   -2.3735435 ]\n",
            "  [-0.90619814 -3.0712223  -2.9500248   9.447913   -2.3497012\n",
            "   -1.8572366 ]\n",
            "  [-0.7095085  -2.6548617  -3.323987    9.27624    -2.2581627\n",
            "   -2.3166654 ]\n",
            "  ...\n",
            "  [13.002865   -1.8609704  -2.6197937  -2.6060476  -2.4698765\n",
            "   -2.0456367 ]\n",
            "  [12.975988   -1.838455   -2.6327024  -2.6447833  -2.4639058\n",
            "   -2.0878456 ]\n",
            "  [12.99367    -1.8370837  -2.6119642  -2.645088   -2.4545825\n",
            "   -2.0522325 ]]]\n",
            "[[3 3 3 ... 0 0 0]\n",
            " [3 3 3 ... 0 0 0]]\n",
            "[[3 3 3 ... 0 0 0]\n",
            " [3 3 3 ... 0 0 0]]\n",
            "{'eval_loss': 0.008242851123213768}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbu5-AucWveV"
      },
      "source": [
        "### Calculation of f1-score\n",
        "\n",
        "\n",
        "> In the next two cells I calculate the f1-micro and the f1-macro score. For each true-label - prediction pair, I excluded the padding labels at the end as those are not relevant for the evaluation. I then concatenate all the lists and calculate the score over the entire list of predictions. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw5OKVipDaY_",
        "outputId": "0c8ac186-5ab5-495c-a7bf-75126990c341"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "\n",
        "for y_true, y_pred in zip(preds.label_ids, preds.predictions.argmax(-1)):\n",
        "    y_true = [label for label in y_true if label != 0]\n",
        "    all_y_true.extend(y_true)\n",
        "\n",
        "    y_pred = y_pred[:len(y_true)]\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "f1_score(all_y_true, all_y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.931673743512891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sV5lYaCp8Iy",
        "outputId": "383b2dcc-7451-4281-cb63-1bca0d2e2422"
      },
      "source": [
        "f1_score(all_y_true, all_y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49008843221416837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXz0DGD0WAgE"
      },
      "source": [
        "# Model with 1000 sentences\n",
        "\n",
        "\n",
        "> This model and the following ones work exactley as the one above, I won't comment everything again\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or-OeaedMP-h"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    output_dir='results',\n",
        "    logging_dir='logs',\n",
        "    no_cuda=False,  # defaults to false anyway, just to be explicit\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set_small\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "yQC-LKFtNYpr",
        "outputId": "bfe928d0-38e9-4f80-ceef-49c066af6663"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 09:25, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.018792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=625, training_loss=0.016381402587890625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "vj6Z_1R6kr6k",
        "outputId": "f1a41088-e9bd-4f37-c8e8-1f73385722ae"
      },
      "source": [
        "preds = trainer.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:15]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUtCyEygVjfI",
        "outputId": "3e847489-588a-4fcf-fbc2-31e6657c854a"
      },
      "source": [
        "print(preds.predictions[:2])\n",
        "print(preds.predictions[:2].argmax(-1))\n",
        "print(preds.label_ids[:2])\n",
        "print(preds.metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-2.9156985  -3.836385   -0.5930642   5.9930077  -1.6499581\n",
            "    1.2419959 ]\n",
            "  [-2.769393   -3.5535655  -1.5530106   5.5897694  -1.6562132\n",
            "    2.0578024 ]\n",
            "  [-2.2806468  -3.4086447  -1.4520355   6.4426684  -1.4975652\n",
            "    1.234459  ]\n",
            "  ...\n",
            "  [11.272462   -1.944296   -2.6601825  -2.4194908  -2.7369988\n",
            "   -2.3305857 ]\n",
            "  [11.270475   -2.0024924  -2.679599   -2.465958   -2.7375848\n",
            "   -2.2849898 ]\n",
            "  [11.244193   -2.025214   -2.7094889  -2.3955238  -2.7369878\n",
            "   -2.329712  ]]\n",
            "\n",
            " [[-2.0221992  -3.8438432  -0.83458495  7.592824   -1.8784277\n",
            "   -0.68975884]\n",
            "  [-1.2488247  -3.4709244  -0.66187155  7.548788   -1.2896341\n",
            "   -1.2947161 ]\n",
            "  [-0.9994811  -3.41322    -0.5937271   7.5105724  -1.4148058\n",
            "   -1.4303062 ]\n",
            "  ...\n",
            "  [11.279121   -1.9371833  -2.6390607  -2.4033275  -2.7177348\n",
            "   -2.3511748 ]\n",
            "  [11.277723   -1.9979805  -2.6647825  -2.4496853  -2.721288\n",
            "   -2.300159  ]\n",
            "  [11.259235   -2.0222461  -2.6967072  -2.3749454  -2.7070818\n",
            "   -2.3590255 ]]]\n",
            "[[3 3 3 ... 0 0 0]\n",
            " [3 3 3 ... 0 0 0]]\n",
            "[[3 3 3 ... 0 0 0]\n",
            " [3 3 3 ... 0 0 0]]\n",
            "{'eval_loss': 0.013866704888641834}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6nl3CVoVmAA",
        "outputId": "ba84e1fb-e658-4782-bd13-a87e4e55d447"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "\n",
        "for y_true, y_pred in zip(preds.label_ids, preds.predictions.argmax(-1)):\n",
        "    y_true = [label for label in y_true if label != 0]\n",
        "    all_y_true.extend(y_true)\n",
        "\n",
        "    y_pred = y_pred[:len(y_true)]\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "f1_score(all_y_true, all_y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9158834844737566"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m59nW5xy6SM",
        "outputId": "6396dbde-dcfb-4d30-d18d-1f81d04042f2"
      },
      "source": [
        "f1_score(all_y_true, all_y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.347656092377417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR150EjFWIws"
      },
      "source": [
        "# Model with 1000 sentences frozen embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8YPdpBHXcEs"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    output_dir='results',\n",
        "    logging_dir='logs',\n",
        "    no_cuda=False,  # defaults to false anyway, just to be explicit\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set_small\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "IwhrylViGqqd",
        "outputId": "f474586e-cb7b-4fd1-9905-0519e9e4fcad"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 03:20, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.257590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=625, training_loss=0.219908056640625)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "n08_25SAGqql",
        "outputId": "7e237b89-fc41-496f-8653-f372a583b257"
      },
      "source": [
        "preds = trainer.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAVOkcHoGqqm",
        "outputId": "cda61f25-fba4-4157-a3ad-9a5c38125077"
      },
      "source": [
        "print(preds.predictions[:2])\n",
        "print(preds.predictions[:2].argmax(-1))\n",
        "print(preds.label_ids[:2])\n",
        "print(preds.metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 3.0805361  -4.4334545  -3.6101274  -0.6713129  -4.4284472\n",
            "   -4.4712625 ]\n",
            "  [ 1.4856422  -2.8480468  -2.8110518   1.1655972  -3.157579\n",
            "   -2.9233978 ]\n",
            "  [ 0.74164206 -1.7661538  -1.2426201   1.7834777  -1.3608127\n",
            "   -1.3447394 ]\n",
            "  ...\n",
            "  [ 3.6326692  -4.2259693  -3.6661148  -1.7152568  -4.8849883\n",
            "   -4.721519  ]\n",
            "  [ 3.520103   -4.4289217  -3.5748076  -1.5725886  -4.659845\n",
            "   -4.9389744 ]\n",
            "  [ 3.5478072  -4.293312   -3.6680615  -1.5539088  -4.579565\n",
            "   -4.7203746 ]]\n",
            "\n",
            " [[ 3.0844004  -4.432086   -3.6001828  -0.6720069  -4.4204917\n",
            "   -4.4626284 ]\n",
            "  [ 2.0117276  -3.1768694  -2.4977648   0.57732165 -3.83344\n",
            "   -3.5368087 ]\n",
            "  [ 1.2618809  -2.6064522  -1.9052707   0.93889    -2.9567604\n",
            "   -2.7056599 ]\n",
            "  ...\n",
            "  [ 3.6280358  -4.223399   -3.6556547  -1.7111757  -4.877194\n",
            "   -4.7172346 ]\n",
            "  [ 3.5156293  -4.420115   -3.557813   -1.5602709  -4.6515093\n",
            "   -4.9252996 ]\n",
            "  [ 3.542303   -4.290576   -3.6565883  -1.5457845  -4.5712023\n",
            "   -4.7143784 ]]]\n",
            "[[0 0 3 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[3 3 3 ... 0 0 0]\n",
            " [3 3 3 ... 0 0 0]]\n",
            "{'eval_loss': 0.058619674295186996}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRc4SlccGqqn",
        "outputId": "456241c7-41dc-457f-a6c2-591bbdae63b7"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "\n",
        "for y_true, y_pred in zip(preds.label_ids, preds.predictions.argmax(-1)):\n",
        "    y_true = [label for label in y_true if label != 0]\n",
        "    all_y_true.extend(y_true)\n",
        "\n",
        "    y_pred = y_pred[:len(y_true)]\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "f1_score(all_y_true, all_y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.511267217630854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz34knU1Gqqo",
        "outputId": "69cfeeed-d35f-4b78-bc70-3c2d7424f1af"
      },
      "source": [
        "f1_score(all_y_true, all_y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.138321936313328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOW4GokdWNw6"
      },
      "source": [
        "# Model with 5000 sentences frozen embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kd3DniaXFT0"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    output_dir='results',\n",
        "    logging_dir='logs',\n",
        "    no_cuda=False,  # defaults to false anyway, just to be explicit\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set_big\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWHT0lD_XFT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "39d53c9e-5c31-4bdb-b965-73301cced98d"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 16:54, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.196692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.049400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.043822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.040632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.039951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.038977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3125, training_loss=0.06701560241699218)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR9sjW0XXFT4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "43927735-8cfa-4cde-c675-cd4899e289a6"
      },
      "source": [
        "preds = trainer.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 01:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQqay0z3XFT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2445bf0-5468-40b1-a009-4ed10ca6a3db"
      },
      "source": [
        "print(preds.predictions[:2])\n",
        "print(preds.predictions[:2].argmax(-1))\n",
        "print(preds.label_ids[:2])\n",
        "print(preds.metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 2.220413   -6.1790056  -3.818466    1.7472477  -4.5413694\n",
            "   -4.0529046 ]\n",
            "  [ 2.4006584  -5.785126   -3.1284258   1.7519944  -3.72584\n",
            "   -3.0948648 ]\n",
            "  [ 0.9290033  -5.4676     -1.9664247   3.5016837  -2.6962779\n",
            "   -2.6081924 ]\n",
            "  ...\n",
            "  [ 6.139125   -6.680579   -4.4689126  -3.0176024  -4.8494444\n",
            "   -4.753057  ]\n",
            "  [ 5.8732257  -6.5412946  -4.514598   -2.6618178  -4.767673\n",
            "   -4.825128  ]\n",
            "  [ 5.522051   -6.419426   -4.4964004  -2.6009846  -4.713314\n",
            "   -4.7750864 ]]\n",
            "\n",
            " [[ 2.2352834  -6.221768   -3.8681667   1.8091202  -4.66357\n",
            "   -4.00101   ]\n",
            "  [ 0.41250107 -3.079933   -1.3278934   2.7463598  -1.3408433\n",
            "   -2.3782635 ]\n",
            "  [-0.35789034 -3.191218   -1.3136376   3.300728   -1.5793434\n",
            "   -2.3327353 ]\n",
            "  ...\n",
            "  [ 6.220709   -6.7253857  -4.474293   -3.0850656  -4.9264107\n",
            "   -4.7803063 ]\n",
            "  [ 5.969802   -6.597586   -4.5245657  -2.737121   -4.8510923\n",
            "   -4.838787  ]\n",
            "  [ 5.5878115  -6.4642253  -4.509656   -2.6166134  -4.795164\n",
            "   -4.7647114 ]]]\n",
            "[[0 0 3 ... 0 0 0]\n",
            " [0 3 3 ... 0 0 0]]\n",
            "[[3 3 2 ... 0 0 0]\n",
            " [3 3 3 ... 0 0 0]]\n",
            "{'eval_loss': 0.03649449720978737}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBitOGTeiNFs",
        "outputId": "a3535fae-a657-4fd0-ecff-8ea08353664a"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "\n",
        "for y_true, y_pred in zip(preds.label_ids, preds.predictions.argmax(-1)):\n",
        "    y_true = [label for label in y_true if label != 0]\n",
        "    all_y_true.extend(y_true)\n",
        "\n",
        "    y_pred = y_pred[:len(y_true)]\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "f1_score(all_y_true, all_y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8146182999458581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJx3y4uviNFs",
        "outputId": "aa42723e-0bb3-4b71-fa7d-719279d1c5d1"
      },
      "source": [
        "f1_score(all_y_true, all_y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18042119463389045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}