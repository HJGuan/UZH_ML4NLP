{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex01_mlp_jan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/submission/ex01_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mUlNUnJ4Ljk"
      },
      "source": [
        "# Exercise 01 - Part 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxRcPsF_tMOO"
      },
      "source": [
        "## Importing all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynDK5thyzl_v"
      },
      "source": [
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 200)  \n",
        "pd.set_option('display.max_columns', 200)   \n",
        "pd.set_option('display.width', 4000) \n",
        "\n",
        "from io import StringIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfzPwQnN2eHY"
      },
      "source": [
        "## 1. Data Acquisition\n",
        "In this assignment we are not going to do all the data cleaning and preprocessing again.  \n",
        "We are just loading the saved dataset from the first exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alVvFkGn2uih"
      },
      "source": [
        "dataset = pd.read_csv('./dataset.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g2XQFLeBClK",
        "outputId": "2a0c7ca9-d6b6-499c-cdf3-fe5504e9398f"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67642, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMTSM4istMQw"
      },
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oyQ6eZbCeUX"
      },
      "source": [
        "TARGET_COLUMN = 'label'\n",
        "TWEET_COLUMN = 'tweet'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNPDezQCVpH"
      },
      "source": [
        "X = dataset[TWEET_COLUMN]\n",
        "y = dataset[TARGET_COLUMN]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIWW6ZqKPKH"
      },
      "source": [
        "# Vectorize with ngram_range 1 to 3\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7udC4tUb3v",
        "outputId": "c78a5a4c-073b-47df-a01b-0b66e5986383"
      },
      "source": [
        "print(type(X_train_vec))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UfmSwvltMRQ"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zdPLMHJ2AV"
      },
      "source": [
        "# All parameters we are individually testing\n",
        "# If the computational power would be high enough we could\n",
        "# use GridSearchCV to easily find the best hyperparameters\n",
        "# However running this grid search CV exceeds colabs max runtime.\n",
        "parameters = {\n",
        "        'hidden_layer_sizes': [100, 500],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'activation': ['tanh', 'relu'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nb7mqEL9Ve"
      },
      "source": [
        "## Run by Jan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUP9_D47N0Ed"
      },
      "source": [
        "### Configuration 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gq1DtZktMRR",
        "outputId": "5725af1c-99c0-4448-ab2c-d9513731d892"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.35136123\n",
            "Validation score: 0.864488\n",
            "Iteration 2, loss = 0.38750770\n",
            "Validation score: 0.898160\n",
            "Iteration 3, loss = 0.20907587\n",
            "Validation score: 0.912779\n",
            "Iteration 4, loss = 0.12316765\n",
            "Validation score: 0.914586\n",
            "Iteration 5, loss = 0.07781613\n",
            "Validation score: 0.918857\n",
            "Iteration 6, loss = 0.05258100\n",
            "Validation score: 0.919021\n",
            "Iteration 7, loss = 0.03794585\n",
            "Validation score: 0.919678\n",
            "Iteration 8, loss = 0.02905713\n",
            "Validation score: 0.919021\n",
            "Iteration 9, loss = 0.02351217\n",
            "Validation score: 0.918693\n",
            "Iteration 10, loss = 0.01983701\n",
            "Validation score: 0.916064\n",
            "Iteration 11, loss = 0.01737863\n",
            "Validation score: 0.917050\n",
            "Iteration 12, loss = 0.01551853\n",
            "Validation score: 0.917050\n",
            "Iteration 13, loss = 0.01421724\n",
            "Validation score: 0.915243\n",
            "Iteration 14, loss = 0.01312494\n",
            "Validation score: 0.915079\n",
            "Iteration 15, loss = 0.01225299\n",
            "Validation score: 0.914586\n",
            "Iteration 16, loss = 0.01154947\n",
            "Validation score: 0.914750\n",
            "Iteration 17, loss = 0.01087968\n",
            "Validation score: 0.915900\n",
            "Iteration 18, loss = 0.01028974\n",
            "Validation score: 0.914093\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuUJKblKM87g",
        "outputId": "efa08744-19cf-4021-9344-d187559aa5ba"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.98      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.79      0.88        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.97      0.95      2357\n",
            "          es       0.92      0.95      0.93       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.60      0.75         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.87      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.67      0.79        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.83      0.90        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.75      0.18      0.29        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.86      0.82      0.84        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.86      0.67      0.75         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.92      0.93       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.67      0.80         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.83      0.69      0.75        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.94      0.85      0.89        74\n",
            "          uk       1.00      0.80      0.89         5\n",
            "         und       0.66      0.66      0.66       595\n",
            "          ur       1.00      1.00      1.00         3\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.85      0.88      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk380eGhN-IF"
      },
      "source": [
        "### Configuration 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4aSvJzFN-IG",
        "outputId": "b0f4e5b8-b025-4eb2-edb9-a805c8db442c"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.44080992\n",
            "Validation score: 0.869087\n",
            "Iteration 2, loss = 0.40336973\n",
            "Validation score: 0.904895\n",
            "Iteration 3, loss = 0.22184401\n",
            "Validation score: 0.920828\n",
            "Iteration 4, loss = 0.13248716\n",
            "Validation score: 0.926248\n",
            "Iteration 5, loss = 0.08481837\n",
            "Validation score: 0.926577\n",
            "Iteration 6, loss = 0.05784939\n",
            "Validation score: 0.926413\n",
            "Iteration 7, loss = 0.04195377\n",
            "Validation score: 0.926248\n",
            "Iteration 8, loss = 0.03211862\n",
            "Validation score: 0.927070\n",
            "Iteration 9, loss = 0.02582995\n",
            "Validation score: 0.925756\n",
            "Iteration 10, loss = 0.02167531\n",
            "Validation score: 0.924606\n",
            "Iteration 11, loss = 0.01884304\n",
            "Validation score: 0.925099\n",
            "Iteration 12, loss = 0.01690268\n",
            "Validation score: 0.924770\n",
            "Iteration 13, loss = 0.01537346\n",
            "Validation score: 0.924606\n",
            "Iteration 14, loss = 0.01423894\n",
            "Validation score: 0.924606\n",
            "Iteration 15, loss = 0.01328507\n",
            "Validation score: 0.924934\n",
            "Iteration 16, loss = 0.01248132\n",
            "Validation score: 0.924934\n",
            "Iteration 17, loss = 0.01183086\n",
            "Validation score: 0.923784\n",
            "Iteration 18, loss = 0.01130216\n",
            "Validation score: 0.925263\n",
            "Iteration 19, loss = 0.01067333\n",
            "Validation score: 0.924606\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kBnRu9BOU9G",
        "outputId": "992b091f-6b79-4300-a70c-57ec513104a6"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.97      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.82      0.90        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.96      0.95      2357\n",
            "          es       0.92      0.95      0.94       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.80      0.89         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.88      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.64      0.77        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.81      0.89        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.62      0.29      0.40        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.83      0.68      0.75        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.83      0.56      0.67         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.91      0.92       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.50      0.67         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.81      0.71      0.76        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.96      0.86      0.91        74\n",
            "          uk       1.00      1.00      1.00         5\n",
            "         und       0.66      0.68      0.67       595\n",
            "          ur       1.00      0.67      0.80         3\n",
            "      urlatn       1.00      1.00      1.00         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.86      0.89      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mkAJzofOEq2"
      },
      "source": [
        "### Configuration 03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uFzCjU5OEq3",
        "outputId": "bafb7a36-7fdb-49f0-e450-26b7e3f79225"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.83790675\n",
            "Validation score: 0.346091\n",
            "Iteration 2, loss = 2.80005137\n",
            "Validation score: 0.346091\n",
            "Iteration 3, loss = 2.43424634\n",
            "Validation score: 0.346091\n",
            "Iteration 4, loss = 2.29328226\n",
            "Validation score: 0.346091\n",
            "Iteration 5, loss = 2.21992028\n",
            "Validation score: 0.346091\n",
            "Iteration 6, loss = 2.16930773\n",
            "Validation score: 0.366130\n",
            "Iteration 7, loss = 2.12569797\n",
            "Validation score: 0.480289\n",
            "Iteration 8, loss = 2.08346862\n",
            "Validation score: 0.515769\n",
            "Iteration 9, loss = 2.04120553\n",
            "Validation score: 0.526938\n",
            "Iteration 10, loss = 1.99883010\n",
            "Validation score: 0.530388\n",
            "Iteration 11, loss = 1.95691272\n",
            "Validation score: 0.529074\n",
            "Iteration 12, loss = 1.91601130\n",
            "Validation score: 0.528581\n",
            "Iteration 13, loss = 1.87660695\n",
            "Validation score: 0.527431\n",
            "Iteration 14, loss = 1.83893518\n",
            "Validation score: 0.527102\n",
            "Iteration 15, loss = 1.80301735\n",
            "Validation score: 0.527102\n",
            "Iteration 16, loss = 1.76876771\n",
            "Validation score: 0.525953\n",
            "Iteration 17, loss = 1.73596789\n",
            "Validation score: 0.527267\n",
            "Iteration 18, loss = 1.70438489\n",
            "Validation score: 0.529895\n",
            "Iteration 19, loss = 1.67385303\n",
            "Validation score: 0.537451\n",
            "Iteration 20, loss = 1.64443073\n",
            "Validation score: 0.543857\n",
            "Iteration 21, loss = 1.61577152\n",
            "Validation score: 0.553548\n",
            "Iteration 22, loss = 1.58799018\n",
            "Validation score: 0.568495\n",
            "Iteration 23, loss = 1.56103380\n",
            "Validation score: 0.580979\n",
            "Iteration 24, loss = 1.53489508\n",
            "Validation score: 0.597076\n",
            "Iteration 25, loss = 1.50966422\n",
            "Validation score: 0.606110\n",
            "Iteration 26, loss = 1.48528117\n",
            "Validation score: 0.616787\n",
            "Iteration 27, loss = 1.46186302\n",
            "Validation score: 0.624507\n",
            "Iteration 28, loss = 1.43935293\n",
            "Validation score: 0.632227\n",
            "Iteration 29, loss = 1.41783294\n",
            "Validation score: 0.637484\n",
            "Iteration 30, loss = 1.39721355\n",
            "Validation score: 0.642083\n",
            "Iteration 31, loss = 1.37756498\n",
            "Validation score: 0.647339\n",
            "Iteration 32, loss = 1.35879851\n",
            "Validation score: 0.650953\n",
            "Iteration 33, loss = 1.34093833\n",
            "Validation score: 0.655716\n",
            "Iteration 34, loss = 1.32392275\n",
            "Validation score: 0.659987\n",
            "Iteration 35, loss = 1.30766425\n",
            "Validation score: 0.661137\n",
            "Iteration 36, loss = 1.29219057\n",
            "Validation score: 0.671485\n",
            "Iteration 37, loss = 1.27740079\n",
            "Validation score: 0.676413\n",
            "Iteration 38, loss = 1.26325136\n",
            "Validation score: 0.680519\n",
            "Iteration 39, loss = 1.24975294\n",
            "Validation score: 0.685283\n",
            "Iteration 40, loss = 1.23678184\n",
            "Validation score: 0.688732\n",
            "Iteration 41, loss = 1.22434442\n",
            "Validation score: 0.693988\n",
            "Iteration 42, loss = 1.21235271\n",
            "Validation score: 0.698095\n",
            "Iteration 43, loss = 1.20080773\n",
            "Validation score: 0.701544\n",
            "Iteration 44, loss = 1.18971234\n",
            "Validation score: 0.706472\n",
            "Iteration 45, loss = 1.17896182\n",
            "Validation score: 0.710414\n",
            "Iteration 46, loss = 1.16858059\n",
            "Validation score: 0.712385\n",
            "Iteration 47, loss = 1.15852927\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.14877519\n",
            "Validation score: 0.719284\n",
            "Iteration 49, loss = 1.13932871\n",
            "Validation score: 0.720762\n",
            "Iteration 50, loss = 1.13012600\n",
            "Validation score: 0.724869\n",
            "Iteration 51, loss = 1.12123430\n",
            "Validation score: 0.727497\n",
            "Iteration 52, loss = 1.11251944\n",
            "Validation score: 0.727661\n",
            "Iteration 53, loss = 1.10406905\n",
            "Validation score: 0.729632\n",
            "Iteration 54, loss = 1.09586074\n",
            "Validation score: 0.734888\n",
            "Iteration 55, loss = 1.08782374\n",
            "Validation score: 0.735381\n",
            "Iteration 56, loss = 1.08001231\n",
            "Validation score: 0.738502\n",
            "Iteration 57, loss = 1.07240383\n",
            "Validation score: 0.741459\n",
            "Iteration 58, loss = 1.06496062\n",
            "Validation score: 0.743922\n",
            "Iteration 59, loss = 1.05770561\n",
            "Validation score: 0.745237\n",
            "Iteration 60, loss = 1.05062061\n",
            "Validation score: 0.747208\n",
            "Iteration 61, loss = 1.04374049\n",
            "Validation score: 0.747700\n",
            "Iteration 62, loss = 1.03699385\n",
            "Validation score: 0.750657\n",
            "Iteration 63, loss = 1.03038835\n",
            "Validation score: 0.752792\n",
            "Iteration 64, loss = 1.02396438\n",
            "Validation score: 0.753942\n",
            "Iteration 65, loss = 1.01769635\n",
            "Validation score: 0.755420\n",
            "Iteration 66, loss = 1.01154920\n",
            "Validation score: 0.757556\n",
            "Iteration 67, loss = 1.00555981\n",
            "Validation score: 0.758049\n",
            "Iteration 68, loss = 0.99966179\n",
            "Validation score: 0.759198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urcbii6kigaj",
        "outputId": "8efcb260-7c07-4d1a-8df8-df0a6eef20e4"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.97      0.95      0.96       274\n",
            "      arlatn       0.00      0.00      0.00         5\n",
            "          az       0.00      0.00      0.00         5\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         2\n",
            "          bs       0.00      0.00      0.00         5\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         1\n",
            "          de       0.00      0.00      0.00        19\n",
            "          dv       0.00      0.00      0.00         2\n",
            "          el       0.00      0.00      0.00         1\n",
            "          en       0.84      0.97      0.90      2355\n",
            "          es       0.67      0.90      0.77       763\n",
            "          et       0.00      0.00      0.00         4\n",
            "          eu       0.00      0.00      0.00         5\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.00      0.00      0.00       103\n",
            "          gl       0.00      0.00      0.00         2\n",
            "          ha       0.00      0.00      0.00         4\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         1\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         8\n",
            "          ht       0.00      0.00      0.00         2\n",
            "          hu       0.00      0.00      0.00         5\n",
            "          hy       0.00      0.00      0.00         6\n",
            "          id       0.64      0.80      0.71       362\n",
            "          is       0.00      0.00      0.00         3\n",
            "          it       0.00      0.00      0.00        35\n",
            "          ja       0.87      0.97      0.91      1295\n",
            "      jalatn       0.00      0.00      0.00         2\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         3\n",
            "          ko       0.00      0.00      0.00        53\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         6\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         6\n",
            "          mr       0.00      0.00      0.00         6\n",
            "          ms       0.00      0.00      0.00         9\n",
            "          ne       0.00      0.00      0.00         8\n",
            "          nl       0.00      0.00      0.00        30\n",
            "          no       0.00      0.00      0.00         2\n",
            "          pl       0.00      0.00      0.00        10\n",
            "          ps       0.00      0.00      0.00         4\n",
            "      pslatn       0.00      0.00      0.00         1\n",
            "          pt       0.93      0.19      0.31       349\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.88      0.79      0.83       124\n",
            "          si       0.00      0.00      0.00         6\n",
            "          sk       0.00      0.00      0.00         5\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         2\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       0.00      0.00      0.00         7\n",
            "          sv       0.00      0.00      0.00        10\n",
            "          sw       0.00      0.00      0.00         3\n",
            "          ta       0.00      0.00      0.00         3\n",
            "      talatn       0.00      0.00      0.00         2\n",
            "          th       0.00      0.00      0.00        65\n",
            "          tl       0.00      0.00      0.00        55\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        80\n",
            "          uk       0.00      0.00      0.00         8\n",
            "         und       0.41      0.50      0.45       548\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         2\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         6\n",
            "          xh       0.00      0.00      0.00         5\n",
            "          yo       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         5\n",
            "          zu       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.77      6765\n",
            "   macro avg       0.08      0.08      0.08      6765\n",
            "weighted avg       0.71      0.77      0.72      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy8NGueVOM5q"
      },
      "source": [
        "### Configuration 04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjKjeyXXOM5q",
        "outputId": "e6199608-83bc-4acf-d177-e209b2330308"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 4.02919301\n",
            "Validation score: 0.346748\n",
            "Iteration 2, loss = 3.14377492\n",
            "Validation score: 0.346748\n",
            "Iteration 3, loss = 2.56392484\n",
            "Validation score: 0.346748\n",
            "Iteration 4, loss = 2.35278089\n",
            "Validation score: 0.346748\n",
            "Iteration 5, loss = 2.26528485\n",
            "Validation score: 0.346748\n",
            "Iteration 6, loss = 2.21389089\n",
            "Validation score: 0.346748\n",
            "Iteration 7, loss = 2.17213758\n",
            "Validation score: 0.348883\n",
            "Iteration 8, loss = 2.13207392\n",
            "Validation score: 0.453515\n",
            "Iteration 9, loss = 2.09104169\n",
            "Validation score: 0.498357\n",
            "Iteration 10, loss = 2.04880234\n",
            "Validation score: 0.517247\n",
            "Iteration 11, loss = 2.00590778\n",
            "Validation score: 0.521189\n",
            "Iteration 12, loss = 1.96306010\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.92126695\n",
            "Validation score: 0.519054\n",
            "Iteration 14, loss = 1.88095186\n",
            "Validation score: 0.518397\n",
            "Iteration 15, loss = 1.84241353\n",
            "Validation score: 0.518233\n",
            "Iteration 16, loss = 1.80577731\n",
            "Validation score: 0.518068\n",
            "Iteration 17, loss = 1.77081258\n",
            "Validation score: 0.519218\n",
            "Iteration 18, loss = 1.73745917\n",
            "Validation score: 0.521189\n",
            "Iteration 19, loss = 1.70540344\n",
            "Validation score: 0.524967\n",
            "Iteration 20, loss = 1.67455771\n",
            "Validation score: 0.529566\n",
            "Iteration 21, loss = 1.64467251\n",
            "Validation score: 0.538601\n",
            "Iteration 22, loss = 1.61578854\n",
            "Validation score: 0.550099\n",
            "Iteration 23, loss = 1.58778501\n",
            "Validation score: 0.558804\n",
            "Iteration 24, loss = 1.56064452\n",
            "Validation score: 0.571124\n",
            "Iteration 25, loss = 1.53443847\n",
            "Validation score: 0.584264\n",
            "Iteration 26, loss = 1.50906186\n",
            "Validation score: 0.594941\n",
            "Iteration 27, loss = 1.48475539\n",
            "Validation score: 0.605289\n",
            "Iteration 28, loss = 1.46135115\n",
            "Validation score: 0.611695\n",
            "Iteration 29, loss = 1.43899993\n",
            "Validation score: 0.618594\n",
            "Iteration 30, loss = 1.41752904\n",
            "Validation score: 0.626807\n",
            "Iteration 31, loss = 1.39710464\n",
            "Validation score: 0.631735\n",
            "Iteration 32, loss = 1.37756625\n",
            "Validation score: 0.636827\n",
            "Iteration 33, loss = 1.35896542\n",
            "Validation score: 0.642904\n",
            "Iteration 34, loss = 1.34125814\n",
            "Validation score: 0.645696\n",
            "Iteration 35, loss = 1.32439846\n",
            "Validation score: 0.650460\n",
            "Iteration 36, loss = 1.30829094\n",
            "Validation score: 0.659001\n",
            "Iteration 37, loss = 1.29297601\n",
            "Validation score: 0.661794\n",
            "Iteration 38, loss = 1.27836837\n",
            "Validation score: 0.667871\n",
            "Iteration 39, loss = 1.26436781\n",
            "Validation score: 0.675920\n",
            "Iteration 40, loss = 1.25107209\n",
            "Validation score: 0.679698\n",
            "Iteration 41, loss = 1.23827764\n",
            "Validation score: 0.688239\n",
            "Iteration 42, loss = 1.22597316\n",
            "Validation score: 0.688568\n",
            "Iteration 43, loss = 1.21421455\n",
            "Validation score: 0.694809\n",
            "Iteration 44, loss = 1.20288021\n",
            "Validation score: 0.698259\n",
            "Iteration 45, loss = 1.19193738\n",
            "Validation score: 0.702037\n",
            "Iteration 46, loss = 1.18138379\n",
            "Validation score: 0.704172\n",
            "Iteration 47, loss = 1.17118849\n",
            "Validation score: 0.705979\n",
            "Iteration 48, loss = 1.16128318\n",
            "Validation score: 0.707786\n",
            "Iteration 49, loss = 1.15168758\n",
            "Validation score: 0.711235\n",
            "Iteration 50, loss = 1.14240475\n",
            "Validation score: 0.715177\n",
            "Iteration 51, loss = 1.13339869\n",
            "Validation score: 0.717477\n",
            "Iteration 52, loss = 1.12461737\n",
            "Validation score: 0.719777\n",
            "Iteration 53, loss = 1.11607600\n",
            "Validation score: 0.721255\n",
            "Iteration 54, loss = 1.10778021\n",
            "Validation score: 0.721912\n",
            "Iteration 55, loss = 1.09968494\n",
            "Validation score: 0.723883\n",
            "Iteration 56, loss = 1.09184158\n",
            "Validation score: 0.724540\n",
            "Iteration 57, loss = 1.08415567\n",
            "Validation score: 0.725690\n",
            "Iteration 58, loss = 1.07666505\n",
            "Validation score: 0.726511\n",
            "Iteration 59, loss = 1.06933136\n",
            "Validation score: 0.729304\n",
            "Iteration 60, loss = 1.06219828\n",
            "Validation score: 0.730453\n",
            "Iteration 61, loss = 1.05522855\n",
            "Validation score: 0.733903\n",
            "Iteration 62, loss = 1.04841870\n",
            "Validation score: 0.735381\n",
            "Iteration 63, loss = 1.04176983\n",
            "Validation score: 0.736859\n",
            "Iteration 64, loss = 1.03526080\n",
            "Validation score: 0.739159\n",
            "Iteration 65, loss = 1.02889163\n",
            "Validation score: 0.742444\n",
            "Iteration 66, loss = 1.02266797\n",
            "Validation score: 0.742773\n",
            "Iteration 67, loss = 1.01659430\n",
            "Validation score: 0.744251\n",
            "Iteration 68, loss = 1.01062949\n",
            "Validation score: 0.746879\n",
            "Iteration 69, loss = 1.00481937\n",
            "Validation score: 0.747865\n",
            "Iteration 70, loss = 0.99912205\n",
            "Validation score: 0.749671\n",
            "Iteration 71, loss = 0.99351362\n",
            "Validation score: 0.752464\n",
            "Iteration 72, loss = 0.98807280\n",
            "Validation score: 0.753614\n",
            "Iteration 73, loss = 0.98268432\n",
            "Validation score: 0.754271\n",
            "Iteration 74, loss = 0.97745743\n",
            "Validation score: 0.754763\n",
            "Iteration 75, loss = 0.97233744\n",
            "Validation score: 0.758870\n",
            "Iteration 76, loss = 0.96729777\n",
            "Validation score: 0.758870\n",
            "Iteration 77, loss = 0.96234634\n",
            "Validation score: 0.762319\n",
            "Iteration 78, loss = 0.95747945\n",
            "Validation score: 0.764619\n",
            "Iteration 79, loss = 0.95276842\n",
            "Validation score: 0.767904\n",
            "Iteration 80, loss = 0.94808632\n",
            "Validation score: 0.767740\n",
            "Iteration 81, loss = 0.94347783\n",
            "Validation score: 0.768561\n",
            "Iteration 82, loss = 0.93896076\n",
            "Validation score: 0.770696\n",
            "Iteration 83, loss = 0.93461697\n",
            "Validation score: 0.773489\n",
            "Iteration 84, loss = 0.93024661\n",
            "Validation score: 0.773653\n",
            "Iteration 85, loss = 0.92596250\n",
            "Validation score: 0.775460\n",
            "Iteration 86, loss = 0.92180211\n",
            "Validation score: 0.777267\n",
            "Iteration 87, loss = 0.91766880\n",
            "Validation score: 0.777924\n",
            "Iteration 88, loss = 0.91362931\n",
            "Validation score: 0.781209\n",
            "Iteration 89, loss = 0.90964798\n",
            "Validation score: 0.782523\n",
            "Iteration 90, loss = 0.90572372\n",
            "Validation score: 0.783837\n",
            "Iteration 91, loss = 0.90184454\n",
            "Validation score: 0.784166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PMRXKVjhb2b"
      },
      "source": [
        "**This code crashed after running for around 5 hours and we were not able to print the classification report. However, since the validation score is just at 78% eprcent after 91 iterations, we will not rerun it since it wont achieve the performance of the models being trained with Adam.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-brwl2BOwqC"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}