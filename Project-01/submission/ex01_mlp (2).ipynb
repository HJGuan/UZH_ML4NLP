{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex01_mlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/ex01_mlp_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mUlNUnJ4Ljk"
      },
      "source": [
        "# Exercise 01 - Part 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-tSmGwauDkm"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFdqlZ-1uDSw"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxRcPsF_tMOO"
      },
      "source": [
        "## Importing all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynDK5thyzl_v"
      },
      "source": [
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 200)  \n",
        "pd.set_option('display.max_columns', 200)   \n",
        "pd.set_option('display.width', 4000) \n",
        "\n",
        "from io import StringIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfzPwQnN2eHY"
      },
      "source": [
        "## 1. Data Acquisition\n",
        "In this assignment we are not going to do all the data cleaning and preprocessing again.  \n",
        "We are just loading the saved dataset from the first exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alVvFkGn2uih"
      },
      "source": [
        "dataset = pd.read_csv('./dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g2XQFLeBClK",
        "outputId": "2a0c7ca9-d6b6-499c-cdf3-fe5504e9398f"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67642, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMTSM4istMQw"
      },
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oyQ6eZbCeUX"
      },
      "source": [
        "TARGET_COLUMN = 'label'\n",
        "TWEET_COLUMN = 'tweet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNPDezQCVpH"
      },
      "source": [
        "X = dataset[TWEET_COLUMN]\n",
        "y = dataset[TARGET_COLUMN]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIWW6ZqKPKH"
      },
      "source": [
        "# Vectorize with ngram_range 1 to 3\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7udC4tUb3v",
        "outputId": "c78a5a4c-073b-47df-a01b-0b66e5986383"
      },
      "source": [
        "print(type(X_train_vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UfmSwvltMRQ"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zdPLMHJ2AV"
      },
      "source": [
        "# All parameters we are individually testing\n",
        "# If the computational power would be high enough we could\n",
        "# use GridSearchCV to easily find the best hyperparameters\n",
        "# However running this grid search CV exceeds colabs max runtime.\n",
        "parameters = {\n",
        "        'hidden_layer_sizes': [100, 500],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'activation': ['tanh', 'relu'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nb7mqEL9Ve"
      },
      "source": [
        "\n",
        "## hidden_layer_sizes=(100): configuration 1-4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUP9_D47N0Ed"
      },
      "source": [
        "### Configuration 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gq1DtZktMRR",
        "outputId": "5725af1c-99c0-4448-ab2c-d9513731d892"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.35136123\n",
            "Validation score: 0.864488\n",
            "Iteration 2, loss = 0.38750770\n",
            "Validation score: 0.898160\n",
            "Iteration 3, loss = 0.20907587\n",
            "Validation score: 0.912779\n",
            "Iteration 4, loss = 0.12316765\n",
            "Validation score: 0.914586\n",
            "Iteration 5, loss = 0.07781613\n",
            "Validation score: 0.918857\n",
            "Iteration 6, loss = 0.05258100\n",
            "Validation score: 0.919021\n",
            "Iteration 7, loss = 0.03794585\n",
            "Validation score: 0.919678\n",
            "Iteration 8, loss = 0.02905713\n",
            "Validation score: 0.919021\n",
            "Iteration 9, loss = 0.02351217\n",
            "Validation score: 0.918693\n",
            "Iteration 10, loss = 0.01983701\n",
            "Validation score: 0.916064\n",
            "Iteration 11, loss = 0.01737863\n",
            "Validation score: 0.917050\n",
            "Iteration 12, loss = 0.01551853\n",
            "Validation score: 0.917050\n",
            "Iteration 13, loss = 0.01421724\n",
            "Validation score: 0.915243\n",
            "Iteration 14, loss = 0.01312494\n",
            "Validation score: 0.915079\n",
            "Iteration 15, loss = 0.01225299\n",
            "Validation score: 0.914586\n",
            "Iteration 16, loss = 0.01154947\n",
            "Validation score: 0.914750\n",
            "Iteration 17, loss = 0.01087968\n",
            "Validation score: 0.915900\n",
            "Iteration 18, loss = 0.01028974\n",
            "Validation score: 0.914093\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuUJKblKM87g",
        "outputId": "efa08744-19cf-4021-9344-d187559aa5ba"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.98      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.79      0.88        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.97      0.95      2357\n",
            "          es       0.92      0.95      0.93       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.60      0.75         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.87      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.67      0.79        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.83      0.90        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.75      0.18      0.29        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.86      0.82      0.84        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.86      0.67      0.75         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.92      0.93       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.67      0.80         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.83      0.69      0.75        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.94      0.85      0.89        74\n",
            "          uk       1.00      0.80      0.89         5\n",
            "         und       0.66      0.66      0.66       595\n",
            "          ur       1.00      1.00      1.00         3\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.85      0.88      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk380eGhN-IF"
      },
      "source": [
        "### Configuration 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4aSvJzFN-IG",
        "outputId": "b0f4e5b8-b025-4eb2-edb9-a805c8db442c"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.44080992\n",
            "Validation score: 0.869087\n",
            "Iteration 2, loss = 0.40336973\n",
            "Validation score: 0.904895\n",
            "Iteration 3, loss = 0.22184401\n",
            "Validation score: 0.920828\n",
            "Iteration 4, loss = 0.13248716\n",
            "Validation score: 0.926248\n",
            "Iteration 5, loss = 0.08481837\n",
            "Validation score: 0.926577\n",
            "Iteration 6, loss = 0.05784939\n",
            "Validation score: 0.926413\n",
            "Iteration 7, loss = 0.04195377\n",
            "Validation score: 0.926248\n",
            "Iteration 8, loss = 0.03211862\n",
            "Validation score: 0.927070\n",
            "Iteration 9, loss = 0.02582995\n",
            "Validation score: 0.925756\n",
            "Iteration 10, loss = 0.02167531\n",
            "Validation score: 0.924606\n",
            "Iteration 11, loss = 0.01884304\n",
            "Validation score: 0.925099\n",
            "Iteration 12, loss = 0.01690268\n",
            "Validation score: 0.924770\n",
            "Iteration 13, loss = 0.01537346\n",
            "Validation score: 0.924606\n",
            "Iteration 14, loss = 0.01423894\n",
            "Validation score: 0.924606\n",
            "Iteration 15, loss = 0.01328507\n",
            "Validation score: 0.924934\n",
            "Iteration 16, loss = 0.01248132\n",
            "Validation score: 0.924934\n",
            "Iteration 17, loss = 0.01183086\n",
            "Validation score: 0.923784\n",
            "Iteration 18, loss = 0.01130216\n",
            "Validation score: 0.925263\n",
            "Iteration 19, loss = 0.01067333\n",
            "Validation score: 0.924606\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kBnRu9BOU9G",
        "outputId": "992b091f-6b79-4300-a70c-57ec513104a6"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.97      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.82      0.90        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.96      0.95      2357\n",
            "          es       0.92      0.95      0.94       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.80      0.89         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.88      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.64      0.77        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.81      0.89        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.62      0.29      0.40        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.83      0.68      0.75        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.83      0.56      0.67         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.91      0.92       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.50      0.67         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.81      0.71      0.76        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.96      0.86      0.91        74\n",
            "          uk       1.00      1.00      1.00         5\n",
            "         und       0.66      0.68      0.67       595\n",
            "          ur       1.00      0.67      0.80         3\n",
            "      urlatn       1.00      1.00      1.00         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.86      0.89      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mkAJzofOEq2"
      },
      "source": [
        "### Configuration 03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uFzCjU5OEq3",
        "outputId": "bafb7a36-7fdb-49f0-e450-26b7e3f79225"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.83790675\n",
            "Validation score: 0.346091\n",
            "Iteration 2, loss = 2.80005137\n",
            "Validation score: 0.346091\n",
            "Iteration 3, loss = 2.43424634\n",
            "Validation score: 0.346091\n",
            "Iteration 4, loss = 2.29328226\n",
            "Validation score: 0.346091\n",
            "Iteration 5, loss = 2.21992028\n",
            "Validation score: 0.346091\n",
            "Iteration 6, loss = 2.16930773\n",
            "Validation score: 0.366130\n",
            "Iteration 7, loss = 2.12569797\n",
            "Validation score: 0.480289\n",
            "Iteration 8, loss = 2.08346862\n",
            "Validation score: 0.515769\n",
            "Iteration 9, loss = 2.04120553\n",
            "Validation score: 0.526938\n",
            "Iteration 10, loss = 1.99883010\n",
            "Validation score: 0.530388\n",
            "Iteration 11, loss = 1.95691272\n",
            "Validation score: 0.529074\n",
            "Iteration 12, loss = 1.91601130\n",
            "Validation score: 0.528581\n",
            "Iteration 13, loss = 1.87660695\n",
            "Validation score: 0.527431\n",
            "Iteration 14, loss = 1.83893518\n",
            "Validation score: 0.527102\n",
            "Iteration 15, loss = 1.80301735\n",
            "Validation score: 0.527102\n",
            "Iteration 16, loss = 1.76876771\n",
            "Validation score: 0.525953\n",
            "Iteration 17, loss = 1.73596789\n",
            "Validation score: 0.527267\n",
            "Iteration 18, loss = 1.70438489\n",
            "Validation score: 0.529895\n",
            "Iteration 19, loss = 1.67385303\n",
            "Validation score: 0.537451\n",
            "Iteration 20, loss = 1.64443073\n",
            "Validation score: 0.543857\n",
            "Iteration 21, loss = 1.61577152\n",
            "Validation score: 0.553548\n",
            "Iteration 22, loss = 1.58799018\n",
            "Validation score: 0.568495\n",
            "Iteration 23, loss = 1.56103380\n",
            "Validation score: 0.580979\n",
            "Iteration 24, loss = 1.53489508\n",
            "Validation score: 0.597076\n",
            "Iteration 25, loss = 1.50966422\n",
            "Validation score: 0.606110\n",
            "Iteration 26, loss = 1.48528117\n",
            "Validation score: 0.616787\n",
            "Iteration 27, loss = 1.46186302\n",
            "Validation score: 0.624507\n",
            "Iteration 28, loss = 1.43935293\n",
            "Validation score: 0.632227\n",
            "Iteration 29, loss = 1.41783294\n",
            "Validation score: 0.637484\n",
            "Iteration 30, loss = 1.39721355\n",
            "Validation score: 0.642083\n",
            "Iteration 31, loss = 1.37756498\n",
            "Validation score: 0.647339\n",
            "Iteration 32, loss = 1.35879851\n",
            "Validation score: 0.650953\n",
            "Iteration 33, loss = 1.34093833\n",
            "Validation score: 0.655716\n",
            "Iteration 34, loss = 1.32392275\n",
            "Validation score: 0.659987\n",
            "Iteration 35, loss = 1.30766425\n",
            "Validation score: 0.661137\n",
            "Iteration 36, loss = 1.29219057\n",
            "Validation score: 0.671485\n",
            "Iteration 37, loss = 1.27740079\n",
            "Validation score: 0.676413\n",
            "Iteration 38, loss = 1.26325136\n",
            "Validation score: 0.680519\n",
            "Iteration 39, loss = 1.24975294\n",
            "Validation score: 0.685283\n",
            "Iteration 40, loss = 1.23678184\n",
            "Validation score: 0.688732\n",
            "Iteration 41, loss = 1.22434442\n",
            "Validation score: 0.693988\n",
            "Iteration 42, loss = 1.21235271\n",
            "Validation score: 0.698095\n",
            "Iteration 43, loss = 1.20080773\n",
            "Validation score: 0.701544\n",
            "Iteration 44, loss = 1.18971234\n",
            "Validation score: 0.706472\n",
            "Iteration 45, loss = 1.17896182\n",
            "Validation score: 0.710414\n",
            "Iteration 46, loss = 1.16858059\n",
            "Validation score: 0.712385\n",
            "Iteration 47, loss = 1.15852927\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.14877519\n",
            "Validation score: 0.719284\n",
            "Iteration 49, loss = 1.13932871\n",
            "Validation score: 0.720762\n",
            "Iteration 50, loss = 1.13012600\n",
            "Validation score: 0.724869\n",
            "Iteration 51, loss = 1.12123430\n",
            "Validation score: 0.727497\n",
            "Iteration 52, loss = 1.11251944\n",
            "Validation score: 0.727661\n",
            "Iteration 53, loss = 1.10406905\n",
            "Validation score: 0.729632\n",
            "Iteration 54, loss = 1.09586074\n",
            "Validation score: 0.734888\n",
            "Iteration 55, loss = 1.08782374\n",
            "Validation score: 0.735381\n",
            "Iteration 56, loss = 1.08001231\n",
            "Validation score: 0.738502\n",
            "Iteration 57, loss = 1.07240383\n",
            "Validation score: 0.741459\n",
            "Iteration 58, loss = 1.06496062\n",
            "Validation score: 0.743922\n",
            "Iteration 59, loss = 1.05770561\n",
            "Validation score: 0.745237\n",
            "Iteration 60, loss = 1.05062061\n",
            "Validation score: 0.747208\n",
            "Iteration 61, loss = 1.04374049\n",
            "Validation score: 0.747700\n",
            "Iteration 62, loss = 1.03699385\n",
            "Validation score: 0.750657\n",
            "Iteration 63, loss = 1.03038835\n",
            "Validation score: 0.752792\n",
            "Iteration 64, loss = 1.02396438\n",
            "Validation score: 0.753942\n",
            "Iteration 65, loss = 1.01769635\n",
            "Validation score: 0.755420\n",
            "Iteration 66, loss = 1.01154920\n",
            "Validation score: 0.757556\n",
            "Iteration 67, loss = 1.00555981\n",
            "Validation score: 0.758049\n",
            "Iteration 68, loss = 0.99966179\n",
            "Validation score: 0.759198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urcbii6kigaj",
        "outputId": "8efcb260-7c07-4d1a-8df8-df0a6eef20e4"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.97      0.95      0.96       274\n",
            "      arlatn       0.00      0.00      0.00         5\n",
            "          az       0.00      0.00      0.00         5\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         2\n",
            "          bs       0.00      0.00      0.00         5\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         1\n",
            "          de       0.00      0.00      0.00        19\n",
            "          dv       0.00      0.00      0.00         2\n",
            "          el       0.00      0.00      0.00         1\n",
            "          en       0.84      0.97      0.90      2355\n",
            "          es       0.67      0.90      0.77       763\n",
            "          et       0.00      0.00      0.00         4\n",
            "          eu       0.00      0.00      0.00         5\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.00      0.00      0.00       103\n",
            "          gl       0.00      0.00      0.00         2\n",
            "          ha       0.00      0.00      0.00         4\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         1\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         8\n",
            "          ht       0.00      0.00      0.00         2\n",
            "          hu       0.00      0.00      0.00         5\n",
            "          hy       0.00      0.00      0.00         6\n",
            "          id       0.64      0.80      0.71       362\n",
            "          is       0.00      0.00      0.00         3\n",
            "          it       0.00      0.00      0.00        35\n",
            "          ja       0.87      0.97      0.91      1295\n",
            "      jalatn       0.00      0.00      0.00         2\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         3\n",
            "          ko       0.00      0.00      0.00        53\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         6\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         6\n",
            "          mr       0.00      0.00      0.00         6\n",
            "          ms       0.00      0.00      0.00         9\n",
            "          ne       0.00      0.00      0.00         8\n",
            "          nl       0.00      0.00      0.00        30\n",
            "          no       0.00      0.00      0.00         2\n",
            "          pl       0.00      0.00      0.00        10\n",
            "          ps       0.00      0.00      0.00         4\n",
            "      pslatn       0.00      0.00      0.00         1\n",
            "          pt       0.93      0.19      0.31       349\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.88      0.79      0.83       124\n",
            "          si       0.00      0.00      0.00         6\n",
            "          sk       0.00      0.00      0.00         5\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         2\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       0.00      0.00      0.00         7\n",
            "          sv       0.00      0.00      0.00        10\n",
            "          sw       0.00      0.00      0.00         3\n",
            "          ta       0.00      0.00      0.00         3\n",
            "      talatn       0.00      0.00      0.00         2\n",
            "          th       0.00      0.00      0.00        65\n",
            "          tl       0.00      0.00      0.00        55\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        80\n",
            "          uk       0.00      0.00      0.00         8\n",
            "         und       0.41      0.50      0.45       548\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         2\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         6\n",
            "          xh       0.00      0.00      0.00         5\n",
            "          yo       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         5\n",
            "          zu       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.77      6765\n",
            "   macro avg       0.08      0.08      0.08      6765\n",
            "weighted avg       0.71      0.77      0.72      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy8NGueVOM5q"
      },
      "source": [
        "### Configuration 04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjKjeyXXOM5q",
        "outputId": "e6199608-83bc-4acf-d177-e209b2330308"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 4.02919301\n",
            "Validation score: 0.346748\n",
            "Iteration 2, loss = 3.14377492\n",
            "Validation score: 0.346748\n",
            "Iteration 3, loss = 2.56392484\n",
            "Validation score: 0.346748\n",
            "Iteration 4, loss = 2.35278089\n",
            "Validation score: 0.346748\n",
            "Iteration 5, loss = 2.26528485\n",
            "Validation score: 0.346748\n",
            "Iteration 6, loss = 2.21389089\n",
            "Validation score: 0.346748\n",
            "Iteration 7, loss = 2.17213758\n",
            "Validation score: 0.348883\n",
            "Iteration 8, loss = 2.13207392\n",
            "Validation score: 0.453515\n",
            "Iteration 9, loss = 2.09104169\n",
            "Validation score: 0.498357\n",
            "Iteration 10, loss = 2.04880234\n",
            "Validation score: 0.517247\n",
            "Iteration 11, loss = 2.00590778\n",
            "Validation score: 0.521189\n",
            "Iteration 12, loss = 1.96306010\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.92126695\n",
            "Validation score: 0.519054\n",
            "Iteration 14, loss = 1.88095186\n",
            "Validation score: 0.518397\n",
            "Iteration 15, loss = 1.84241353\n",
            "Validation score: 0.518233\n",
            "Iteration 16, loss = 1.80577731\n",
            "Validation score: 0.518068\n",
            "Iteration 17, loss = 1.77081258\n",
            "Validation score: 0.519218\n",
            "Iteration 18, loss = 1.73745917\n",
            "Validation score: 0.521189\n",
            "Iteration 19, loss = 1.70540344\n",
            "Validation score: 0.524967\n",
            "Iteration 20, loss = 1.67455771\n",
            "Validation score: 0.529566\n",
            "Iteration 21, loss = 1.64467251\n",
            "Validation score: 0.538601\n",
            "Iteration 22, loss = 1.61578854\n",
            "Validation score: 0.550099\n",
            "Iteration 23, loss = 1.58778501\n",
            "Validation score: 0.558804\n",
            "Iteration 24, loss = 1.56064452\n",
            "Validation score: 0.571124\n",
            "Iteration 25, loss = 1.53443847\n",
            "Validation score: 0.584264\n",
            "Iteration 26, loss = 1.50906186\n",
            "Validation score: 0.594941\n",
            "Iteration 27, loss = 1.48475539\n",
            "Validation score: 0.605289\n",
            "Iteration 28, loss = 1.46135115\n",
            "Validation score: 0.611695\n",
            "Iteration 29, loss = 1.43899993\n",
            "Validation score: 0.618594\n",
            "Iteration 30, loss = 1.41752904\n",
            "Validation score: 0.626807\n",
            "Iteration 31, loss = 1.39710464\n",
            "Validation score: 0.631735\n",
            "Iteration 32, loss = 1.37756625\n",
            "Validation score: 0.636827\n",
            "Iteration 33, loss = 1.35896542\n",
            "Validation score: 0.642904\n",
            "Iteration 34, loss = 1.34125814\n",
            "Validation score: 0.645696\n",
            "Iteration 35, loss = 1.32439846\n",
            "Validation score: 0.650460\n",
            "Iteration 36, loss = 1.30829094\n",
            "Validation score: 0.659001\n",
            "Iteration 37, loss = 1.29297601\n",
            "Validation score: 0.661794\n",
            "Iteration 38, loss = 1.27836837\n",
            "Validation score: 0.667871\n",
            "Iteration 39, loss = 1.26436781\n",
            "Validation score: 0.675920\n",
            "Iteration 40, loss = 1.25107209\n",
            "Validation score: 0.679698\n",
            "Iteration 41, loss = 1.23827764\n",
            "Validation score: 0.688239\n",
            "Iteration 42, loss = 1.22597316\n",
            "Validation score: 0.688568\n",
            "Iteration 43, loss = 1.21421455\n",
            "Validation score: 0.694809\n",
            "Iteration 44, loss = 1.20288021\n",
            "Validation score: 0.698259\n",
            "Iteration 45, loss = 1.19193738\n",
            "Validation score: 0.702037\n",
            "Iteration 46, loss = 1.18138379\n",
            "Validation score: 0.704172\n",
            "Iteration 47, loss = 1.17118849\n",
            "Validation score: 0.705979\n",
            "Iteration 48, loss = 1.16128318\n",
            "Validation score: 0.707786\n",
            "Iteration 49, loss = 1.15168758\n",
            "Validation score: 0.711235\n",
            "Iteration 50, loss = 1.14240475\n",
            "Validation score: 0.715177\n",
            "Iteration 51, loss = 1.13339869\n",
            "Validation score: 0.717477\n",
            "Iteration 52, loss = 1.12461737\n",
            "Validation score: 0.719777\n",
            "Iteration 53, loss = 1.11607600\n",
            "Validation score: 0.721255\n",
            "Iteration 54, loss = 1.10778021\n",
            "Validation score: 0.721912\n",
            "Iteration 55, loss = 1.09968494\n",
            "Validation score: 0.723883\n",
            "Iteration 56, loss = 1.09184158\n",
            "Validation score: 0.724540\n",
            "Iteration 57, loss = 1.08415567\n",
            "Validation score: 0.725690\n",
            "Iteration 58, loss = 1.07666505\n",
            "Validation score: 0.726511\n",
            "Iteration 59, loss = 1.06933136\n",
            "Validation score: 0.729304\n",
            "Iteration 60, loss = 1.06219828\n",
            "Validation score: 0.730453\n",
            "Iteration 61, loss = 1.05522855\n",
            "Validation score: 0.733903\n",
            "Iteration 62, loss = 1.04841870\n",
            "Validation score: 0.735381\n",
            "Iteration 63, loss = 1.04176983\n",
            "Validation score: 0.736859\n",
            "Iteration 64, loss = 1.03526080\n",
            "Validation score: 0.739159\n",
            "Iteration 65, loss = 1.02889163\n",
            "Validation score: 0.742444\n",
            "Iteration 66, loss = 1.02266797\n",
            "Validation score: 0.742773\n",
            "Iteration 67, loss = 1.01659430\n",
            "Validation score: 0.744251\n",
            "Iteration 68, loss = 1.01062949\n",
            "Validation score: 0.746879\n",
            "Iteration 69, loss = 1.00481937\n",
            "Validation score: 0.747865\n",
            "Iteration 70, loss = 0.99912205\n",
            "Validation score: 0.749671\n",
            "Iteration 71, loss = 0.99351362\n",
            "Validation score: 0.752464\n",
            "Iteration 72, loss = 0.98807280\n",
            "Validation score: 0.753614\n",
            "Iteration 73, loss = 0.98268432\n",
            "Validation score: 0.754271\n",
            "Iteration 74, loss = 0.97745743\n",
            "Validation score: 0.754763\n",
            "Iteration 75, loss = 0.97233744\n",
            "Validation score: 0.758870\n",
            "Iteration 76, loss = 0.96729777\n",
            "Validation score: 0.758870\n",
            "Iteration 77, loss = 0.96234634\n",
            "Validation score: 0.762319\n",
            "Iteration 78, loss = 0.95747945\n",
            "Validation score: 0.764619\n",
            "Iteration 79, loss = 0.95276842\n",
            "Validation score: 0.767904\n",
            "Iteration 80, loss = 0.94808632\n",
            "Validation score: 0.767740\n",
            "Iteration 81, loss = 0.94347783\n",
            "Validation score: 0.768561\n",
            "Iteration 82, loss = 0.93896076\n",
            "Validation score: 0.770696\n",
            "Iteration 83, loss = 0.93461697\n",
            "Validation score: 0.773489\n",
            "Iteration 84, loss = 0.93024661\n",
            "Validation score: 0.773653\n",
            "Iteration 85, loss = 0.92596250\n",
            "Validation score: 0.775460\n",
            "Iteration 86, loss = 0.92180211\n",
            "Validation score: 0.777267\n",
            "Iteration 87, loss = 0.91766880\n",
            "Validation score: 0.777924\n",
            "Iteration 88, loss = 0.91362931\n",
            "Validation score: 0.781209\n",
            "Iteration 89, loss = 0.90964798\n",
            "Validation score: 0.782523\n",
            "Iteration 90, loss = 0.90572372\n",
            "Validation score: 0.783837\n",
            "Iteration 91, loss = 0.90184454\n",
            "Validation score: 0.784166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PMRXKVjhb2b"
      },
      "source": [
        "**This code crashed after running for around 5 hours and we were not able to print the classification report. However, since the validation score is just at 78% eprcent after 91 iterations, we will not rerun it since it wont achieve the performance of the models being trained with Adam.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-brwl2BOwqC"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMBqHGuqmiwF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePp9RqvwpFzy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/ex01_mlp_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfUVMgBNottV"
      },
      "source": [
        "\n",
        "## hidden_layer_sizes=(200): configuration 5-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD569-BptrHc"
      },
      "source": [
        "### Configuration 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-T9ReRRthN4",
        "outputId": "29737cbd-1fca-4b14-952c-d7ab73c97711"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.09069852\n",
            "Validation score: 0.898160\n",
            "Iteration 2, loss = 0.27471013\n",
            "Validation score: 0.921321\n",
            "Iteration 3, loss = 0.13070372\n",
            "Validation score: 0.925591\n",
            "Iteration 4, loss = 0.07119369\n",
            "Validation score: 0.925427\n",
            "Iteration 5, loss = 0.04386892\n",
            "Validation score: 0.924277\n",
            "Iteration 6, loss = 0.03021037\n",
            "Validation score: 0.921813\n",
            "Iteration 7, loss = 0.02308790\n",
            "Validation score: 0.918693\n",
            "Iteration 8, loss = 0.01875333\n",
            "Validation score: 0.920171\n",
            "Iteration 9, loss = 0.01624824\n",
            "Validation score: 0.920171\n",
            "Iteration 10, loss = 0.01456572\n",
            "Validation score: 0.921321\n",
            "Iteration 11, loss = 0.01326822\n",
            "Validation score: 0.921156\n",
            "Iteration 12, loss = 0.01228777\n",
            "Validation score: 0.920007\n",
            "Iteration 13, loss = 0.01157770\n",
            "Validation score: 0.920171\n",
            "Iteration 14, loss = 0.01090817\n",
            "Validation score: 0.921156\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyNs9cs-uUPK",
        "outputId": "483dbf10-9496-4828-ddab-89949e18eaa3"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.99      0.97      0.98       259\n",
            "      arlatn       0.00      0.00      0.00         3\n",
            "          az       1.00      1.00      1.00         4\n",
            "          bg       1.00      1.00      1.00         3\n",
            "          bn       1.00      1.00      1.00         3\n",
            "          bs       1.00      1.00      1.00         2\n",
            "          ca       0.00      0.00      0.00         1\n",
            "          cs       1.00      1.00      1.00         5\n",
            "          cy       1.00      1.00      1.00         1\n",
            "          da       1.00      0.80      0.89         5\n",
            "          de       1.00      0.54      0.70        24\n",
            "          dv       1.00      1.00      1.00         7\n",
            "          el       1.00      0.75      0.86         4\n",
            "          en       0.92      0.97      0.94      2255\n",
            "          es       0.94      0.94      0.94       789\n",
            "          et       1.00      1.00      1.00         4\n",
            "          eu       1.00      1.00      1.00         2\n",
            "          fa       1.00      0.67      0.80         3\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.97      0.87      0.92       124\n",
            "          gl       1.00      1.00      1.00         2\n",
            "          ha       1.00      1.00      1.00         5\n",
            "          he       1.00      1.00      1.00         3\n",
            "          hi       1.00      1.00      1.00         2\n",
            "      hilatn       1.00      0.50      0.67         2\n",
            "          hr       1.00      1.00      1.00         2\n",
            "          ht       1.00      1.00      1.00         2\n",
            "          hu       1.00      0.75      0.86         8\n",
            "          hy       1.00      1.00      1.00         3\n",
            "          id       0.89      0.92      0.90       353\n",
            "          is       1.00      1.00      1.00         4\n",
            "          it       1.00      0.72      0.84        47\n",
            "          ja       0.99      0.98      0.99      1336\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.93      0.96        70\n",
            "      kolatn       1.00      1.00      1.00         5\n",
            "          la       1.00      1.00      1.00         5\n",
            "          lv       1.00      0.80      0.89         5\n",
            "          mk       1.00      1.00      1.00         4\n",
            "          mn       1.00      1.00      1.00         3\n",
            "          mr       1.00      1.00      1.00         5\n",
            "          ms       0.00      0.00      0.00        13\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.89      0.64      0.74        25\n",
            "          no       1.00      0.75      0.86         8\n",
            "          pl       1.00      0.67      0.80         9\n",
            "          ps       1.00      1.00      1.00         2\n",
            "      pslatn       1.00      1.00      1.00         1\n",
            "          pt       0.94      0.89      0.91       323\n",
            "          ro       1.00      1.00      1.00         1\n",
            "          ru       0.98      0.96      0.97       119\n",
            "          si       1.00      1.00      1.00         3\n",
            "          sk       1.00      1.00      1.00         1\n",
            "          sl       1.00      1.00      1.00         6\n",
            "          sq       1.00      1.00      1.00         1\n",
            "          sr       0.00      0.00      0.00         2\n",
            "          su       1.00      0.67      0.80         3\n",
            "          sv       1.00      0.57      0.73         7\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         5\n",
            "      talatn       1.00      1.00      1.00         6\n",
            "          th       0.98      0.95      0.97        64\n",
            "          tl       0.81      0.88      0.84        40\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.98      0.87      0.92        91\n",
            "          uk       1.00      0.88      0.93         8\n",
            "         und       0.68      0.70      0.69       606\n",
            "          ur       1.00      1.00      1.00         7\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      1.00      1.00         2\n",
            "          wo       1.00      1.00      1.00         6\n",
            "          xh       1.00      1.00      1.00         4\n",
            "          yo       1.00      1.00      1.00         3\n",
            "        zhcn       0.00      0.00      0.00         2\n",
            "        zhtw       1.00      1.00      1.00         3\n",
            "          zu       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.91      0.84      0.87      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwawZ5T9uF4x"
      },
      "source": [
        "### Configuration 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loFg9Uget1Qe",
        "outputId": "1da37358-909c-46e2-df76-695b781483f6"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.16928718\n",
            "Validation score: 0.896846\n",
            "Iteration 2, loss = 0.27827844\n",
            "Validation score: 0.924277\n",
            "Iteration 3, loss = 0.13075589\n",
            "Validation score: 0.931012\n",
            "Iteration 4, loss = 0.07191803\n",
            "Validation score: 0.931012\n",
            "Iteration 5, loss = 0.04476653\n",
            "Validation score: 0.931176\n",
            "Iteration 6, loss = 0.03102889\n",
            "Validation score: 0.930026\n",
            "Iteration 7, loss = 0.02358820\n",
            "Validation score: 0.929041\n",
            "Iteration 8, loss = 0.01942962\n",
            "Validation score: 0.929369\n",
            "Iteration 9, loss = 0.01665520\n",
            "Validation score: 0.929369\n",
            "Iteration 10, loss = 0.01488181\n",
            "Validation score: 0.928384\n",
            "Iteration 11, loss = 0.01358687\n",
            "Validation score: 0.928384\n",
            "Iteration 12, loss = 0.01254886\n",
            "Validation score: 0.928548\n",
            "Iteration 13, loss = 0.01174835\n",
            "Validation score: 0.927727\n",
            "Iteration 14, loss = 0.01116501\n",
            "Validation score: 0.928219\n",
            "Iteration 15, loss = 0.01050550\n",
            "Validation score: 0.927727\n",
            "Iteration 16, loss = 0.01003985\n",
            "Validation score: 0.928384\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E05Um7zGuW_C",
        "outputId": "092356f9-435b-45e2-b34c-6bf7a797df1d"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.99      0.99       283\n",
            "      arlatn       1.00      1.00      1.00         4\n",
            "          az       1.00      1.00      1.00         4\n",
            "          bg       1.00      1.00      1.00         7\n",
            "          bn       1.00      1.00      1.00         2\n",
            "          bs       1.00      0.80      0.89         5\n",
            "          ca       0.00      0.00      0.00         2\n",
            "          cs       1.00      1.00      1.00         3\n",
            "          cy       1.00      1.00      1.00         6\n",
            "          da       1.00      1.00      1.00         2\n",
            "          de       1.00      0.78      0.88        37\n",
            "          dv       1.00      1.00      1.00         3\n",
            "          el       1.00      1.00      1.00         1\n",
            "          en       0.93      0.97      0.95      2272\n",
            "          es       0.93      0.95      0.94       734\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         7\n",
            "          fa       1.00      0.50      0.67         2\n",
            "          fi       1.00      0.50      0.67         2\n",
            "          fr       0.97      0.79      0.87       144\n",
            "          gl       1.00      1.00      1.00         3\n",
            "          ha       1.00      1.00      1.00         4\n",
            "          he       1.00      1.00      1.00         3\n",
            "          hi       1.00      1.00      1.00         1\n",
            "      hilatn       1.00      0.75      0.86         4\n",
            "          hr       1.00      1.00      1.00         3\n",
            "          ht       1.00      1.00      1.00         2\n",
            "          hu       1.00      0.86      0.92         7\n",
            "          hy       1.00      1.00      1.00         2\n",
            "          id       0.84      0.88      0.86       366\n",
            "          is       1.00      1.00      1.00         3\n",
            "          it       0.93      0.67      0.78        39\n",
            "          ja       0.99      0.98      0.99      1276\n",
            "      jalatn       1.00      1.00      1.00         6\n",
            "          jv       1.00      1.00      1.00         7\n",
            "          km       1.00      1.00      1.00         3\n",
            "          ko       1.00      0.73      0.84        48\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         7\n",
            "          lv       1.00      1.00      1.00         5\n",
            "          mk       1.00      1.00      1.00         5\n",
            "          mn       1.00      1.00      1.00         7\n",
            "          mr       1.00      1.00      1.00         4\n",
            "          ms       0.50      0.10      0.17        20\n",
            "          ne       1.00      1.00      1.00         3\n",
            "          nl       1.00      0.77      0.87        26\n",
            "          no       1.00      1.00      1.00         2\n",
            "          pl       1.00      0.67      0.80        15\n",
            "          ps       1.00      1.00      1.00         5\n",
            "          pt       0.91      0.92      0.92       362\n",
            "          ro       1.00      0.67      0.80         6\n",
            "          ru       0.97      0.98      0.98       128\n",
            "          si       1.00      1.00      1.00         5\n",
            "          sk       1.00      1.00      1.00         3\n",
            "          sl       1.00      1.00      1.00         6\n",
            "          sq       1.00      1.00      1.00         5\n",
            "          sr       1.00      0.20      0.33         5\n",
            "          su       1.00      0.25      0.40         4\n",
            "          sv       1.00      0.44      0.62         9\n",
            "          sw       1.00      1.00      1.00         1\n",
            "          ta       1.00      1.00      1.00         7\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      1.00      1.00        51\n",
            "          tl       0.91      0.71      0.80        45\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.96      0.88      0.92        93\n",
            "          uk       1.00      0.86      0.92         7\n",
            "         und       0.64      0.65      0.65       596\n",
            "          ur       1.00      1.00      1.00         5\n",
            "      urlatn       1.00      0.60      0.75         5\n",
            "          vi       0.00      0.00      0.00         1\n",
            "          wo       1.00      1.00      1.00         2\n",
            "          xh       1.00      1.00      1.00         1\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhtw       1.00      1.00      1.00         3\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.95      0.87      0.89      6765\n",
            "weighted avg       0.92      0.92      0.91      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJJoxJWuotti"
      },
      "source": [
        "### Configuration 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-16T09:46:41.615001Z",
          "iopub.status.busy": "2021-10-16T09:46:41.614735Z",
          "iopub.status.idle": "2021-10-16T09:54:22.291069Z",
          "shell.execute_reply": "2021-10-16T09:54:22.289706Z",
          "shell.execute_reply.started": "2021-10-16T09:46:41.614971Z"
        },
        "id": "bubkQtE-iVyI",
        "outputId": "013903ef-bf6c-45e1-c6aa-d2e4c78320f5"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.70249981\n",
            "Validation score: 0.343627\n",
            "Iteration 2, loss = 2.69717160\n",
            "Validation score: 0.343627\n",
            "Iteration 3, loss = 2.39582595\n",
            "Validation score: 0.343627\n",
            "Iteration 4, loss = 2.26983137\n",
            "Validation score: 0.343627\n",
            "Iteration 5, loss = 2.20258270\n",
            "Validation score: 0.343627\n",
            "Iteration 6, loss = 2.15363711\n",
            "Validation score: 0.386170\n",
            "Iteration 7, loss = 2.10856486\n",
            "Validation score: 0.485381\n",
            "Iteration 8, loss = 2.06354278\n",
            "Validation score: 0.509198\n",
            "Iteration 9, loss = 2.01797672\n",
            "Validation score: 0.521353\n",
            "Iteration 10, loss = 1.97237272\n",
            "Validation score: 0.521353\n",
            "Iteration 11, loss = 1.92752119\n",
            "Validation score: 0.520368\n",
            "Iteration 12, loss = 1.88398228\n",
            "Validation score: 0.518725\n",
            "Iteration 13, loss = 1.84233862\n",
            "Validation score: 0.516919\n",
            "Iteration 14, loss = 1.80273953\n",
            "Validation score: 0.517083\n",
            "Iteration 15, loss = 1.76505337\n",
            "Validation score: 0.517576\n",
            "Iteration 16, loss = 1.72908061\n",
            "Validation score: 0.518561\n",
            "Iteration 17, loss = 1.69467793\n",
            "Validation score: 0.521353\n",
            "Iteration 18, loss = 1.66162981\n",
            "Validation score: 0.526281\n",
            "Iteration 19, loss = 1.62971276\n",
            "Validation score: 0.535808\n",
            "Iteration 20, loss = 1.59892563\n",
            "Validation score: 0.550263\n",
            "Iteration 21, loss = 1.56920564\n",
            "Validation score: 0.570795\n",
            "Iteration 22, loss = 1.54057397\n",
            "Validation score: 0.593298\n",
            "Iteration 23, loss = 1.51304759\n",
            "Validation score: 0.602168\n",
            "Iteration 24, loss = 1.48655961\n",
            "Validation score: 0.610217\n",
            "Iteration 25, loss = 1.46129017\n",
            "Validation score: 0.621222\n",
            "Iteration 26, loss = 1.43709952\n",
            "Validation score: 0.628449\n",
            "Iteration 27, loss = 1.41408361\n",
            "Validation score: 0.636005\n",
            "Iteration 28, loss = 1.39223118\n",
            "Validation score: 0.642247\n",
            "Iteration 29, loss = 1.37143819\n",
            "Validation score: 0.648982\n",
            "Iteration 30, loss = 1.35177536\n",
            "Validation score: 0.653581\n",
            "Iteration 31, loss = 1.33306992\n",
            "Validation score: 0.662122\n",
            "Iteration 32, loss = 1.31530034\n",
            "Validation score: 0.666557\n",
            "Iteration 33, loss = 1.29845560\n",
            "Validation score: 0.674934\n",
            "Iteration 34, loss = 1.28241096\n",
            "Validation score: 0.680848\n",
            "Iteration 35, loss = 1.26716929\n",
            "Validation score: 0.685283\n",
            "Iteration 36, loss = 1.25255334\n",
            "Validation score: 0.688568\n",
            "Iteration 37, loss = 1.23862458\n",
            "Validation score: 0.693495\n",
            "Iteration 38, loss = 1.22528452\n",
            "Validation score: 0.698095\n",
            "Iteration 39, loss = 1.21250156\n",
            "Validation score: 0.703187\n",
            "Iteration 40, loss = 1.20020462\n",
            "Validation score: 0.705322\n",
            "Iteration 41, loss = 1.18839254\n",
            "Validation score: 0.710578\n",
            "Iteration 42, loss = 1.17697136\n",
            "Validation score: 0.711071\n",
            "Iteration 43, loss = 1.16600295\n",
            "Validation score: 0.716820\n",
            "Iteration 44, loss = 1.15537412\n",
            "Validation score: 0.720598\n",
            "Iteration 45, loss = 1.14509963\n",
            "Validation score: 0.722733\n",
            "Iteration 46, loss = 1.13515941\n",
            "Validation score: 0.725033\n",
            "Iteration 47, loss = 1.12551359\n",
            "Validation score: 0.727497\n",
            "Iteration 48, loss = 1.11621460\n",
            "Validation score: 0.729796\n",
            "Iteration 49, loss = 1.10709397\n",
            "Validation score: 0.730946\n",
            "Iteration 50, loss = 1.09828425\n",
            "Validation score: 0.732917\n",
            "Iteration 51, loss = 1.08971079\n",
            "Validation score: 0.735053\n",
            "Iteration 52, loss = 1.08141290\n",
            "Validation score: 0.736859\n",
            "Iteration 53, loss = 1.07331725\n",
            "Validation score: 0.737845\n",
            "Iteration 54, loss = 1.06540585\n",
            "Validation score: 0.739159\n",
            "Iteration 55, loss = 1.05774942\n",
            "Validation score: 0.743430\n",
            "Iteration 56, loss = 1.05028504\n",
            "Validation score: 0.743594\n",
            "Iteration 57, loss = 1.04301203\n",
            "Validation score: 0.746386\n",
            "Iteration 58, loss = 1.03590004\n",
            "Validation score: 0.748522\n",
            "Iteration 59, loss = 1.02902258\n",
            "Validation score: 0.749507\n",
            "Iteration 60, loss = 1.02226838\n",
            "Validation score: 0.749343\n",
            "Iteration 61, loss = 1.01566995\n",
            "Validation score: 0.751150\n",
            "Iteration 62, loss = 1.00925489\n",
            "Validation score: 0.755256\n",
            "Iteration 63, loss = 1.00300600\n",
            "Validation score: 0.754271\n",
            "Iteration 64, loss = 0.99688749\n",
            "Validation score: 0.757227\n",
            "Iteration 65, loss = 0.99093246\n",
            "Validation score: 0.758541\n",
            "Iteration 66, loss = 0.98510924\n",
            "Validation score: 0.759034\n",
            "Iteration 67, loss = 0.97940174\n",
            "Validation score: 0.761662\n",
            "Iteration 68, loss = 0.97383430\n",
            "Validation score: 0.761991\n",
            "Iteration 69, loss = 0.96837912\n",
            "Validation score: 0.763469\n",
            "Iteration 70, loss = 0.96306066\n",
            "Validation score: 0.765769\n",
            "Iteration 71, loss = 0.95783286\n",
            "Validation score: 0.767740\n",
            "Iteration 72, loss = 0.95273305\n",
            "Validation score: 0.768725\n",
            "Iteration 73, loss = 0.94772958\n",
            "Validation score: 0.771682\n",
            "Iteration 74, loss = 0.94286595\n",
            "Validation score: 0.772011\n",
            "Iteration 75, loss = 0.93804390\n",
            "Validation score: 0.773653\n",
            "Iteration 76, loss = 0.93331464\n",
            "Validation score: 0.773325\n",
            "Iteration 77, loss = 0.92869261\n",
            "Validation score: 0.774639\n",
            "Iteration 78, loss = 0.92422148\n",
            "Validation score: 0.777267\n",
            "Iteration 79, loss = 0.91974878\n",
            "Validation score: 0.777760\n",
            "Iteration 80, loss = 0.91539317\n",
            "Validation score: 0.779895\n",
            "Iteration 81, loss = 0.91108623\n",
            "Validation score: 0.780223\n",
            "Iteration 82, loss = 0.90688962\n",
            "Validation score: 0.782359\n",
            "Iteration 83, loss = 0.90274567\n",
            "Validation score: 0.782852\n",
            "Iteration 84, loss = 0.89867988\n",
            "Validation score: 0.783673\n",
            "Iteration 85, loss = 0.89467521\n",
            "Validation score: 0.784494\n",
            "Iteration 86, loss = 0.89073850\n",
            "Validation score: 0.784658\n",
            "Iteration 87, loss = 0.88687711\n",
            "Validation score: 0.786958\n",
            "Iteration 88, loss = 0.88305621\n",
            "Validation score: 0.788272\n",
            "Iteration 89, loss = 0.87926802\n",
            "Validation score: 0.790407\n",
            "Iteration 90, loss = 0.87557077\n",
            "Validation score: 0.791229\n",
            "Iteration 91, loss = 0.87191952\n",
            "Validation score: 0.792050\n",
            "Iteration 92, loss = 0.86835515\n",
            "Validation score: 0.792871\n",
            "Iteration 93, loss = 0.86478605\n",
            "Validation score: 0.792707\n",
            "Iteration 94, loss = 0.86131876\n",
            "Validation score: 0.793693\n",
            "Iteration 95, loss = 0.85788630\n",
            "Validation score: 0.794842\n",
            "Iteration 96, loss = 0.85448165\n",
            "Validation score: 0.796978\n",
            "Iteration 97, loss = 0.85111729\n",
            "Validation score: 0.797470\n",
            "Iteration 98, loss = 0.84784344\n",
            "Validation score: 0.798456\n",
            "Iteration 99, loss = 0.84456882\n",
            "Validation score: 0.798949\n",
            "Iteration 100, loss = 0.84134895\n",
            "Validation score: 0.799770\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2021-10-16T09:54:22.292515Z",
          "iopub.status.idle": "2021-10-16T09:54:22.293197Z",
          "shell.execute_reply": "2021-10-16T09:54:22.292949Z",
          "shell.execute_reply.started": "2021-10-16T09:54:22.292922Z"
        },
        "id": "UnGrrGK2iVyI",
        "outputId": "4adfd1b3-2606-4f3b-fbcd-7fd35556e91a"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.93      0.96      0.95       255\n",
            "      arlatn       0.00      0.00      0.00         6\n",
            "          az       0.00      0.00      0.00         3\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         3\n",
            "          bs       0.00      0.00      0.00         4\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         3\n",
            "          de       0.00      0.00      0.00        21\n",
            "          dv       0.00      0.00      0.00         1\n",
            "          el       0.00      0.00      0.00         2\n",
            "          en       0.86      0.96      0.91      2358\n",
            "          es       0.77      0.92      0.84       738\n",
            "          et       0.00      0.00      0.00         7\n",
            "          eu       0.00      0.00      0.00         6\n",
            "          fa       0.00      0.00      0.00         3\n",
            "          fi       0.00      0.00      0.00         1\n",
            "          fr       0.00      0.00      0.00       114\n",
            "          gl       0.00      0.00      0.00         3\n",
            "          ha       0.00      0.00      0.00         2\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         3\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         4\n",
            "          ht       0.00      0.00      0.00         5\n",
            "          hu       0.00      0.00      0.00         6\n",
            "          id       0.64      0.79      0.71       345\n",
            "          is       0.00      0.00      0.00         6\n",
            "          it       0.00      0.00      0.00        50\n",
            "          ja       0.91      0.97      0.94      1297\n",
            "      jalatn       0.00      0.00      0.00         3\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         5\n",
            "          ko       0.00      0.00      0.00        50\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         4\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         3\n",
            "          mr       0.00      0.00      0.00         5\n",
            "          ms       0.00      0.00      0.00        17\n",
            "          ne       0.00      0.00      0.00         5\n",
            "          nl       0.00      0.00      0.00        27\n",
            "          no       0.00      0.00      0.00         3\n",
            "          pl       0.00      0.00      0.00        11\n",
            "          ps       0.00      0.00      0.00         9\n",
            "      pslatn       0.00      0.00      0.00         3\n",
            "          pt       0.88      0.65      0.75       388\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.90      0.89      0.89       110\n",
            "          si       0.00      0.00      0.00         1\n",
            "          sk       0.00      0.00      0.00         6\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         6\n",
            "          sr       0.00      0.00      0.00         3\n",
            "          su       0.00      0.00      0.00         4\n",
            "          sv       0.00      0.00      0.00         7\n",
            "          sw       0.00      0.00      0.00         4\n",
            "          ta       0.00      0.00      0.00         2\n",
            "      talatn       0.00      0.00      0.00         5\n",
            "          th       0.00      0.00      0.00        59\n",
            "          tl       0.00      0.00      0.00        50\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        90\n",
            "          uk       0.00      0.00      0.00         5\n",
            "         und       0.40      0.56      0.47       550\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         6\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         1\n",
            "          xh       0.00      0.00      0.00         2\n",
            "          yo       0.00      0.00      0.00         6\n",
            "        zhcn       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         6\n",
            "          zu       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.80      6765\n",
            "   macro avg       0.08      0.09      0.08      6765\n",
            "weighted avg       0.72      0.80      0.76      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9NJk_UluMvZ"
      },
      "source": [
        "### Configuration 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilsQFkyKuB-U",
        "outputId": "301684fa-ecde-44bf-8f4b-4ec7f0bf03e4"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.98300187\n",
            "Validation score: 0.339520\n",
            "Iteration 2, loss = 3.03748377\n",
            "Validation score: 0.339520\n",
            "Iteration 3, loss = 2.52303243\n",
            "Validation score: 0.339520\n",
            "Iteration 4, loss = 2.33395189\n",
            "Validation score: 0.339520\n",
            "Iteration 5, loss = 2.23689899\n",
            "Validation score: 0.339520\n",
            "Iteration 6, loss = 2.17713531\n",
            "Validation score: 0.341820\n",
            "Iteration 7, loss = 2.12898423\n",
            "Validation score: 0.431012\n",
            "Iteration 8, loss = 2.08270709\n",
            "Validation score: 0.502628\n",
            "Iteration 9, loss = 2.03630077\n",
            "Validation score: 0.518890\n",
            "Iteration 10, loss = 1.98986490\n",
            "Validation score: 0.521189\n",
            "Iteration 11, loss = 1.94401979\n",
            "Validation score: 0.521025\n",
            "Iteration 12, loss = 1.89970961\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.85725869\n",
            "Validation score: 0.519547\n",
            "Iteration 14, loss = 1.81703284\n",
            "Validation score: 0.519218\n",
            "Iteration 15, loss = 1.77893385\n",
            "Validation score: 0.518725\n",
            "Iteration 16, loss = 1.74274838\n",
            "Validation score: 0.520204\n",
            "Iteration 17, loss = 1.70825634\n",
            "Validation score: 0.522175\n",
            "Iteration 18, loss = 1.67517703\n",
            "Validation score: 0.526610\n",
            "Iteration 19, loss = 1.64329366\n",
            "Validation score: 0.538108\n",
            "Iteration 20, loss = 1.61260493\n",
            "Validation score: 0.546978\n",
            "Iteration 21, loss = 1.58296134\n",
            "Validation score: 0.560775\n",
            "Iteration 22, loss = 1.55433587\n",
            "Validation score: 0.575230\n",
            "Iteration 23, loss = 1.52672923\n",
            "Validation score: 0.591656\n",
            "Iteration 24, loss = 1.50018910\n",
            "Validation score: 0.606767\n",
            "Iteration 25, loss = 1.47468322\n",
            "Validation score: 0.618265\n",
            "Iteration 26, loss = 1.45025312\n",
            "Validation score: 0.623850\n",
            "Iteration 27, loss = 1.42696090\n",
            "Validation score: 0.627792\n",
            "Iteration 28, loss = 1.40474078\n",
            "Validation score: 0.635677\n",
            "Iteration 29, loss = 1.38355712\n",
            "Validation score: 0.640604\n",
            "Iteration 30, loss = 1.36343794\n",
            "Validation score: 0.645696\n",
            "Iteration 31, loss = 1.34436424\n",
            "Validation score: 0.649639\n",
            "Iteration 32, loss = 1.32621072\n",
            "Validation score: 0.653252\n",
            "Iteration 33, loss = 1.30893355\n",
            "Validation score: 0.657359\n",
            "Iteration 34, loss = 1.29252028\n",
            "Validation score: 0.663765\n",
            "Iteration 35, loss = 1.27691213\n",
            "Validation score: 0.671813\n",
            "Iteration 36, loss = 1.26202509\n",
            "Validation score: 0.678384\n",
            "Iteration 37, loss = 1.24780959\n",
            "Validation score: 0.681505\n",
            "Iteration 38, loss = 1.23421558\n",
            "Validation score: 0.686104\n",
            "Iteration 39, loss = 1.22117372\n",
            "Validation score: 0.688568\n",
            "Iteration 40, loss = 1.20867471\n",
            "Validation score: 0.693824\n",
            "Iteration 41, loss = 1.19669775\n",
            "Validation score: 0.697109\n",
            "Iteration 42, loss = 1.18512879\n",
            "Validation score: 0.701873\n",
            "Iteration 43, loss = 1.17395944\n",
            "Validation score: 0.705486\n",
            "Iteration 44, loss = 1.16320444\n",
            "Validation score: 0.708443\n",
            "Iteration 45, loss = 1.15284571\n",
            "Validation score: 0.710250\n",
            "Iteration 46, loss = 1.14277769\n",
            "Validation score: 0.715342\n",
            "Iteration 47, loss = 1.13301892\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.12355959\n",
            "Validation score: 0.720105\n",
            "Iteration 49, loss = 1.11441324\n",
            "Validation score: 0.723390\n",
            "Iteration 50, loss = 1.10550422\n",
            "Validation score: 0.726511\n",
            "Iteration 51, loss = 1.09684978\n",
            "Validation score: 0.729139\n",
            "Iteration 52, loss = 1.08842390\n",
            "Validation score: 0.731110\n",
            "Iteration 53, loss = 1.08023785\n",
            "Validation score: 0.732917\n",
            "Iteration 54, loss = 1.07225205\n",
            "Validation score: 0.734231\n",
            "Iteration 55, loss = 1.06448317\n",
            "Validation score: 0.735545\n",
            "Iteration 56, loss = 1.05690499\n",
            "Validation score: 0.737024\n",
            "Iteration 57, loss = 1.04955022\n",
            "Validation score: 0.738995\n",
            "Iteration 58, loss = 1.04233262\n",
            "Validation score: 0.740966\n",
            "Iteration 59, loss = 1.03536738\n",
            "Validation score: 0.743101\n",
            "Iteration 60, loss = 1.02851266\n",
            "Validation score: 0.745072\n",
            "Iteration 61, loss = 1.02183352\n",
            "Validation score: 0.745237\n",
            "Iteration 62, loss = 1.01530706\n",
            "Validation score: 0.747700\n",
            "Iteration 63, loss = 1.00895242\n",
            "Validation score: 0.748193\n",
            "Iteration 64, loss = 1.00274792\n",
            "Validation score: 0.751807\n",
            "Iteration 65, loss = 0.99668398\n",
            "Validation score: 0.751478\n",
            "Iteration 66, loss = 0.99078650\n",
            "Validation score: 0.752135\n",
            "Iteration 67, loss = 0.98500460\n",
            "Validation score: 0.753614\n",
            "Iteration 68, loss = 0.97932487\n",
            "Validation score: 0.756242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMtrpZF1pzjq"
      },
      "source": [
        "**The colab session crashed before we get the result after 10 hours run.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "j6tBcAL6uawv",
        "outputId": "9754a3fb-89a8-4e1c-e824-bb34cc6cf5f9"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-574670982061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E7FhC3Vottq"
      },
      "source": [
        "## hidden_layer_sizes=(500): configuration 9-12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vmZicxFTiX4"
      },
      "source": [
        "### Combination 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gG74xARKrZC",
        "outputId": "ffe78e75-8465-4cc8-e416-20a11a457baf"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(500), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.82472025\n",
            "Validation score: 0.908837\n",
            "Iteration 2, loss = 0.17352512\n",
            "Validation score: 0.920171\n",
            "Iteration 3, loss = 0.07117001\n",
            "Validation score: 0.921649\n",
            "Iteration 4, loss = 0.03742881\n",
            "Validation score: 0.919842\n",
            "Iteration 5, loss = 0.02495777\n",
            "Validation score: 0.920335\n",
            "Iteration 6, loss = 0.01901140\n",
            "Validation score: 0.918528\n",
            "Iteration 7, loss = 0.01588782\n",
            "Validation score: 0.917871\n",
            "Iteration 8, loss = 0.01424210\n",
            "Validation score: 0.919185\n",
            "Iteration 9, loss = 0.01283344\n",
            "Validation score: 0.918035\n",
            "Iteration 10, loss = 0.01216719\n",
            "Validation score: 0.920007\n",
            "Iteration 11, loss = 0.01148272\n",
            "Validation score: 0.917378\n",
            "Iteration 12, loss = 0.01059250\n",
            "Validation score: 0.916886\n",
            "Iteration 13, loss = 0.01011839\n",
            "Validation score: 0.919185\n",
            "Iteration 14, loss = 0.01071457\n",
            "Validation score: 0.917543\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=500, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJpUqokLqGvf"
      },
      "source": [
        "**The colab session crashed before we get the result after 10 hours run.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "mjUMgfMlq_lH",
        "outputId": "3efc3133-c5bf-4283-8e68-ed1f04b392a6"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4098ccd1e49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8kd-ZnxUTW_"
      },
      "source": [
        "### Configuration 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-MaLYsZKuBh",
        "outputId": "e17595ac-5f2a-4e13-cbe4-00a9ebf16770"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(500), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.88746644\n",
            "Validation score: 0.906045\n",
            "Iteration 2, loss = 0.17268924\n",
            "Validation score: 0.917543\n",
            "Iteration 3, loss = 0.07023909\n",
            "Validation score: 0.914915\n",
            "Iteration 4, loss = 0.03684853\n",
            "Validation score: 0.917871\n",
            "Iteration 5, loss = 0.02410536\n",
            "Validation score: 0.915572\n",
            "Iteration 6, loss = 0.01850925\n",
            "Validation score: 0.917871\n",
            "Iteration 7, loss = 0.01546526\n",
            "Validation score: 0.917871\n",
            "Iteration 8, loss = 0.01385808\n",
            "Validation score: 0.916721\n",
            "Iteration 9, loss = 0.01271496\n",
            "Validation score: 0.919514\n",
            "Iteration 10, loss = 0.01164270\n",
            "Validation score: 0.917543\n",
            "Iteration 11, loss = 0.01123009\n",
            "Validation score: 0.917707\n",
            "Iteration 12, loss = 0.01060281\n",
            "Validation score: 0.915736\n",
            "Iteration 13, loss = 0.01013526\n",
            "Validation score: 0.915079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R19cHZK9rXMO"
      },
      "source": [
        "**The colab session crashed before we get the result after 10 hours run.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csxLLtSdKt9X"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzwe2cJ6UWf8"
      },
      "source": [
        "### Configuration 11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSlzNWNqKt57",
        "outputId": "043250a0-ebcb-41e7-b6d8-c9dcdfed0172"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(500), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.68443523\n",
            "Validation score: 0.345762\n",
            "Iteration 2, loss = 2.63764847\n",
            "Validation score: 0.345762\n",
            "Iteration 3, loss = 2.35022142\n",
            "Validation score: 0.345762\n",
            "Iteration 4, loss = 2.23328714\n",
            "Validation score: 0.345762\n",
            "Iteration 5, loss = 2.16417720\n",
            "Validation score: 0.386170\n",
            "Iteration 6, loss = 2.10882945\n",
            "Validation score: 0.481603\n",
            "Iteration 7, loss = 2.05712003\n",
            "Validation score: 0.522832\n",
            "Iteration 8, loss = 2.00638822\n",
            "Validation score: 0.528088\n",
            "Iteration 9, loss = 1.95653822\n",
            "Validation score: 0.531373\n",
            "Iteration 10, loss = 1.90800705\n",
            "Validation score: 0.530059\n",
            "Iteration 11, loss = 1.86130113\n",
            "Validation score: 0.529566\n",
            "Iteration 12, loss = 1.81666854\n",
            "Validation score: 0.530716\n",
            "Iteration 13, loss = 1.77432900\n",
            "Validation score: 0.531866\n",
            "Iteration 14, loss = 1.73405267\n",
            "Validation score: 0.536137\n",
            "Iteration 15, loss = 1.69574580\n",
            "Validation score: 0.542707\n",
            "Iteration 16, loss = 1.65919949\n",
            "Validation score: 0.555683\n",
            "Iteration 17, loss = 1.62426462\n",
            "Validation score: 0.568495\n",
            "Iteration 18, loss = 1.59091210\n",
            "Validation score: 0.580815\n",
            "Iteration 19, loss = 1.55903911\n",
            "Validation score: 0.599047\n",
            "Iteration 20, loss = 1.52858522\n",
            "Validation score: 0.614488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUokyr6OqPEQ"
      },
      "source": [
        "**The colab session crashed before we get the result after 10 hours run.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaQATAAWKtyV"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk5R1_c8UaN0"
      },
      "source": [
        "### Configuration 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-nuY4c-Ktjw",
        "outputId": "c3b4651f-97c0-427b-e732-4a66fca5efbd"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(500), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.95299450\n",
            "Validation score: 0.340342\n",
            "Iteration 2, loss = 2.87220791\n",
            "Validation score: 0.340342\n",
            "Iteration 3, loss = 2.42962469\n",
            "Validation score: 0.340342\n",
            "Iteration 4, loss = 2.27259029\n",
            "Validation score: 0.340342\n",
            "Iteration 5, loss = 2.19337572\n",
            "Validation score: 0.340342\n",
            "Iteration 6, loss = 2.13754228\n",
            "Validation score: 0.428055\n",
            "Iteration 7, loss = 2.08775902\n",
            "Validation score: 0.500329\n",
            "Iteration 8, loss = 2.03915492\n",
            "Validation score: 0.522175\n",
            "Iteration 9, loss = 1.99110016\n",
            "Validation score: 0.525953\n",
            "Iteration 10, loss = 1.94410927\n",
            "Validation score: 0.523817\n",
            "Iteration 11, loss = 1.89856533\n",
            "Validation score: 0.523489\n",
            "Iteration 12, loss = 1.85516263\n",
            "Validation score: 0.522339\n",
            "Iteration 13, loss = 1.81384239\n",
            "Validation score: 0.521189\n",
            "Iteration 14, loss = 1.77465418\n",
            "Validation score: 0.521846\n",
            "Iteration 15, loss = 1.73740386\n",
            "Validation score: 0.522503\n",
            "Iteration 16, loss = 1.70188760\n",
            "Validation score: 0.525131\n",
            "Iteration 17, loss = 1.66773673\n",
            "Validation score: 0.529074\n",
            "Iteration 18, loss = 1.63498784\n",
            "Validation score: 0.540407\n",
            "Iteration 19, loss = 1.60339628\n",
            "Validation score: 0.552562\n",
            "Iteration 20, loss = 1.57296938\n",
            "Validation score: 0.571781\n",
            "Iteration 21, loss = 1.54365255\n",
            "Validation score: 0.588535\n",
            "Iteration 22, loss = 1.51551032\n",
            "Validation score: 0.597898\n",
            "Iteration 23, loss = 1.48851370\n",
            "Validation score: 0.608246\n",
            "Iteration 24, loss = 1.46271861\n",
            "Validation score: 0.619087\n",
            "Iteration 25, loss = 1.43809107\n",
            "Validation score: 0.628942\n",
            "Iteration 26, loss = 1.41466027\n",
            "Validation score: 0.633870\n",
            "Iteration 27, loss = 1.39247112\n",
            "Validation score: 0.639947\n",
            "Iteration 28, loss = 1.37133470\n",
            "Validation score: 0.647175\n",
            "Iteration 29, loss = 1.35127178\n",
            "Validation score: 0.654731\n",
            "Iteration 30, loss = 1.33236297\n",
            "Validation score: 0.660315\n",
            "Iteration 31, loss = 1.31434586\n",
            "Validation score: 0.665243\n",
            "Iteration 32, loss = 1.29729162\n",
            "Validation score: 0.672635\n",
            "Iteration 33, loss = 1.28101623\n",
            "Validation score: 0.677727\n",
            "Iteration 34, loss = 1.26563277\n",
            "Validation score: 0.682819\n",
            "Iteration 35, loss = 1.25088810\n",
            "Validation score: 0.688403\n",
            "Iteration 36, loss = 1.23684723\n",
            "Validation score: 0.692510\n",
            "Iteration 37, loss = 1.22341482\n",
            "Validation score: 0.695138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-dFNGuIrZlb"
      },
      "source": [
        "**The colab session crashed before we get the result after 10 hours run.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdiIc3jnUIa4"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ]
    }
  ]
}