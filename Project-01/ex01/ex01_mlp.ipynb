{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex01_mlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/ex01_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mUlNUnJ4Ljk"
      },
      "source": [
        "# Exercise 01 - Part 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-tSmGwauDkm"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFdqlZ-1uDSw"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfzPwQnN2eHY"
      },
      "source": [
        "## 1. Data Acquisition\n",
        "In this assignment we are not going to do all the data cleaning and preprocessing again.  \n",
        "We are just loading the saved dataset from the first exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPHMAkQcl6HA",
        "outputId": "c7995366-3419-4123-d2f4-cac620673127"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▋                        | 10 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 20 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 40 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 679 kB/s \n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNaUC8y6JDVx",
        "outputId": "3f0b7126-89ec-49f6-92ee-0bc39a2906a9"
      },
      "source": [
        "!pip install googletrans==4.0.0rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2021.5.30)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2.10)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (3.0.4)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.10.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 27.7 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17415 sha256=ab51c0e4dc37633575e4f28eb4253156e8a7e8ea46131278007b70852f53d617\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/00/4fe71786ea6d12314b29037620c36d857e5d104ac2748bf82a\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.10.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aoiO-Esh19N"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdOJGl6Gr07z"
      },
      "source": [
        "from io import StringIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 200)  \n",
        "pd.set_option('display.max_columns', 200)   \n",
        "pd.set_option('display.width', 4000) \n",
        "\n",
        "\n",
        "import demoji\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from googletrans import Translator\n",
        "translator = Translator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8zj6rO6hKo2"
      },
      "source": [
        "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
        "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgLDtzKQ52IL"
      },
      "source": [
        "#translated_data = pd.read_pickle('sample_data/augmented_data.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkIJ7QuNv_lt"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYruJqdrsPOS"
      },
      "source": [
        "TARGET_COLUMN = 'label'\n",
        "TWEET_COLUMN = 'tweet'\n",
        "SAMPLE_THRESHOLD = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okInclFn5rzc"
      },
      "source": [
        "### 1. Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdwxfjxjhN58"
      },
      "source": [
        "def load_dataset(url):\n",
        "    r = requests.get(url)\n",
        "    data = r.content.decode('utf8')\n",
        "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
        "    df.columns = ['tweet', 'label']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmOiJT-2hPpt"
      },
      "source": [
        "training_data = load_dataset(url_train_dev)\n",
        "test_data = load_dataset(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhRDofrsShY"
      },
      "source": [
        "dataset = pd.concat([training_data, test_data], axis=0) # Merge into one dataset for the pre-processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSWYkwJnsZ9h",
        "outputId": "ae20a38e-205a-4f63-fb95-a2e7396e9e4d"
      },
      "source": [
        "print(\"The length of the combined dataset is {0} training samples + {1} test samples = {2} samples\".format(len(training_data), len(test_data), len(dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the combined dataset is 52675 training samples + 13279 test samples = 65954 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJDwSNkfuMcE"
      },
      "source": [
        "dataset = dataset.sample(frac=1).reset_index(drop=True) # Randomly shuffle the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "TvoAwKLCzd7N",
        "outputId": "71d1ade0-2084-4b53-81ac-506c525c21a8"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anyone goin to the rope swing?</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No fue fácil pero valió la pena.</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jochortega es plaga el lala jajajaja</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>特進の校舎のトイレはウォシュレットがついていて羨ましい</td>\n",
              "      <td>ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>두 눈을 감은 이유가, 누구때문도 아니기를...</td>\n",
              "      <td>ko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Today stats: One follower, No unfollowers via ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Phone-hacking case shows openness is best poli...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@BlEBERSKING haha baby💕</td>\n",
              "      <td>und</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Brezilya artik sana aciyorum. :(</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@EmmaPereyraaa jajajaja ;)))))</td>\n",
              "      <td>und</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet label\n",
              "0                     Anyone goin to the rope swing?    en\n",
              "1                   No fue fácil pero valió la pena.    es\n",
              "2              @jochortega es plaga el lala jajajaja    es\n",
              "3                        特進の校舎のトイレはウォシュレットがついていて羨ましい    ja\n",
              "4                         두 눈을 감은 이유가, 누구때문도 아니기를...    ko\n",
              "5  Today stats: One follower, No unfollowers via ...    en\n",
              "6  Phone-hacking case shows openness is best poli...    en\n",
              "7                            @BlEBERSKING haha baby💕   und\n",
              "8                   Brezilya artik sana aciyorum. :(    tr\n",
              "9                     @EmmaPereyraaa jajajaja ;)))))   und"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OZ3EaAQ6Ahq"
      },
      "source": [
        "### 2. Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heZh4YHxhhQA"
      },
      "source": [
        "def data_exploration(df):\n",
        "  n_labels = len(np.unique(df[\"label\"]))\n",
        "  df = df.sort_values('label')\n",
        "  print(\"Dataset contains the columns: {}\".format(list(df.keys())))\n",
        "  print(\"with a total of {} observations\".format(len(df)))\n",
        "  print(\"and {} different possible labels.\".format(n_labels))\n",
        "  print(\"The unique labels are {}\".format(df[\"label\"].unique()))\n",
        "  plt.figure(figsize=(15, 3))\n",
        "  plt.hist(df[\"label\"], bins=n_labels)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yscale(\"log\")\n",
        "  plt.xlabel(\"Language\")\n",
        "  plt.ylabel(\"#Occurences\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Z5fpaX76xr"
      },
      "source": [
        "def get_underrepresented_languages(df, target_column, sample_threshold):\n",
        "    df = df.groupby(target_column).size().to_frame().reset_index(drop=False).rename(columns={0: 'occurences'})\n",
        "    underrepresented_languages = list(df[df['occurences'] < SAMPLE_THRESHOLD][target_column])\n",
        "    return underrepresented_languages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syyazhl683ZK"
      },
      "source": [
        "def print_number_of_underrepresented_languages(df, target_column, sample_threshold):\n",
        "  underrepresented_languages = get_underrepresented_languages(df, target_column, sample_threshold)\n",
        "  print(\"There are {} languages in this data set with less then {} samples.\".format(len(underrepresented_languages), sample_threshold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "IZtCEi7_hYQW",
        "outputId": "e77197d7-ef9a-42f8-c00e-957f2b26e293"
      },
      "source": [
        "data_exploration(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contains the columns: ['tweet', 'label']\n",
            "with a total of 65954 observations\n",
            "and 78 different possible labels.\n",
            "The unique labels are ['ar' 'ar_LATN' 'az' 'bg' 'bn' 'bs' 'ca' 'cs' 'cy' 'da' 'de' 'dv' 'el'\n",
            " 'en' 'es' 'et' 'eu' 'fa' 'fi' 'fr' 'gl' 'ha' 'he' 'hi' 'hi-Latn' 'hr'\n",
            " 'ht' 'hu' 'hy' 'id' 'is' 'it' 'ja' 'ja_LATN' 'jv' 'km' 'ko' 'ko_LATN'\n",
            " 'la' 'lv' 'mk' 'mn' 'mr' 'ms' 'ne' 'nl' 'no' 'pl' 'ps' 'ps_LATN' 'pt'\n",
            " 'ro' 'ru' 'si' 'sk' 'sl' 'sq' 'sr' 'su' 'sv' 'sw' 'ta' 'ta_LATN' 'th'\n",
            " 'tl' 'tn' 'tr' 'uk' 'und' 'ur' 'ur_LATN' 'vi' 'wo' 'xh' 'yo' 'zh-CN'\n",
            " 'zh-TW' 'zu']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLPZXkaLCH3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6662d7-6bf2-4d94-bd87-372c484a3661"
      },
      "source": [
        "print_number_of_underrepresented_languages(dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 50 languages in this data set with less then 20 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYLOL2_B5OrT"
      },
      "source": [
        "### 3. Text Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np67DQkz5JEm"
      },
      "source": [
        "This is generally a good idea as many text classification tools rely on counting the occurrences of words. If both upper and lower case versions of the same word are found in the text then the algorithm will count them as different words even though the meaning is the same. Of course this does mean that where the capitalised versions of a word exists, that does have a different meaning. For example the company Apple vs the fruit apple. This could result in poorer performance for some data sets. This is one area of NLP where you may try different methods to see how they affect the overall performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsh1XvSsAwYL"
      },
      "source": [
        "def remove_all_emojis(text):\n",
        "  dem = demoji.findall(text)\n",
        "  for item in dem.keys():\n",
        "    text = text.replace(item, '')\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQfxTUB36n4C"
      },
      "source": [
        "def clean_data(df, column):\n",
        "    df = df.copy(deep=True) # Make deep copy of tweets\n",
        "    df[column] = df[column].str.lower() # Transform into all lowercase\n",
        "    \n",
        "    patterns = []\n",
        "    retweet_pattern = '^RT'\n",
        "    patterns.append(retweet_pattern)\n",
        "    xml_pattern = '&\\S+;'\n",
        "    patterns.append(xml_pattern)\n",
        "    hashtag_pattern = '#[A-Za-z0-9_]+'\n",
        "    patterns.append(hashtag_pattern)\n",
        "    twitter_mention_pattern = '@[A-Za-z0-9_]+'\n",
        "    patterns.append(twitter_mention_pattern)\n",
        "    http_pattern = 'http\\S+'\n",
        "    patterns.append(http_pattern)\n",
        "    www_pattern = 'www\\S+'\n",
        "    patterns.append(www_pattern)\n",
        "    tab_pattern = '\\t'\n",
        "    patterns.append(tab_pattern)\n",
        "    punctuation_pattern = '[!\"#$%&\\\\()*+,-./:;<=>?@\\[\\]^_`\\'{}~]+'\n",
        "    patterns.append(punctuation_pattern)\n",
        "    numeric_pattern = '[0-9]+'\n",
        "    patterns.append(numeric_pattern)\n",
        "    regex = \"|\".join(patterns)\n",
        "\n",
        "    #df[column] = df[column].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem)) \n",
        "    df[column] = df[column].apply(lambda elem: re.sub(r\"{}\".format(regex), \"\", elem))\n",
        "    df[column] = df[column].apply(remove_all_emojis)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtIoEEyK8Dxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be448858-f4be-45bd-d6d8-89873a0301da"
      },
      "source": [
        "# Now we want to find out which special characters need to be removed from tweets in order to make the prediction better.\n",
        "# We go over the printed list an not down the symbold which are not needed for language identification.\n",
        "# These will be removed in a later step.\n",
        "languages = list(np.unique(test_data['label']))\n",
        "for language in languages:\n",
        "  localized_tweets = training_data[training_data['label'] == language]\n",
        "  # Clean and compare them\n",
        "  cleaned_localized_tweets = clean_data(localized_tweets, 'tweet')\n",
        "  comparison_view = pd.concat([localized_tweets.drop(['label'], axis=1), cleaned_localized_tweets], axis=1)\n",
        "  print(comparison_view.head(5))\n",
        "  #print(localized_tweets.head(5))\n",
        "  print(\"---\")\n",
        "\n",
        "# Symbols like @<mention>, #, http://link !, numeric values (e.g 16000), \" do not help for language identification."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet                                              tweet label\n",
            "0  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...    ar\n",
            "1  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...    ar\n",
            "2  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...    ar\n",
            "3                                  يا ابو سلو عرفتني                                  يا ابو سلو عرفتني    ar\n",
            "4  ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...  ب ريال أكفل معتمر في رمضان ، ولك بإذن الله مثل...    ar\n",
            "---\n",
            "                                         tweet                            tweet    label\n",
            "2199                      ya allah ya allah x)              ya allah ya allah x  ar_LATN\n",
            "2200                   Ya rab tekhlas hel game          ya rab tekhlas hel game  ar_LATN\n",
            "2201                           Istaqfurullah 😂                   istaqfurullah   ar_LATN\n",
            "2202  @g56_ 7abeeebbbbbie enty ghalaaayyyy 😩❤️   abeeebbbbbie enty ghalaaayyyy   ar_LATN\n",
            "2203    Ya Hasiib... Ya Jaliil... Ya Mujiib...    ya hasiib ya jaliil ya mujiib  ar_LATN\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2211  Gözləmək səbrin imtahanıdır.Sevinc qapısının a...  gözləmək səbrin imtahanıdırsevinc qapısının aç...    az\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2212  Ботас може да стане изключителен пилот, смята ...  ботас може да стане изключителен пилот смята с...    bg\n",
            "2213  Най-добре се смее ,който се смее последен --дн...  найдобре се смее който се смее последен днес м...    bg\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2222  Najbolji 💟💟 blue angels berlin http://t.co/4wF...                      najbolji  blue angels berlin     bs\n",
            "2223  Subotić oslobodjen optužbi za šverc cigareta- ...      subotić oslobodjen optužbi za šverc cigareta     bs\n",
            "2224              @samobakrac u septembru ulaze u vlast                          u septembru ulaze u vlast    bs\n",
            "2225  Italijanski novinar Vanoli(70) upozorava: VAKC...  italijanski novinar vanoli upozorava vakcinama...    bs\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2226  @Laureta8 a tu cariñet dspues prlem molts besi...            a tu cariñet dspues prlem molts besitos    ca\n",
            "2227  No en tinc ni idea Teresa @llobetilla, esperem...  no en tinc ni idea teresa  esperem que respong...    ca\n",
            "2228  Res es imposible. Ell m'ha ensenyat que si vol...  res es imposible ell mha ensenyat que si vols ...    ca\n",
            "2229                   @CescGF jaspi aventures mata! :)                              jaspi aventures mata     ca\n",
            "2230  @Somia_Truites Ets tot un caballer!!! I una mo...   ets tot un caballer i una molt bona persona a...    ca\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2248  Mechanical Moth - Winternachtstraum texty a př...  mechanical moth  winternachtstraum texty a pře...    cs\n",
            "2249  Na Novotného lávce jsou k vidění Smetanovy kre...  na novotného lávce jsou k vidění smetanovy kre...    cs\n",
            "2250  #ojeu #notice 33115100 €521k Český Krumlov:CT ...     €k český krumlovct skener dodávka ct skener...    cs\n",
            "2251  Sestra nevěsty má dle maminky důležitou úlohu....  sestra nevěsty má dle maminky důležitou úlohu ...    cs\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2253                           @UnibetNorge 2-1 til arg                                            til arg    da\n",
            "2254  Blank &amp; Jones - Fallen (Delerium &amp; Ran...  blank  jones  fallen delerium  rani sangtekste...    da\n",
            "2255         @jesperdahl @kaarelbk det er jo helt vildt                               det er jo helt vildt    da\n",
            "2256  @mpbdavidsen Jeg har nydt hvert et minut. Men ...   jeg har nydt hvert et minut men jeg føler ikk...    da\n",
            "2257  BB (Les) - Comme Un Loup sangtekster og oversæ...  bb les  comme un loup sangtekster og oversætte...    da\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2260                @hmjahnel guten morgen, der herr :)                             guten morgen der herr     de\n",
            "2261  @SkaKeller @GreensEP @Piratenpartei @JanAlbrec...                                      wie peinlich     de\n",
            "2262  Ich habe 16,100 Goldmünzen gesammelt! http://t...                 ich habe  goldmünzen gesammelt        de\n",
            "2263  Dachte früher immer es heißt \"Sommer Angebot\" ...  dachte früher immer es heißt sommer angebot an...    de\n",
            "2264  Da kommt Bei mir ist es sau langsam; keine Sch...  da kommt bei mir ist es sau langsam keine schu...    de\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2432  Όλα ξεκινάνε από τον ανύπαρκτο επαγγελματικό π...  όλα ξεκινάνε από τον ανύπαρκτο επαγγελματικό π...    el\n",
            "2433  http://t.co/sLTRx7aTgP  #Bring1DToGreeceCampai...                                       διακοσια ολε    el\n",
            "2434  Μπαίνει και περπατάει κατσαρίδα στο σπιτι σαν ...  μπαίνει και περπατάει κατσαρίδα στο σπιτι σαν ...    el\n",
            "2435  @its_leonidas Δεν νομίζω να έχετε λόγο να το κ...   δεν νομίζω να έχετε λόγο να το κάνετε ούτε δι...    el\n",
            "2436  Πανηγυρίζει και η ΔΗΜΑΡ για την επέλαση των ισ...  πανηγυρίζει και η δημαρ για την επέλαση των ισ...    el\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2460  Οταν όμως είναι το κράτος που επιβάλλει διά νό...  οταν όμως είναι το κράτος που επιβάλλει διά νό...    en\n",
            "2461                             @Duaa_e_aamir  urself*                                             urself    en\n",
            "2462                               1/5 please #JulyWish                                            please     en\n",
            "2463                                           to happy                                           to happy    en\n",
            "2464      Wtfffff already a month of summer has gone by      wtfffff already a month of summer has gone by    en\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "20968  LAS EMOCIONES dependen del grado de: CANTIDAD,...  las emociones dependen del grado de cantidad c...    es\n",
            "20969  No pare un segundo en todo el dia, todavia me ...  no pare un segundo en todo el dia todavia me f...    es\n",
            "20970             Dios tu tienes algo preparado para my♥              dios tu tienes algo preparado para my    es\n",
            "20971  si te haces el piercing en el labio y no te qu...  si te haces el piercing en el labio y no te qu...    es\n",
            "20972  Ahora en @AldeaLocalZte  hablamos de la creaci...  ahora en   hablamos de la creación de la parro...    es\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "26900  رییس فراکسیون زنان مجلس تلویحا به وجود حکم حکو...  رییس فراکسیون زنان مجلس تلویحا به وجود حکم حکو...    fa\n",
            "26901  افزایش ۲۰ درصدی شمار مبتلایان به ویروس ابولا د...  افزایش ۲۰ درصدی شمار مبتلایان به ویروس ابولا د...    fa\n",
            "26902  @farzi_mahdi @aydaezadi @mrdodel @pariart71 پر...                              پريسااا صداش در نمياد    fa\n",
            "26903  دانلود The Ministry of Silly Walks 1.0.3 بازی ...  دانلود the ministry of silly walks  بازی اکشن ...    fa\n",
            "26904                          @shavoor تلاش خودت رو بکن                                   تلاش خودت رو بکن    fa\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "26918  @HenriAlen Tosielämän välipalaa miehellä #kuit...     tosielämän välipalaa miehellä   terveellistä      fi\n",
            "26919  Miss märkäpaita #mattopesulla #suomalainentrad...                          miss märkäpaita   tämäkin    fi\n",
            "26920  @Mirppu outoo vaa kuvitella ku et käy enää bäk...        outoo vaa kuvitella ku et käy enää bäkkäril    fi\n",
            "26921  @anskiiuu Uskon! :D Mutt jokainen tsäänssi on ...   uskon d mutt jokainen tsäänssi on niille mahd...    fi\n",
            "26922  Jotenkin, ihan hitusen tosin, näyttäisi siltä,...  jotenkin ihan hitusen tosin näyttäisi siltä et...    fi\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "26933                @Alicia_Mammola jte comprend ahah 💕                                 jte comprend ahah     fr\n",
            "26934  Je suis sur qui y'as plus de prévente a Black ...  je suis sur qui yas plus de prévente a black top     fr\n",
            "26935  @luke5sos hey bb ça va tu t'amuse bien en boit...       hey bb ça va tu tamuse bien en boite de nuit    fr\n",
            "26936  J'ai hâte qu'elle regarde jusqu'au bout  Bon j...  jai hâte quelle regarde jusquau bout  bon je v...    fr\n",
            "26937  Oklmzer le taf, petit bureau avec double scree...  oklmzer le taf petit bureau avec double screen...    fr\n",
            "---\n",
            "                                                   tweet                                       tweet label\n",
            "27883                               איזה הרגשה מסריחה...                           איזה הרגשה מסריחה    he\n",
            "27884                                  אין היום משחקקק 😩                            אין היום משחקקק     he\n",
            "27885  @LDJ_France @Tsahal_IDF @JuifIsrael @Tsipora77...                    shabbat shalom umevorakh    he\n",
            "27886  “@ZoharHazani: “@AMITELIYAO: “@shiraz_nachmias...  “ “ “ חייבת ללכת לראות אשמת הכוכבים שוב”””    he\n",
            "27887                              @karin201020 נקווה של                                    נקווה של    he\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27910  किसे सुनाएँ अपने गम के चन्द पन्नो के किस्से, य...  किसे सुनाएँ अपने गम के चन्द पन्नो के किस्से यह...    hi\n",
            "27911  भोपाल-राज्यसभा सांसद अनिल दवे दिल्ली रवाना,एयर...  भोपालराज्यसभा सांसद अनिल दवे दिल्ली रवानाएयर इ...    hi\n",
            "27912  13/7 मुंबई धमाकों को लेकर आंतकी भटकल को कोई पछ...   मुंबई धमाकों को लेकर आंतकी भटकल को कोई पछतावा...    hi\n",
            "27913        @sagornoyon70 নেহি কার পাওগে ;) @ShManus786                                   নেহি কার পাওগে      hi\n",
            "27914  #RT #ipad #iphone इराक में अपने शिया भाइयों की...     इराक में अपने शिया भाइयों की मदद के लिए जान...    hi\n",
            "---\n",
            "                                                   tweet                                              tweet    label\n",
            "27926  rochi di kuch controversial hone pe apne aap o...  rochi di kuch controversial hone pe apne aap o...  hi-Latn\n",
            "27927  @Nilesh_Shah usse mil lijiye.. aapko b pta hai...   usse mil lijiye aapko b pta hai kiski baat kr...  hi-Latn\n",
            "27928    Yeh meri umar ne meri zindagi kharab kardi hai.     yeh meri umar ne meri zindagi kharab kardi hai  hi-Latn\n",
            "27929                                       Maa ki aankh                                       maa ki aankh  hi-Latn\n",
            "27930  mar jayiya tere bin  mar jayiya tere bin mar j...  mar jayiya tere bin  mar jayiya tere bin mar j...  hi-Latn\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27941       Aa izgrickala sam sve nokte do zivca,umireem        aa izgrickala sam sve nokte do zivcaumireem    hr\n",
            "27942                     jebote pa muskarci nose suknje                     jebote pa muskarci nose suknje    hr\n",
            "27943  majka kaze da kad bih pojela vola ne bi mi se ...  majka kaze da kad bih pojela vola ne bi mi se ...    hr\n",
            "27944                   O, zasto smo sada toliko daleko?                     o zasto smo sada toliko daleko    hr\n",
            "27945                   @mlccs1 kuku znam tog lika .....                                kuku znam tog lika     hr\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27946  Jan majorite moun ap viv Ayiti a RT @RomeroBou...  jan majorite moun ap viv ayiti a rt  kijan mou...    ht\n",
            "27947  Gwo vant pa alamod Ekri ou rele 37201033 mande...  gwo vant pa alamod ekri ou rele  mande pwodwi ...    ht\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27965          disaat kita terlalu bergantung kepada org          disaat kita terlalu bergantung kepada org    id\n",
            "27966  Klo udh gk syg mndng tnggln aja drpda kek gni ...  klo udh gk syg mndng tnggln aja drpda kek gni ...    id\n",
            "27967                  Orang benar akan hidup oleh iman.                   orang benar akan hidup oleh iman    id\n",
            "27968                           @LarasNiaty_ Iyy dong :)                                          iyy dong     id\n",
            "27969  Woiiii @kasyfanzulamia @Aulia_Javadd @NurAdhin...      woiiii    kalian harus ikut bukber kita wajib    id\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "30972  Ti svegli e improvvisamente #sixseasonsandamov...                     ti svegli e improvvisamente       it\n",
            "30973  Enzo Salvi - \"Va va va\" E chi non la canta VAVAVA     enzo salvi  va va va e chi non la canta vavava    it\n",
            "30974  Claudio Vismara più che ted di how i met your ...  claudio vismara più che ted di how i met your ...    it\n",
            "30975  Il viaggio in progressione di Arno Cost &amp; ...  il viaggio in progressione di arno cost  norma...    it\n",
            "30976  SEI UN BEL PORCO IO SONO UNA TROIA IN CALORE (...  sei un bel porco io sono una troia in calore t...    it\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "31311             @drm821 明日の本番、どうなっているか、ツイートにご期待ください…！！                     明日の本番、どうなっているか、ツイートにご期待ください…！！    ja\n",
            "31312      かなり雨降ってるけど晴れるのかしら・・・今日は出かけないからどっちでもいいけどちょっと寒い      かなり雨降ってるけど晴れるのかしら・・・今日は出かけないからどっちでもいいけどちょっと寒い    ja\n",
            "31313                              ガンシューティング歴はそろそろ10年になる                                ガンシューティング歴はそろそろ年になる    ja\n",
            "31314  2011 FIFA女子ワールドカップ　なでしこジャパン世界一 すぽレットキャンペーン-Mic...   fifa女子ワールドカップ　なでしこジャパン世界一 すぽレットキャンペーンmicrosof...    ja\n",
            "31315                                @s19_c88 つっちゃんおはよー。                                         つっちゃんおはよー。    ja\n",
            "---\n",
            "                                                   tweet                                              tweet    label\n",
            "41732  http://t.co/Ym4v14YvtE #Description kara-komik...    karakomikku yakinbyotou ni furuedisyonn opez...  ja_LATN\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "41733  @menarafmbali CemonkWyapeksa dinuskam slm buat...   cemonkwyapeksa dinuskam slm buat yogaalc jube...    jv\n",
            "41734        lek kadung gak mood langsung wegah lapo2 :3           lek kadung gak mood langsung wegah lapo     jv\n",
            "41735  @belgiis1 koe kui lo mbah seng tuwek.an -__- e...    koe kui lo mbah seng tuwekan  eling umur nggih     jv\n",
            "41736  makane maenke ki daendels haha RT @p_bayuprada...  makane maenke ki daendels haha rt  congratulat...    jv\n",
            "41737                    @akhyarnst rokok trossss hahaha                               rokok trossss hahaha    jv\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "41743  ញាំថ្នាំផ្តាសសាយខ្លាំពេកឡើងគេញលែងចង់ចង់ក្រោកហើ...    ញាំថ្នាំផ្តាសសាយខ្លាំពេកឡើងគេញលែងចង់ចង់ក្រោកហើយ    km\n",
            "41744  ស្ពានអាកាសស្ទឹងមានជ័យចាប់ដំណើរការពីថ្ងៃព្រហស្ប...  ស្ពានអាកាសស្ទឹងមានជ័យចាប់ដំណើរការពីថ្ងៃព្រហស្ប...    km\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "41745                   쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔                   쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔 쟈긔    ko\n",
            "41746                                 @sweetieYH 그니까ㅋㅋㅋㅋ                                            그니까ㅋㅋㅋㅋ    ko\n",
            "41747  ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ...  ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ...    ko\n",
            "41748                                     @hscha87 못난아..                                                못난아    ko\n",
            "41749  어제랑 똑같은 음악 똑같은 부분에서 컴이 멈추길래 혹시나 해서 시험해봤다 장미의 기...  어제랑 똑같은 음악 똑같은 부분에서 컴이 멈추길래 혹시나 해서 시험해봤다 장미의 기...    ko\n",
            "---\n",
            "                      tweet     tweet    label\n",
            "42203  @SL_kyuraw gomawoo:)   gomawoo  ko_LATN\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42204  Sed fugit interea,fugit irreparabile tempus, s...  sed fugit intereafugit irreparabile tempus sin...    ms\n",
            "42205  @iloveshf Aku tadi baru nampak dia! Senyum je ...   aku tadi baru nampak dia senyum je aku mampu ...    ms\n",
            "42206  @nazirulhaziqs: @ItsMymie_ haha. hzq rendah je...    haha hzq rendah je okay mcm budak darjah  ha...    ms\n",
            "42207                          Hati berasa dupan ye haha                          hati berasa dupan ye haha    ms\n",
            "42208  So tak boleh la beli jongkong emas simpan kat ...  so tak boleh la beli jongkong emas simpan kat ...    ms\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42328  Foeballuh! “@Spitstwit: Gamecolumn: Het is maa...  foeballuh “ gamecolumn het is maar een spellet...    nl\n",
            "42329                        Proefwerken gimgen best oké                        proefwerken gimgen best oké    nl\n",
            "42330  @ANWBverkeer dus via de A15 - A4 ?  Wellicht d...   dus via de a  a   wellicht dit te vermelden t...    nl\n",
            "42331  La Mer kiest voor Beautypartner als leverancie...  la mer kiest voor beautypartner als leverancie...    nl\n",
            "42332  Willem Drees had dat al snel door dat de socia...  willem drees had dat al snel door dat de socia...    nl\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42510  Nytt pris: E85: 8,88 B95: 14,25 Diesel: 14,02 ...                        nytt pris e  b  diesel         no\n",
            "42511  AUF vil la deler av kafébygget på Utøya bestå ...  auf vil la deler av kafébygget på utøya bestå ...    no\n",
            "42512  @Harryisthecraic kjæresten til søskenbarnet mi...   kjæresten til søskenbarnet mitt er her og fra...    no\n",
            "42513  @OpkvitneEaters Fifas disciplinary code er skr...   fifas disciplinary code er skrevet slik at ma...    no\n",
            "42514  Neymar av banen med Norges folkesykdom. Vondt ...  neymar av banen med norges folkesykdom vondt i...    no\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42521  Edward III nie mógł zostać... - http://t.co/ii...                       edward iii nie mógł zostać      pl\n",
            "42522  @perfctcalum właśnie sie skaplam ze ty mialam ...   właśnie sie skaplam ze ty mialam z tego ikonk...    pl\n",
            "42523             @mailencanossini: kolor frrrreza #lulu                                    kolor frrrreza     pl\n",
            "42524                    @zarrydiary ty mi nie odpisałas                                ty mi nie odpisałas    pl\n",
            "42525  @awhmyleigh Ale to przecież fair... Poza tym t...   ale to przecież fair poza tym to tylko na chw...    pl\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42616                                     meio estranho!                                      meio estranho    pt\n",
            "42617  Não se gostam?  Vai um pra cada lado e pronto ...  não se gostam  vai um pra cada lado e pronto p...    pt\n",
            "42618  Eu adoro ir às compras. Olha só o que eu compr...  eu adoro ir às compras olha só o que eu compre...    pt\n",
            "42619  @gruviquantica estas muito sofisticada esses ú...   estas muito sofisticada esses últimos dias amiga    pt\n",
            "42620                                    Boa noite ♥ ☺ '                                       boa noite       pt\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "45494                                           Revoltei                                           revoltei    ro\n",
            "45495  #Horizon2020 este cel mai amplu program de cer...   este cel mai amplu program de cercetare al ue...    ro\n",
            "45496  @ElenaRogoz Mda da! Acum o saptamana 0.0 sper ...   mda da acum o saptamana  sper ca macar incerc...    ro\n",
            "45497  ITI PERMITI acum sa-ti faci publicitate! 100 d...  iti permiti acum sati faci publicitate  de eur...    ro\n",
            "45498  Tracy Morgan, victimă a unui accident rutier c...  tracy morgan victimă a unui accident rutier ca...    ro\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "45506                    @egosh_69 в 6 утра?есть?ахахаха                                 в  утраестьахахаха    ru\n",
            "45507  Кинофильм собрал за время проката 230 984 145 ...  кинофильм собрал за время проката    руб на не...    ru\n",
            "45508  Притча о разводе | Свадебный коктейль http://t...             притча о разводе | свадебный коктейль     ru\n",
            "45509     Проекты домов из бревна http://t.co/nKtLxsiBhD                           проекты домов из бревна     ru\n",
            "45510         8-я серия 03.07.2014 смотреть онлайн - 2x2                        я серия  смотреть онлайн  x    ru\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46496            a boli uvo svajcarsku, puni su k'o brod              a boli uvo svajcarsku puni su ko brod    sr\n",
            "46497                            Prekini da mi se drkaš.                             prekini da mi se drkaš    sr\n",
            "46498  Nosim samo Nike, imam dijamantska pluca  ček s...  nosim samo nike imam dijamantska pluca  ček sa...    sr\n",
            "46499         ZAŠTO JE ENDRU SKOT GEJ, ZAŠTOOOOOOOOOOOOO          zašto je endru skot gej zaštooooooooooooo    sr\n",
            "46500  ĐOKOVIĆ: Teško bilo posle četvrtog seta | Srbi...  đoković teško bilo posle četvrtog seta | srbij...    sr\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46528  @Wilbacher På riktigt alltså. Du får 10% av in...         på riktigt alltså du får  av intäkterna ok    sv\n",
            "46529  Mora satsar för att vara med i kampen om SHL-p...  mora satsar för att vara med i kampen om shlpl...    sv\n",
            "46530  Vårt glamourösa backstageområde. Längst upp ti...  vårt glamourösa backstageområde längst upp til...    sv\n",
            "46531  @rudbergamanda nice! Vill fan också tillbaka r...    nice vill fan också tillbaka redan nu i sommar     sv\n",
            "46532  @Krakel_ @kringelkrokar  Ta tilllbaka Kentas l...            ta tilllbaka kentas låt från rasisterna    sv\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46582  LMFAOO RT \"@Limo_alan: \"@Emahnue: Ziko wapi iz...  lmfaoo rt limoalan emahnue ziko wapi izo scree...    sw\n",
            "46583  HATIMAYE MWISHO WA DUNIA UMEKARIBIA..!! FREEMA...  hatimaye mwisho wa dunia umekaribia freemason ...    sw\n",
            "46584                         @stevengitz nilipoteza cmu                                     nilipoteza cmu    sw\n",
            "46585  Liverpool yamsajili Markovic kwa £20m kuziba p...  liverpool yamsajili markovic kwa £m kuziba pengo     sw\n",
            "46586  KUELEKEA UCHAGUZI 2015:: VIJANA WAAMUA KUTANGA...  kuelekea uchaguzi  vijana waamua kutangaza nia...    sw\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46588  சார்.உங்க பழைய நாவலை எல்லாம் கிலோ 50 ரூபா க்கு...  சார்உங்க பழைய நாவலை எல்லாம் கிலோ  ரூபா க்கு வா...    ta\n",
            "46589                      @silvakaskas திருடா நான் ரெடி                                   திருடா நான் ரெடி    ta\n",
            "46590  MH17 :அதிர்ஷ்டவசமாக தப்பிய பிரிட்டன் தம்பதி ht...          mh அதிர்ஷ்டவசமாக தப்பிய பிரிட்டன் தம்பதி     ta\n",
            "46591  பார்வையற்ற குழந்தைகளை அடித்துத் துன்புறுத்திய ...  பார்வையற்ற குழந்தைகளை அடித்துத் துன்புறுத்திய ...    ta\n",
            "46592                         அஞ்சான் பாடல்கள் கிடைச்சதா                         அஞ்சான் பாடல்கள் கிடைச்சதா    ta\n",
            "---\n",
            "                          tweet            tweet    label\n",
            "46597  @bunbaby1 Vanakkam fakeu   vanakkam fakeu  ta_LATN\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46598      @BTSJK_97BOT @jungkook_fxxk พึ่งเลิกเรียน -.-                                     พึ่งเลิกเรียน     th\n",
            "46599             น้องต้วนกับแจ๊คสันและเจบีฮามาก ไอสาดดด             น้องต้วนกับแจ๊คสันและเจบีฮามาก ไอสาดดด    th\n",
            "46600  ทำไมกินกลูต้าแล้วไม่เหนผลซักที วันนี่มีคำตอบ h...      ทำไมกินกลูต้าแล้วไม่เหนผลซักที วันนี่มีคำตอบ     th\n",
            "46601  ลูกเหม็นนี่มันเหม็นสมชื่อจริงๆ ตอนนี้สับสนว่าก...  ลูกเหม็นนี่มันเหม็นสมชื่อจริงๆ ตอนนี้สับสนว่าก...    th\n",
            "46602                                    อยากหลับสัก10ปี                                      อยากหลับสักปี    th\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "47060  At least yung mukha ko d malala tulad ni Jayso...  at least yung mukha ko d malala tulad ni jayso...    tl\n",
            "47061           Yung mga nag uunfollow mga pa famous ./.              yung mga nag uunfollow mga pa famous     tl\n",
            "47062  @ALTHEADELATORRE Ayy. Di naman ganon yung akin...                      ayy di naman ganon yung akin     tl\n",
            "47063                  Yesss! Galing selos ako kuya! ./.                       yesss galing selos ako kuya     tl\n",
            "47064  @avegaille ah.. kala ko fan ka din ng f1. 😊 pa...   ah kala ko fan ka din ng f  para akong one of...    tl\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "47381  I'm at Avrupa Birliği Bakanlığı w/ 6 others ht...          im at avrupa birliği bakanlığı w  others     tr\n",
            "47382                    @ALKOLKAFAYAPAR ben uyumadım da                                    ben uyumadım da    tr\n",
            "47383                    cigjofte seven kizlar selam :dd                     cigjofte seven kizlar selam dd    tr\n",
            "47384  Dünya mazlumlarının umudu. Rabbim yolunu açık ...  dünya mazlumlarının umudu rabbim yolunu açık e...    tr\n",
            "47385  millet aşk derdine düşmüş biz burda iftar saat...  millet aşk derdine düşmüş biz burda iftar saat...    tr\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "48050  В Ужгороді священик затримав підозрілого «фото...  в ужгороді священик затримав підозрілого «фото...    uk\n",
            "48051  #фитнес #спорт #акции #fitness #lviv #lvov #Ль...  фитнес спорт акции    львов zumba на вул науко...    uk\n",
            "48052  @UKRINFORM @ukrpravda_news Хватить! Ми знаємо ...    хватить ми знаємо що вони стурбовані вже пів...    uk\n",
            "48053  Яценюк очікує, що за 10 років Україна буде пов...  яценюк очікує що за  років україна буде повніс...    uk\n",
            "48054  Волонтери передали на Донбас б�... http://t.co...                   волонтери передали на донбас б�     uk\n",
            "---\n",
            "                                                   tweet                  tweet label\n",
            "48066  “@NkealHarry15: Rasta E-Mann 😂😂😂 @EmannHamm_TY...       “ rasta emann      und\n",
            "48067                                 @MonaKazok  😂😂😂😂😂😂                          und\n",
            "48068                             #aliadosestasdemassss!                          und\n",
            "48069                                  Padahal wes onlen      padahal wes onlen   und\n",
            "48070                 #재효효진행쇼 #재효진행쇼 #안재효♡문효진 @blockbhyo  재효효진행쇼 재효진행쇼 안재효♡문효진    und\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "52603  برطانیہ: سیاہ فام بچے زیادہ فکرمند http://t.co...                 برطانیہ سیاہ فام بچے زیادہ فکرمند     ur\n",
            "52604  چھِن نہ جائے ترا تبسّمِ لب ،   میرے درد و الم ...  چھِن نہ جائے ترا تبسّمِ لب ،   میرے درد و الم ...    ur\n",
            "52605  @phanerozoic11 @dufferistan کس کے ساتھ کیا ہور...                            کس کے ساتھ کیا ہوریا؟      ur\n",
            "52606  جماعت احمدیہ کے بارے حقائق اور پاکستان کی موجو...  جماعت احمدیہ کے بارے حقائق اور پاکستان کی موجو...    ur\n",
            "52607  کچھ لوگ نماز پڑھتے ہیں ، روزہ رکھتے ہیں ہر وہ ...  کچھ لوگ نماز پڑھتے ہیں ، روزہ رکھتے ہیں ہر وہ ...    ur\n",
            "---\n",
            "                                                   tweet                                              tweet    label\n",
            "52610  Dawar-e-Hasaar Ne Ehy Keh Ky Mujhy Bakash Dia ...  dawarehasaar ne ehy keh ky mujhy bakash dia kh...  ur_LATN\n",
            "52611  @preeti_luvkcnwk wah wah sukriya aapka...iss s...   wah wah sukriya aapkaiss shandar swagat ke li...  ur_LATN\n",
            "52612  @Wiseguy70 @VneedChange @waqas_azeem_ch @AnamK...                            aik jadu ki jhapi do na  ur_LATN\n",
            "52613  Qur'an Mein Tajdeed Ka Tariqa http://t.co/z19N...             quran mein tajdeed ka tariqa            ur_LATN\n",
            "52614  @Nice_DuLHaN: Nahi Hum MOhtaaj Kisi Ke Ek Tere...   nahi hum mohtaaj kisi ke ek terey siwa yaa al...  ur_LATN\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "52622  MÙA HÈ 2014 Mùa hè đến là dịp để gia đình bạn ...  mùa hè  mùa hè đến là dịp để gia đình bạn tung...    vi\n",
            "52623  Tôi đã thích video http://t.co/dm62mcF9EU [Alo...  tôi đã thích video  alozovn ghế đưa đa năng sl...    vi\n",
            "52624  Lù hán à =)))))))))))))) lúc uống nc' đắng thì...  lù hán à  lúc uống nc đắng thì mặt nhăn còn  n...    vi\n",
            "52625  Khi một người quyết định IM LẶNG...  . Không p...  khi một người quyết định im lặng   không phải ...    vi\n",
            "52626                    ngày đẹp zời và rất buồn ngủ :(                      ngày đẹp zời và rất buồn ngủ     vi\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "52639  @SJLRadio1 @Umhlobo_Wenene @Maxhoseni @NonalaT...      n ndimpha zonke  ifani ingoma ezimnandi na...    xh\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet  label\n",
            "52640                        被肆意吹捧出来的“经典”作家，如：冰心，矛盾，郭沫若等                        被肆意吹捧出来的“经典”作家，如：冰心，矛盾，郭沫若等  zh-CN\n",
            "52641      一直让你流泪的条件再好也不能要，一直让你笑的，就算吃苦也值得。宁可笑着累，也不要哭着享受。      一直让你流泪的条件再好也不能要，一直让你笑的，就算吃苦也值得。宁可笑着累，也不要哭着享受。  zh-CN\n",
            "52642  热点文章：《《京城81号》吴镇宇特辑—在线播放—优酷网，视频高清在线观看》 http://t...        热点文章：《《京城号》吴镇宇特辑—在线播放—优酷网，视频高清在线观看》  原站链接：   zh-CN\n",
            "52643  我取得了一项新成就：`管理员`.尝试在iPad版Tribez游戏中打败我吧！http://t...              我取得了一项新成就：管理员尝试在ipad版tribez游戏中打败我吧！    zh-CN\n",
            "52644  真佛宗大马各分堂中元节法会活动，欢迎护持 !  农历七月的『中元節』即将到来。农历七月是佛教...  真佛宗大马各分堂中元节法会活动，欢迎护持   农历七月的『中元節』即将到来。农历七月是佛教的...  zh-CN\n",
            "---\n",
            "                                                   tweet                                              tweet  label\n",
            "52665   @EmmaKongms 所以我地要叫朋友來開account 先，緊急情況要識轉台睇Twitter               所以我地要叫朋友來開account 先，緊急情況要識轉台睇twitter  zh-TW\n",
            "52666  《音速經紀》於背地裡支援音速子 引導玩家的 “音樂女神”「繆斯」登場 http://t.co...                《音速經紀》於背地裡支援音速子 引導玩家的 “音樂女神”「繆斯」登場   zh-TW\n",
            "52667        大立光2450盤中新高 台股收漲9520 http://t.co/T1x9EhD7mi                                      大立光盤中新高 台股收漲   zh-TW\n",
            "52668                              @hundtw 不要眯啦 來喝一杯啦 #喂                                       不要眯啦 來喝一杯啦 喂  zh-TW\n",
            "52669  - 賀文p14 台灣訪問你地 其他成員話你係全隊最天不怕地不怕果陣 我林： 如果你去拍叢法 ...   賀文p 台灣訪問你地 其他成員話你係全隊最天不怕地不怕果陣 我林： 如果你去拍叢法 會唔會...  zh-TW\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht7tAk-r5Re8"
      },
      "source": [
        "cleaned_dataset = clean_data(dataset, TARGET_COLUMN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHvLCaLVJAoo",
        "outputId": "36bc6917-53d4-4c34-8212-c03d6ed22962"
      },
      "source": [
        "cleaned_dataset.isnull().values.any() # Dataset does not contain any rows with null values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go29EMqShzcu"
      },
      "source": [
        "### 4.Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8qkq-4MKosP"
      },
      "source": [
        "def back_translation(df,target_languages=['en']):\n",
        "  translated_data = pd.DataFrame(columns={TWEET_COLUMN, TARGET_COLUMN})\n",
        "  for target_language in target_languages:\n",
        "    for index, row in df.iterrows():\n",
        "      try:\n",
        "        tweet = row['tweet']\n",
        "        source_language = row['label']\n",
        "        translated_data=translated_data.append({'tweet': translator.translate(translator.translate(tweet, dest=target_language).text, dest=source_language).text, 'label': source_language}, ignore_index=True)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "  return translated_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iev8EdrRQG2",
        "outputId": "4e74d850-b63e-4ce5-fa9c-f2ebf3a0b405"
      },
      "source": [
        "print_number_of_underrepresented_languages(cleaned_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 50 languages in this data set with less then 20 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPZhejNxdCFn",
        "outputId": "517114ac-460c-4576-d29c-12b6ad10c5d0"
      },
      "source": [
        "underrepresented_languages = get_underrepresented_languages(cleaned_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arlatn', 'az', 'bg', 'bn', 'bs', 'cs', 'cy', 'da', 'dv', 'et', 'eu', 'gl', 'ha', 'hilatn', 'hr', 'ht', 'hu', 'hy', 'is', 'jalatn', 'jv', 'km', 'kolatn', 'la', 'lv', 'mk', 'mn', 'mr', 'ne', 'no', 'ps', 'pslatn', 'ro', 'si', 'sk', 'sl', 'sq', 'su', 'sw', 'ta', 'talatn', 'tn', 'uk', 'ur', 'urlatn', 'wo', 'xh', 'yo', 'zhtw', 'zu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amnYMOOJ1xRA",
        "outputId": "fb54837c-ace7-4e0b-c5ea-068d3aa4a5b8"
      },
      "source": [
        "upsampled_dataset = cleaned_dataset.copy()\n",
        "for l in underrepresented_languages:\n",
        "  if not l.endswith('latn'): \n",
        "    continue #skip latn languages because they dont work with back translation\n",
        "  underrepresented_language = upsampled_dataset[upsampled_dataset[TARGET_COLUMN]==l]\n",
        "  upsampled_dataset.drop(upsampled_dataset[upsampled_dataset[TARGET_COLUMN]==l].index, inplace = True, axis=0)\n",
        "  len_first = len(underrepresented_language)\n",
        "  if not l.endswith('latn'): #skip latn languages because they dont work with back translation\n",
        "    underrepresented_language = pd.concat([underrepresented_language, back_translation(underrepresented_language)], axis=0)\n",
        "  len_second = len(underrepresented_language)\n",
        "  if(len_second < SAMPLE_THRESHOLD):\n",
        "    underrepresented_language = resample(underrepresented_language, n_samples=SAMPLE_THRESHOLD)\n",
        "  len_third = len(underrepresented_language)\n",
        "  print(\"({0}): #{1}=>back_translation=>#{2}=>resampling=>#{3}\".format(l, len_first, len_second, len_third))\n",
        "  upsampled_dataset = pd.concat([upsampled_dataset, underrepresented_language], axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arlatn\n",
            "az\n",
            "(az): #3=>back_translation=>#6=>resampling=>#20\n",
            "bg\n",
            "(bg): #4=>back_translation=>#8=>resampling=>#20\n",
            "bn\n",
            "(bn): #8=>back_translation=>#16=>resampling=>#20\n",
            "bs\n",
            "(bs): #5=>back_translation=>#10=>resampling=>#20\n",
            "cs\n",
            "(cs): #5=>back_translation=>#10=>resampling=>#20\n",
            "cy\n",
            "(cy): #1=>back_translation=>#2=>resampling=>#20\n",
            "da\n",
            "(da): #8=>back_translation=>#16=>resampling=>#20\n",
            "dv\n",
            "invalid destination language\n",
            "(dv): #1=>back_translation=>#1=>resampling=>#20\n",
            "et\n",
            "(et): #2=>back_translation=>#4=>resampling=>#20\n",
            "eu\n",
            "(eu): #2=>back_translation=>#4=>resampling=>#20\n",
            "gl\n",
            "(gl): #3=>back_translation=>#6=>resampling=>#20\n",
            "ha\n",
            "(ha): #1=>back_translation=>#2=>resampling=>#20\n",
            "hilatn\n",
            "hr\n",
            "(hr): #6=>back_translation=>#12=>resampling=>#20\n",
            "ht\n",
            "(ht): #3=>back_translation=>#6=>resampling=>#20\n",
            "hu\n",
            "(hu): #15=>back_translation=>#30=>resampling=>#30\n",
            "hy\n",
            "(hy): #2=>back_translation=>#4=>resampling=>#20\n",
            "is\n",
            "(is): #1=>back_translation=>#2=>resampling=>#20\n",
            "jalatn\n",
            "jv\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "(jv): #11=>back_translation=>#11=>resampling=>#20\n",
            "km\n",
            "(km): #3=>back_translation=>#6=>resampling=>#20\n",
            "kolatn\n",
            "la\n",
            "(la): #1=>back_translation=>#2=>resampling=>#20\n",
            "lv\n",
            "(lv): #5=>back_translation=>#10=>resampling=>#20\n",
            "mk\n",
            "(mk): #1=>back_translation=>#2=>resampling=>#20\n",
            "mn\n",
            "(mn): #1=>back_translation=>#2=>resampling=>#20\n",
            "mr\n",
            "(mr): #1=>back_translation=>#2=>resampling=>#20\n",
            "ne\n",
            "(ne): #5=>back_translation=>#10=>resampling=>#20\n",
            "no\n",
            "(no): #12=>back_translation=>#24=>resampling=>#24\n",
            "ps\n",
            "(ps): #1=>back_translation=>#2=>resampling=>#20\n",
            "pslatn\n",
            "ro\n",
            "(ro): #14=>back_translation=>#28=>resampling=>#28\n",
            "si\n",
            "(si): #1=>back_translation=>#2=>resampling=>#20\n",
            "sk\n",
            "(sk): #1=>back_translation=>#2=>resampling=>#20\n",
            "sl\n",
            "(sl): #2=>back_translation=>#4=>resampling=>#20\n",
            "sq\n",
            "(sq): #9=>back_translation=>#18=>resampling=>#20\n",
            "su\n",
            "(su): #10=>back_translation=>#20=>resampling=>#20\n",
            "sw\n",
            "(sw): #8=>back_translation=>#16=>resampling=>#20\n",
            "ta\n",
            "(ta): #12=>back_translation=>#24=>resampling=>#24\n",
            "talatn\n",
            "tn\n",
            "invalid destination language\n",
            "(tn): #1=>back_translation=>#1=>resampling=>#20\n",
            "uk\n",
            "(uk): #18=>back_translation=>#36=>resampling=>#36\n",
            "ur\n",
            "(ur): #12=>back_translation=>#24=>resampling=>#24\n",
            "urlatn\n",
            "wo\n",
            "invalid destination language\n",
            "(wo): #1=>back_translation=>#1=>resampling=>#20\n",
            "xh\n",
            "(xh): #2=>back_translation=>#4=>resampling=>#20\n",
            "yo\n",
            "(yo): #1=>back_translation=>#2=>resampling=>#20\n",
            "zhtw\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "(zhtw): #14=>back_translation=>#14=>resampling=>#20\n",
            "zu\n",
            "(zu): #1=>back_translation=>#2=>resampling=>#20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "mM5NKgHNjdKp",
        "outputId": "5870b01d-3f7f-4bbd-c036-d9778201102e"
      },
      "source": [
        "upsampled_dataset.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anyone goin to the rope swing?</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No fue fácil pero valió la pena.</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jochortega es plaga el lala jajajaja</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>特進の校舎のトイレはウォシュレットがついていて羨ましい</td>\n",
              "      <td>ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>두 눈을 감은 이유가, 누구때문도 아니기를...</td>\n",
              "      <td>ko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67637</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67638</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67639</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67640</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67641</th>\n",
              "      <td>@ Official_SABC1 Molooo nawe !!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67642 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet label\n",
              "0             Anyone goin to the rope swing?    en\n",
              "1           No fue fácil pero valió la pena.    es\n",
              "2      @jochortega es plaga el lala jajajaja    es\n",
              "3                特進の校舎のトイレはウォシュレットがついていて羨ましい    ja\n",
              "4                 두 눈을 감은 이유가, 누구때문도 아니기를...    ko\n",
              "...                                      ...   ...\n",
              "67637      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67638      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67639      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67640      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67641       @ Official_SABC1 Molooo nawe !!!    zu\n",
              "\n",
              "[67642 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR2fpoJ3iyN3"
      },
      "source": [
        "upsampled_dataset.to_pickle('./dataset.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc9DsPayjCU9"
      },
      "source": [
        "upsampled_dataset.to_csv('./dataset.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPZANQdPhavy",
        "outputId": "a7f39c69-f658-4dae-cde9-fc122fb9b9c0"
      },
      "source": [
        "get_underrepresented_languages(upsampled_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaFPH8EA2CdR",
        "outputId": "e0456aa5-ee18-4b1b-e7f6-b9f0d0c2b4dd"
      },
      "source": [
        "print_number_of_underrepresented_languages(upsampled_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 languages in this data set with less then 20 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCXkJaGzhJB7"
      },
      "source": [
        "#for l in underrepresented_languages:\n",
        "#  underrepresented_language = upsampled_dataset[upsampled_dataset[TARGET_COLUMN]==l]\n",
        "#  underrepresented_language = resample(underrepresented_language, n_samples=SAMPLE_THRESHOLD)\n",
        "#  upsampled_dataset = pd.concat([upsampled_dataset, underrepresented_language], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvvbKuzu-3XL",
        "outputId": "93cb3db1-4650-44b0-f499-424818244b9a"
      },
      "source": [
        "print(\"The length of the upsampled dataset is {}\".format(len(upsampled_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the upsampled dataset is 67642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMTSM4istMQw"
      },
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oyQ6eZbCeUX"
      },
      "source": [
        "TARGET_COLUMN = 'label'\n",
        "TWEET_COLUMN = 'tweet'\n",
        "dataset=upsampled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNPDezQCVpH"
      },
      "source": [
        "X = dataset[TWEET_COLUMN]\n",
        "y = dataset[TARGET_COLUMN]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIWW6ZqKPKH"
      },
      "source": [
        "# Vectorize with ngram_range 1 to 3\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7udC4tUb3v",
        "outputId": "c78a5a4c-073b-47df-a01b-0b66e5986383"
      },
      "source": [
        "print(type(X_train_vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UfmSwvltMRQ"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zdPLMHJ2AV"
      },
      "source": [
        "# All parameters we are individually testing\n",
        "# If the computational power would be high enough we could\n",
        "# use GridSearchCV to easily find the best hyperparameters\n",
        "# However running this grid search CV exceeds colabs max runtime.\n",
        "parameters = {\n",
        "        'hidden_layer_sizes': [100, 500],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'activation': ['tanh', 'relu'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nb7mqEL9Ve"
      },
      "source": [
        "\n",
        "## hidden_layer_sizes=(100): configuration 1-4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUP9_D47N0Ed"
      },
      "source": [
        "### Configuration 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gq1DtZktMRR",
        "outputId": "5725af1c-99c0-4448-ab2c-d9513731d892"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.35136123\n",
            "Validation score: 0.864488\n",
            "Iteration 2, loss = 0.38750770\n",
            "Validation score: 0.898160\n",
            "Iteration 3, loss = 0.20907587\n",
            "Validation score: 0.912779\n",
            "Iteration 4, loss = 0.12316765\n",
            "Validation score: 0.914586\n",
            "Iteration 5, loss = 0.07781613\n",
            "Validation score: 0.918857\n",
            "Iteration 6, loss = 0.05258100\n",
            "Validation score: 0.919021\n",
            "Iteration 7, loss = 0.03794585\n",
            "Validation score: 0.919678\n",
            "Iteration 8, loss = 0.02905713\n",
            "Validation score: 0.919021\n",
            "Iteration 9, loss = 0.02351217\n",
            "Validation score: 0.918693\n",
            "Iteration 10, loss = 0.01983701\n",
            "Validation score: 0.916064\n",
            "Iteration 11, loss = 0.01737863\n",
            "Validation score: 0.917050\n",
            "Iteration 12, loss = 0.01551853\n",
            "Validation score: 0.917050\n",
            "Iteration 13, loss = 0.01421724\n",
            "Validation score: 0.915243\n",
            "Iteration 14, loss = 0.01312494\n",
            "Validation score: 0.915079\n",
            "Iteration 15, loss = 0.01225299\n",
            "Validation score: 0.914586\n",
            "Iteration 16, loss = 0.01154947\n",
            "Validation score: 0.914750\n",
            "Iteration 17, loss = 0.01087968\n",
            "Validation score: 0.915900\n",
            "Iteration 18, loss = 0.01028974\n",
            "Validation score: 0.914093\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuUJKblKM87g",
        "outputId": "efa08744-19cf-4021-9344-d187559aa5ba"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.98      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.79      0.88        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.97      0.95      2357\n",
            "          es       0.92      0.95      0.93       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.60      0.75         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.87      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.67      0.79        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.83      0.90        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.75      0.18      0.29        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.86      0.82      0.84        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.86      0.67      0.75         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.92      0.93       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.67      0.80         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.83      0.69      0.75        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.94      0.85      0.89        74\n",
            "          uk       1.00      0.80      0.89         5\n",
            "         und       0.66      0.66      0.66       595\n",
            "          ur       1.00      1.00      1.00         3\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.85      0.88      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk380eGhN-IF"
      },
      "source": [
        "### Configuration 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4aSvJzFN-IG",
        "outputId": "b0f4e5b8-b025-4eb2-edb9-a805c8db442c"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.44080992\n",
            "Validation score: 0.869087\n",
            "Iteration 2, loss = 0.40336973\n",
            "Validation score: 0.904895\n",
            "Iteration 3, loss = 0.22184401\n",
            "Validation score: 0.920828\n",
            "Iteration 4, loss = 0.13248716\n",
            "Validation score: 0.926248\n",
            "Iteration 5, loss = 0.08481837\n",
            "Validation score: 0.926577\n",
            "Iteration 6, loss = 0.05784939\n",
            "Validation score: 0.926413\n",
            "Iteration 7, loss = 0.04195377\n",
            "Validation score: 0.926248\n",
            "Iteration 8, loss = 0.03211862\n",
            "Validation score: 0.927070\n",
            "Iteration 9, loss = 0.02582995\n",
            "Validation score: 0.925756\n",
            "Iteration 10, loss = 0.02167531\n",
            "Validation score: 0.924606\n",
            "Iteration 11, loss = 0.01884304\n",
            "Validation score: 0.925099\n",
            "Iteration 12, loss = 0.01690268\n",
            "Validation score: 0.924770\n",
            "Iteration 13, loss = 0.01537346\n",
            "Validation score: 0.924606\n",
            "Iteration 14, loss = 0.01423894\n",
            "Validation score: 0.924606\n",
            "Iteration 15, loss = 0.01328507\n",
            "Validation score: 0.924934\n",
            "Iteration 16, loss = 0.01248132\n",
            "Validation score: 0.924934\n",
            "Iteration 17, loss = 0.01183086\n",
            "Validation score: 0.923784\n",
            "Iteration 18, loss = 0.01130216\n",
            "Validation score: 0.925263\n",
            "Iteration 19, loss = 0.01067333\n",
            "Validation score: 0.924606\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kBnRu9BOU9G",
        "outputId": "992b091f-6b79-4300-a70c-57ec513104a6"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.97      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.82      0.90        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.96      0.95      2357\n",
            "          es       0.92      0.95      0.94       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.80      0.89         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.88      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.64      0.77        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.81      0.89        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.62      0.29      0.40        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.83      0.68      0.75        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.83      0.56      0.67         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.91      0.92       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.50      0.67         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.81      0.71      0.76        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.96      0.86      0.91        74\n",
            "          uk       1.00      1.00      1.00         5\n",
            "         und       0.66      0.68      0.67       595\n",
            "          ur       1.00      0.67      0.80         3\n",
            "      urlatn       1.00      1.00      1.00         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.86      0.89      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mkAJzofOEq2"
      },
      "source": [
        "### Configuration 03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uFzCjU5OEq3",
        "outputId": "bafb7a36-7fdb-49f0-e450-26b7e3f79225"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.83790675\n",
            "Validation score: 0.346091\n",
            "Iteration 2, loss = 2.80005137\n",
            "Validation score: 0.346091\n",
            "Iteration 3, loss = 2.43424634\n",
            "Validation score: 0.346091\n",
            "Iteration 4, loss = 2.29328226\n",
            "Validation score: 0.346091\n",
            "Iteration 5, loss = 2.21992028\n",
            "Validation score: 0.346091\n",
            "Iteration 6, loss = 2.16930773\n",
            "Validation score: 0.366130\n",
            "Iteration 7, loss = 2.12569797\n",
            "Validation score: 0.480289\n",
            "Iteration 8, loss = 2.08346862\n",
            "Validation score: 0.515769\n",
            "Iteration 9, loss = 2.04120553\n",
            "Validation score: 0.526938\n",
            "Iteration 10, loss = 1.99883010\n",
            "Validation score: 0.530388\n",
            "Iteration 11, loss = 1.95691272\n",
            "Validation score: 0.529074\n",
            "Iteration 12, loss = 1.91601130\n",
            "Validation score: 0.528581\n",
            "Iteration 13, loss = 1.87660695\n",
            "Validation score: 0.527431\n",
            "Iteration 14, loss = 1.83893518\n",
            "Validation score: 0.527102\n",
            "Iteration 15, loss = 1.80301735\n",
            "Validation score: 0.527102\n",
            "Iteration 16, loss = 1.76876771\n",
            "Validation score: 0.525953\n",
            "Iteration 17, loss = 1.73596789\n",
            "Validation score: 0.527267\n",
            "Iteration 18, loss = 1.70438489\n",
            "Validation score: 0.529895\n",
            "Iteration 19, loss = 1.67385303\n",
            "Validation score: 0.537451\n",
            "Iteration 20, loss = 1.64443073\n",
            "Validation score: 0.543857\n",
            "Iteration 21, loss = 1.61577152\n",
            "Validation score: 0.553548\n",
            "Iteration 22, loss = 1.58799018\n",
            "Validation score: 0.568495\n",
            "Iteration 23, loss = 1.56103380\n",
            "Validation score: 0.580979\n",
            "Iteration 24, loss = 1.53489508\n",
            "Validation score: 0.597076\n",
            "Iteration 25, loss = 1.50966422\n",
            "Validation score: 0.606110\n",
            "Iteration 26, loss = 1.48528117\n",
            "Validation score: 0.616787\n",
            "Iteration 27, loss = 1.46186302\n",
            "Validation score: 0.624507\n",
            "Iteration 28, loss = 1.43935293\n",
            "Validation score: 0.632227\n",
            "Iteration 29, loss = 1.41783294\n",
            "Validation score: 0.637484\n",
            "Iteration 30, loss = 1.39721355\n",
            "Validation score: 0.642083\n",
            "Iteration 31, loss = 1.37756498\n",
            "Validation score: 0.647339\n",
            "Iteration 32, loss = 1.35879851\n",
            "Validation score: 0.650953\n",
            "Iteration 33, loss = 1.34093833\n",
            "Validation score: 0.655716\n",
            "Iteration 34, loss = 1.32392275\n",
            "Validation score: 0.659987\n",
            "Iteration 35, loss = 1.30766425\n",
            "Validation score: 0.661137\n",
            "Iteration 36, loss = 1.29219057\n",
            "Validation score: 0.671485\n",
            "Iteration 37, loss = 1.27740079\n",
            "Validation score: 0.676413\n",
            "Iteration 38, loss = 1.26325136\n",
            "Validation score: 0.680519\n",
            "Iteration 39, loss = 1.24975294\n",
            "Validation score: 0.685283\n",
            "Iteration 40, loss = 1.23678184\n",
            "Validation score: 0.688732\n",
            "Iteration 41, loss = 1.22434442\n",
            "Validation score: 0.693988\n",
            "Iteration 42, loss = 1.21235271\n",
            "Validation score: 0.698095\n",
            "Iteration 43, loss = 1.20080773\n",
            "Validation score: 0.701544\n",
            "Iteration 44, loss = 1.18971234\n",
            "Validation score: 0.706472\n",
            "Iteration 45, loss = 1.17896182\n",
            "Validation score: 0.710414\n",
            "Iteration 46, loss = 1.16858059\n",
            "Validation score: 0.712385\n",
            "Iteration 47, loss = 1.15852927\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.14877519\n",
            "Validation score: 0.719284\n",
            "Iteration 49, loss = 1.13932871\n",
            "Validation score: 0.720762\n",
            "Iteration 50, loss = 1.13012600\n",
            "Validation score: 0.724869\n",
            "Iteration 51, loss = 1.12123430\n",
            "Validation score: 0.727497\n",
            "Iteration 52, loss = 1.11251944\n",
            "Validation score: 0.727661\n",
            "Iteration 53, loss = 1.10406905\n",
            "Validation score: 0.729632\n",
            "Iteration 54, loss = 1.09586074\n",
            "Validation score: 0.734888\n",
            "Iteration 55, loss = 1.08782374\n",
            "Validation score: 0.735381\n",
            "Iteration 56, loss = 1.08001231\n",
            "Validation score: 0.738502\n",
            "Iteration 57, loss = 1.07240383\n",
            "Validation score: 0.741459\n",
            "Iteration 58, loss = 1.06496062\n",
            "Validation score: 0.743922\n",
            "Iteration 59, loss = 1.05770561\n",
            "Validation score: 0.745237\n",
            "Iteration 60, loss = 1.05062061\n",
            "Validation score: 0.747208\n",
            "Iteration 61, loss = 1.04374049\n",
            "Validation score: 0.747700\n",
            "Iteration 62, loss = 1.03699385\n",
            "Validation score: 0.750657\n",
            "Iteration 63, loss = 1.03038835\n",
            "Validation score: 0.752792\n",
            "Iteration 64, loss = 1.02396438\n",
            "Validation score: 0.753942\n",
            "Iteration 65, loss = 1.01769635\n",
            "Validation score: 0.755420\n",
            "Iteration 66, loss = 1.01154920\n",
            "Validation score: 0.757556\n",
            "Iteration 67, loss = 1.00555981\n",
            "Validation score: 0.758049\n",
            "Iteration 68, loss = 0.99966179\n",
            "Validation score: 0.759198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urcbii6kigaj",
        "outputId": "8efcb260-7c07-4d1a-8df8-df0a6eef20e4"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.97      0.95      0.96       274\n",
            "      arlatn       0.00      0.00      0.00         5\n",
            "          az       0.00      0.00      0.00         5\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         2\n",
            "          bs       0.00      0.00      0.00         5\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         1\n",
            "          de       0.00      0.00      0.00        19\n",
            "          dv       0.00      0.00      0.00         2\n",
            "          el       0.00      0.00      0.00         1\n",
            "          en       0.84      0.97      0.90      2355\n",
            "          es       0.67      0.90      0.77       763\n",
            "          et       0.00      0.00      0.00         4\n",
            "          eu       0.00      0.00      0.00         5\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.00      0.00      0.00       103\n",
            "          gl       0.00      0.00      0.00         2\n",
            "          ha       0.00      0.00      0.00         4\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         1\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         8\n",
            "          ht       0.00      0.00      0.00         2\n",
            "          hu       0.00      0.00      0.00         5\n",
            "          hy       0.00      0.00      0.00         6\n",
            "          id       0.64      0.80      0.71       362\n",
            "          is       0.00      0.00      0.00         3\n",
            "          it       0.00      0.00      0.00        35\n",
            "          ja       0.87      0.97      0.91      1295\n",
            "      jalatn       0.00      0.00      0.00         2\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         3\n",
            "          ko       0.00      0.00      0.00        53\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         6\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         6\n",
            "          mr       0.00      0.00      0.00         6\n",
            "          ms       0.00      0.00      0.00         9\n",
            "          ne       0.00      0.00      0.00         8\n",
            "          nl       0.00      0.00      0.00        30\n",
            "          no       0.00      0.00      0.00         2\n",
            "          pl       0.00      0.00      0.00        10\n",
            "          ps       0.00      0.00      0.00         4\n",
            "      pslatn       0.00      0.00      0.00         1\n",
            "          pt       0.93      0.19      0.31       349\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.88      0.79      0.83       124\n",
            "          si       0.00      0.00      0.00         6\n",
            "          sk       0.00      0.00      0.00         5\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         2\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       0.00      0.00      0.00         7\n",
            "          sv       0.00      0.00      0.00        10\n",
            "          sw       0.00      0.00      0.00         3\n",
            "          ta       0.00      0.00      0.00         3\n",
            "      talatn       0.00      0.00      0.00         2\n",
            "          th       0.00      0.00      0.00        65\n",
            "          tl       0.00      0.00      0.00        55\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        80\n",
            "          uk       0.00      0.00      0.00         8\n",
            "         und       0.41      0.50      0.45       548\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         2\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         6\n",
            "          xh       0.00      0.00      0.00         5\n",
            "          yo       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         5\n",
            "          zu       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.77      6765\n",
            "   macro avg       0.08      0.08      0.08      6765\n",
            "weighted avg       0.71      0.77      0.72      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy8NGueVOM5q"
      },
      "source": [
        "### Configuration 04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjKjeyXXOM5q",
        "outputId": "e6199608-83bc-4acf-d177-e209b2330308"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 4.02919301\n",
            "Validation score: 0.346748\n",
            "Iteration 2, loss = 3.14377492\n",
            "Validation score: 0.346748\n",
            "Iteration 3, loss = 2.56392484\n",
            "Validation score: 0.346748\n",
            "Iteration 4, loss = 2.35278089\n",
            "Validation score: 0.346748\n",
            "Iteration 5, loss = 2.26528485\n",
            "Validation score: 0.346748\n",
            "Iteration 6, loss = 2.21389089\n",
            "Validation score: 0.346748\n",
            "Iteration 7, loss = 2.17213758\n",
            "Validation score: 0.348883\n",
            "Iteration 8, loss = 2.13207392\n",
            "Validation score: 0.453515\n",
            "Iteration 9, loss = 2.09104169\n",
            "Validation score: 0.498357\n",
            "Iteration 10, loss = 2.04880234\n",
            "Validation score: 0.517247\n",
            "Iteration 11, loss = 2.00590778\n",
            "Validation score: 0.521189\n",
            "Iteration 12, loss = 1.96306010\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.92126695\n",
            "Validation score: 0.519054\n",
            "Iteration 14, loss = 1.88095186\n",
            "Validation score: 0.518397\n",
            "Iteration 15, loss = 1.84241353\n",
            "Validation score: 0.518233\n",
            "Iteration 16, loss = 1.80577731\n",
            "Validation score: 0.518068\n",
            "Iteration 17, loss = 1.77081258\n",
            "Validation score: 0.519218\n",
            "Iteration 18, loss = 1.73745917\n",
            "Validation score: 0.521189\n",
            "Iteration 19, loss = 1.70540344\n",
            "Validation score: 0.524967\n",
            "Iteration 20, loss = 1.67455771\n",
            "Validation score: 0.529566\n",
            "Iteration 21, loss = 1.64467251\n",
            "Validation score: 0.538601\n",
            "Iteration 22, loss = 1.61578854\n",
            "Validation score: 0.550099\n",
            "Iteration 23, loss = 1.58778501\n",
            "Validation score: 0.558804\n",
            "Iteration 24, loss = 1.56064452\n",
            "Validation score: 0.571124\n",
            "Iteration 25, loss = 1.53443847\n",
            "Validation score: 0.584264\n",
            "Iteration 26, loss = 1.50906186\n",
            "Validation score: 0.594941\n",
            "Iteration 27, loss = 1.48475539\n",
            "Validation score: 0.605289\n",
            "Iteration 28, loss = 1.46135115\n",
            "Validation score: 0.611695\n",
            "Iteration 29, loss = 1.43899993\n",
            "Validation score: 0.618594\n",
            "Iteration 30, loss = 1.41752904\n",
            "Validation score: 0.626807\n",
            "Iteration 31, loss = 1.39710464\n",
            "Validation score: 0.631735\n",
            "Iteration 32, loss = 1.37756625\n",
            "Validation score: 0.636827\n",
            "Iteration 33, loss = 1.35896542\n",
            "Validation score: 0.642904\n",
            "Iteration 34, loss = 1.34125814\n",
            "Validation score: 0.645696\n",
            "Iteration 35, loss = 1.32439846\n",
            "Validation score: 0.650460\n",
            "Iteration 36, loss = 1.30829094\n",
            "Validation score: 0.659001\n",
            "Iteration 37, loss = 1.29297601\n",
            "Validation score: 0.661794\n",
            "Iteration 38, loss = 1.27836837\n",
            "Validation score: 0.667871\n",
            "Iteration 39, loss = 1.26436781\n",
            "Validation score: 0.675920\n",
            "Iteration 40, loss = 1.25107209\n",
            "Validation score: 0.679698\n",
            "Iteration 41, loss = 1.23827764\n",
            "Validation score: 0.688239\n",
            "Iteration 42, loss = 1.22597316\n",
            "Validation score: 0.688568\n",
            "Iteration 43, loss = 1.21421455\n",
            "Validation score: 0.694809\n",
            "Iteration 44, loss = 1.20288021\n",
            "Validation score: 0.698259\n",
            "Iteration 45, loss = 1.19193738\n",
            "Validation score: 0.702037\n",
            "Iteration 46, loss = 1.18138379\n",
            "Validation score: 0.704172\n",
            "Iteration 47, loss = 1.17118849\n",
            "Validation score: 0.705979\n",
            "Iteration 48, loss = 1.16128318\n",
            "Validation score: 0.707786\n",
            "Iteration 49, loss = 1.15168758\n",
            "Validation score: 0.711235\n",
            "Iteration 50, loss = 1.14240475\n",
            "Validation score: 0.715177\n",
            "Iteration 51, loss = 1.13339869\n",
            "Validation score: 0.717477\n",
            "Iteration 52, loss = 1.12461737\n",
            "Validation score: 0.719777\n",
            "Iteration 53, loss = 1.11607600\n",
            "Validation score: 0.721255\n",
            "Iteration 54, loss = 1.10778021\n",
            "Validation score: 0.721912\n",
            "Iteration 55, loss = 1.09968494\n",
            "Validation score: 0.723883\n",
            "Iteration 56, loss = 1.09184158\n",
            "Validation score: 0.724540\n",
            "Iteration 57, loss = 1.08415567\n",
            "Validation score: 0.725690\n",
            "Iteration 58, loss = 1.07666505\n",
            "Validation score: 0.726511\n",
            "Iteration 59, loss = 1.06933136\n",
            "Validation score: 0.729304\n",
            "Iteration 60, loss = 1.06219828\n",
            "Validation score: 0.730453\n",
            "Iteration 61, loss = 1.05522855\n",
            "Validation score: 0.733903\n",
            "Iteration 62, loss = 1.04841870\n",
            "Validation score: 0.735381\n",
            "Iteration 63, loss = 1.04176983\n",
            "Validation score: 0.736859\n",
            "Iteration 64, loss = 1.03526080\n",
            "Validation score: 0.739159\n",
            "Iteration 65, loss = 1.02889163\n",
            "Validation score: 0.742444\n",
            "Iteration 66, loss = 1.02266797\n",
            "Validation score: 0.742773\n",
            "Iteration 67, loss = 1.01659430\n",
            "Validation score: 0.744251\n",
            "Iteration 68, loss = 1.01062949\n",
            "Validation score: 0.746879\n",
            "Iteration 69, loss = 1.00481937\n",
            "Validation score: 0.747865\n",
            "Iteration 70, loss = 0.99912205\n",
            "Validation score: 0.749671\n",
            "Iteration 71, loss = 0.99351362\n",
            "Validation score: 0.752464\n",
            "Iteration 72, loss = 0.98807280\n",
            "Validation score: 0.753614\n",
            "Iteration 73, loss = 0.98268432\n",
            "Validation score: 0.754271\n",
            "Iteration 74, loss = 0.97745743\n",
            "Validation score: 0.754763\n",
            "Iteration 75, loss = 0.97233744\n",
            "Validation score: 0.758870\n",
            "Iteration 76, loss = 0.96729777\n",
            "Validation score: 0.758870\n",
            "Iteration 77, loss = 0.96234634\n",
            "Validation score: 0.762319\n",
            "Iteration 78, loss = 0.95747945\n",
            "Validation score: 0.764619\n",
            "Iteration 79, loss = 0.95276842\n",
            "Validation score: 0.767904\n",
            "Iteration 80, loss = 0.94808632\n",
            "Validation score: 0.767740\n",
            "Iteration 81, loss = 0.94347783\n",
            "Validation score: 0.768561\n",
            "Iteration 82, loss = 0.93896076\n",
            "Validation score: 0.770696\n",
            "Iteration 83, loss = 0.93461697\n",
            "Validation score: 0.773489\n",
            "Iteration 84, loss = 0.93024661\n",
            "Validation score: 0.773653\n",
            "Iteration 85, loss = 0.92596250\n",
            "Validation score: 0.775460\n",
            "Iteration 86, loss = 0.92180211\n",
            "Validation score: 0.777267\n",
            "Iteration 87, loss = 0.91766880\n",
            "Validation score: 0.777924\n",
            "Iteration 88, loss = 0.91362931\n",
            "Validation score: 0.781209\n",
            "Iteration 89, loss = 0.90964798\n",
            "Validation score: 0.782523\n",
            "Iteration 90, loss = 0.90572372\n",
            "Validation score: 0.783837\n",
            "Iteration 91, loss = 0.90184454\n",
            "Validation score: 0.784166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PMRXKVjhb2b"
      },
      "source": [
        "**This code crashed after running for around 5 hours and we were not able to print the classification report. However, since the validation score is just at 78% eprcent after 91 iterations, we will not rerun it since it wont achieve the performance of the models being trained with Adam.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-brwl2BOwqC"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMBqHGuqmiwF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePp9RqvwpFzy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/ex01_mlp_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfUVMgBNottV"
      },
      "source": [
        "\n",
        "## hidden_layer_sizes=(200): configuration 5-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD569-BptrHc"
      },
      "source": [
        "### Configuration 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-T9ReRRthN4",
        "outputId": "29737cbd-1fca-4b14-952c-d7ab73c97711"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.09069852\n",
            "Validation score: 0.898160\n",
            "Iteration 2, loss = 0.27471013\n",
            "Validation score: 0.921321\n",
            "Iteration 3, loss = 0.13070372\n",
            "Validation score: 0.925591\n",
            "Iteration 4, loss = 0.07119369\n",
            "Validation score: 0.925427\n",
            "Iteration 5, loss = 0.04386892\n",
            "Validation score: 0.924277\n",
            "Iteration 6, loss = 0.03021037\n",
            "Validation score: 0.921813\n",
            "Iteration 7, loss = 0.02308790\n",
            "Validation score: 0.918693\n",
            "Iteration 8, loss = 0.01875333\n",
            "Validation score: 0.920171\n",
            "Iteration 9, loss = 0.01624824\n",
            "Validation score: 0.920171\n",
            "Iteration 10, loss = 0.01456572\n",
            "Validation score: 0.921321\n",
            "Iteration 11, loss = 0.01326822\n",
            "Validation score: 0.921156\n",
            "Iteration 12, loss = 0.01228777\n",
            "Validation score: 0.920007\n",
            "Iteration 13, loss = 0.01157770\n",
            "Validation score: 0.920171\n",
            "Iteration 14, loss = 0.01090817\n",
            "Validation score: 0.921156\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyNs9cs-uUPK",
        "outputId": "483dbf10-9496-4828-ddab-89949e18eaa3"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.99      0.97      0.98       259\n",
            "      arlatn       0.00      0.00      0.00         3\n",
            "          az       1.00      1.00      1.00         4\n",
            "          bg       1.00      1.00      1.00         3\n",
            "          bn       1.00      1.00      1.00         3\n",
            "          bs       1.00      1.00      1.00         2\n",
            "          ca       0.00      0.00      0.00         1\n",
            "          cs       1.00      1.00      1.00         5\n",
            "          cy       1.00      1.00      1.00         1\n",
            "          da       1.00      0.80      0.89         5\n",
            "          de       1.00      0.54      0.70        24\n",
            "          dv       1.00      1.00      1.00         7\n",
            "          el       1.00      0.75      0.86         4\n",
            "          en       0.92      0.97      0.94      2255\n",
            "          es       0.94      0.94      0.94       789\n",
            "          et       1.00      1.00      1.00         4\n",
            "          eu       1.00      1.00      1.00         2\n",
            "          fa       1.00      0.67      0.80         3\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.97      0.87      0.92       124\n",
            "          gl       1.00      1.00      1.00         2\n",
            "          ha       1.00      1.00      1.00         5\n",
            "          he       1.00      1.00      1.00         3\n",
            "          hi       1.00      1.00      1.00         2\n",
            "      hilatn       1.00      0.50      0.67         2\n",
            "          hr       1.00      1.00      1.00         2\n",
            "          ht       1.00      1.00      1.00         2\n",
            "          hu       1.00      0.75      0.86         8\n",
            "          hy       1.00      1.00      1.00         3\n",
            "          id       0.89      0.92      0.90       353\n",
            "          is       1.00      1.00      1.00         4\n",
            "          it       1.00      0.72      0.84        47\n",
            "          ja       0.99      0.98      0.99      1336\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.93      0.96        70\n",
            "      kolatn       1.00      1.00      1.00         5\n",
            "          la       1.00      1.00      1.00         5\n",
            "          lv       1.00      0.80      0.89         5\n",
            "          mk       1.00      1.00      1.00         4\n",
            "          mn       1.00      1.00      1.00         3\n",
            "          mr       1.00      1.00      1.00         5\n",
            "          ms       0.00      0.00      0.00        13\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.89      0.64      0.74        25\n",
            "          no       1.00      0.75      0.86         8\n",
            "          pl       1.00      0.67      0.80         9\n",
            "          ps       1.00      1.00      1.00         2\n",
            "      pslatn       1.00      1.00      1.00         1\n",
            "          pt       0.94      0.89      0.91       323\n",
            "          ro       1.00      1.00      1.00         1\n",
            "          ru       0.98      0.96      0.97       119\n",
            "          si       1.00      1.00      1.00         3\n",
            "          sk       1.00      1.00      1.00         1\n",
            "          sl       1.00      1.00      1.00         6\n",
            "          sq       1.00      1.00      1.00         1\n",
            "          sr       0.00      0.00      0.00         2\n",
            "          su       1.00      0.67      0.80         3\n",
            "          sv       1.00      0.57      0.73         7\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         5\n",
            "      talatn       1.00      1.00      1.00         6\n",
            "          th       0.98      0.95      0.97        64\n",
            "          tl       0.81      0.88      0.84        40\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.98      0.87      0.92        91\n",
            "          uk       1.00      0.88      0.93         8\n",
            "         und       0.68      0.70      0.69       606\n",
            "          ur       1.00      1.00      1.00         7\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      1.00      1.00         2\n",
            "          wo       1.00      1.00      1.00         6\n",
            "          xh       1.00      1.00      1.00         4\n",
            "          yo       1.00      1.00      1.00         3\n",
            "        zhcn       0.00      0.00      0.00         2\n",
            "        zhtw       1.00      1.00      1.00         3\n",
            "          zu       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.91      0.84      0.87      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwawZ5T9uF4x"
      },
      "source": [
        "### Configuration 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loFg9Uget1Qe",
        "outputId": "1da37358-909c-46e2-df76-695b781483f6"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.16928718\n",
            "Validation score: 0.896846\n",
            "Iteration 2, loss = 0.27827844\n",
            "Validation score: 0.924277\n",
            "Iteration 3, loss = 0.13075589\n",
            "Validation score: 0.931012\n",
            "Iteration 4, loss = 0.07191803\n",
            "Validation score: 0.931012\n",
            "Iteration 5, loss = 0.04476653\n",
            "Validation score: 0.931176\n",
            "Iteration 6, loss = 0.03102889\n",
            "Validation score: 0.930026\n",
            "Iteration 7, loss = 0.02358820\n",
            "Validation score: 0.929041\n",
            "Iteration 8, loss = 0.01942962\n",
            "Validation score: 0.929369\n",
            "Iteration 9, loss = 0.01665520\n",
            "Validation score: 0.929369\n",
            "Iteration 10, loss = 0.01488181\n",
            "Validation score: 0.928384\n",
            "Iteration 11, loss = 0.01358687\n",
            "Validation score: 0.928384\n",
            "Iteration 12, loss = 0.01254886\n",
            "Validation score: 0.928548\n",
            "Iteration 13, loss = 0.01174835\n",
            "Validation score: 0.927727\n",
            "Iteration 14, loss = 0.01116501\n",
            "Validation score: 0.928219\n",
            "Iteration 15, loss = 0.01050550\n",
            "Validation score: 0.927727\n",
            "Iteration 16, loss = 0.01003985\n",
            "Validation score: 0.928384\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E05Um7zGuW_C",
        "outputId": "092356f9-435b-45e2-b34c-6bf7a797df1d"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.99      0.99       283\n",
            "      arlatn       1.00      1.00      1.00         4\n",
            "          az       1.00      1.00      1.00         4\n",
            "          bg       1.00      1.00      1.00         7\n",
            "          bn       1.00      1.00      1.00         2\n",
            "          bs       1.00      0.80      0.89         5\n",
            "          ca       0.00      0.00      0.00         2\n",
            "          cs       1.00      1.00      1.00         3\n",
            "          cy       1.00      1.00      1.00         6\n",
            "          da       1.00      1.00      1.00         2\n",
            "          de       1.00      0.78      0.88        37\n",
            "          dv       1.00      1.00      1.00         3\n",
            "          el       1.00      1.00      1.00         1\n",
            "          en       0.93      0.97      0.95      2272\n",
            "          es       0.93      0.95      0.94       734\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         7\n",
            "          fa       1.00      0.50      0.67         2\n",
            "          fi       1.00      0.50      0.67         2\n",
            "          fr       0.97      0.79      0.87       144\n",
            "          gl       1.00      1.00      1.00         3\n",
            "          ha       1.00      1.00      1.00         4\n",
            "          he       1.00      1.00      1.00         3\n",
            "          hi       1.00      1.00      1.00         1\n",
            "      hilatn       1.00      0.75      0.86         4\n",
            "          hr       1.00      1.00      1.00         3\n",
            "          ht       1.00      1.00      1.00         2\n",
            "          hu       1.00      0.86      0.92         7\n",
            "          hy       1.00      1.00      1.00         2\n",
            "          id       0.84      0.88      0.86       366\n",
            "          is       1.00      1.00      1.00         3\n",
            "          it       0.93      0.67      0.78        39\n",
            "          ja       0.99      0.98      0.99      1276\n",
            "      jalatn       1.00      1.00      1.00         6\n",
            "          jv       1.00      1.00      1.00         7\n",
            "          km       1.00      1.00      1.00         3\n",
            "          ko       1.00      0.73      0.84        48\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         7\n",
            "          lv       1.00      1.00      1.00         5\n",
            "          mk       1.00      1.00      1.00         5\n",
            "          mn       1.00      1.00      1.00         7\n",
            "          mr       1.00      1.00      1.00         4\n",
            "          ms       0.50      0.10      0.17        20\n",
            "          ne       1.00      1.00      1.00         3\n",
            "          nl       1.00      0.77      0.87        26\n",
            "          no       1.00      1.00      1.00         2\n",
            "          pl       1.00      0.67      0.80        15\n",
            "          ps       1.00      1.00      1.00         5\n",
            "          pt       0.91      0.92      0.92       362\n",
            "          ro       1.00      0.67      0.80         6\n",
            "          ru       0.97      0.98      0.98       128\n",
            "          si       1.00      1.00      1.00         5\n",
            "          sk       1.00      1.00      1.00         3\n",
            "          sl       1.00      1.00      1.00         6\n",
            "          sq       1.00      1.00      1.00         5\n",
            "          sr       1.00      0.20      0.33         5\n",
            "          su       1.00      0.25      0.40         4\n",
            "          sv       1.00      0.44      0.62         9\n",
            "          sw       1.00      1.00      1.00         1\n",
            "          ta       1.00      1.00      1.00         7\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      1.00      1.00        51\n",
            "          tl       0.91      0.71      0.80        45\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.96      0.88      0.92        93\n",
            "          uk       1.00      0.86      0.92         7\n",
            "         und       0.64      0.65      0.65       596\n",
            "          ur       1.00      1.00      1.00         5\n",
            "      urlatn       1.00      0.60      0.75         5\n",
            "          vi       0.00      0.00      0.00         1\n",
            "          wo       1.00      1.00      1.00         2\n",
            "          xh       1.00      1.00      1.00         1\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhtw       1.00      1.00      1.00         3\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.95      0.87      0.89      6765\n",
            "weighted avg       0.92      0.92      0.91      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJJoxJWuotti"
      },
      "source": [
        "### Configuration 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-16T09:46:41.615001Z",
          "iopub.status.busy": "2021-10-16T09:46:41.614735Z",
          "iopub.status.idle": "2021-10-16T09:54:22.291069Z",
          "shell.execute_reply": "2021-10-16T09:54:22.289706Z",
          "shell.execute_reply.started": "2021-10-16T09:46:41.614971Z"
        },
        "id": "bubkQtE-iVyI",
        "outputId": "013903ef-bf6c-45e1-c6aa-d2e4c78320f5"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.70249981\n",
            "Validation score: 0.343627\n",
            "Iteration 2, loss = 2.69717160\n",
            "Validation score: 0.343627\n",
            "Iteration 3, loss = 2.39582595\n",
            "Validation score: 0.343627\n",
            "Iteration 4, loss = 2.26983137\n",
            "Validation score: 0.343627\n",
            "Iteration 5, loss = 2.20258270\n",
            "Validation score: 0.343627\n",
            "Iteration 6, loss = 2.15363711\n",
            "Validation score: 0.386170\n",
            "Iteration 7, loss = 2.10856486\n",
            "Validation score: 0.485381\n",
            "Iteration 8, loss = 2.06354278\n",
            "Validation score: 0.509198\n",
            "Iteration 9, loss = 2.01797672\n",
            "Validation score: 0.521353\n",
            "Iteration 10, loss = 1.97237272\n",
            "Validation score: 0.521353\n",
            "Iteration 11, loss = 1.92752119\n",
            "Validation score: 0.520368\n",
            "Iteration 12, loss = 1.88398228\n",
            "Validation score: 0.518725\n",
            "Iteration 13, loss = 1.84233862\n",
            "Validation score: 0.516919\n",
            "Iteration 14, loss = 1.80273953\n",
            "Validation score: 0.517083\n",
            "Iteration 15, loss = 1.76505337\n",
            "Validation score: 0.517576\n",
            "Iteration 16, loss = 1.72908061\n",
            "Validation score: 0.518561\n",
            "Iteration 17, loss = 1.69467793\n",
            "Validation score: 0.521353\n",
            "Iteration 18, loss = 1.66162981\n",
            "Validation score: 0.526281\n",
            "Iteration 19, loss = 1.62971276\n",
            "Validation score: 0.535808\n",
            "Iteration 20, loss = 1.59892563\n",
            "Validation score: 0.550263\n",
            "Iteration 21, loss = 1.56920564\n",
            "Validation score: 0.570795\n",
            "Iteration 22, loss = 1.54057397\n",
            "Validation score: 0.593298\n",
            "Iteration 23, loss = 1.51304759\n",
            "Validation score: 0.602168\n",
            "Iteration 24, loss = 1.48655961\n",
            "Validation score: 0.610217\n",
            "Iteration 25, loss = 1.46129017\n",
            "Validation score: 0.621222\n",
            "Iteration 26, loss = 1.43709952\n",
            "Validation score: 0.628449\n",
            "Iteration 27, loss = 1.41408361\n",
            "Validation score: 0.636005\n",
            "Iteration 28, loss = 1.39223118\n",
            "Validation score: 0.642247\n",
            "Iteration 29, loss = 1.37143819\n",
            "Validation score: 0.648982\n",
            "Iteration 30, loss = 1.35177536\n",
            "Validation score: 0.653581\n",
            "Iteration 31, loss = 1.33306992\n",
            "Validation score: 0.662122\n",
            "Iteration 32, loss = 1.31530034\n",
            "Validation score: 0.666557\n",
            "Iteration 33, loss = 1.29845560\n",
            "Validation score: 0.674934\n",
            "Iteration 34, loss = 1.28241096\n",
            "Validation score: 0.680848\n",
            "Iteration 35, loss = 1.26716929\n",
            "Validation score: 0.685283\n",
            "Iteration 36, loss = 1.25255334\n",
            "Validation score: 0.688568\n",
            "Iteration 37, loss = 1.23862458\n",
            "Validation score: 0.693495\n",
            "Iteration 38, loss = 1.22528452\n",
            "Validation score: 0.698095\n",
            "Iteration 39, loss = 1.21250156\n",
            "Validation score: 0.703187\n",
            "Iteration 40, loss = 1.20020462\n",
            "Validation score: 0.705322\n",
            "Iteration 41, loss = 1.18839254\n",
            "Validation score: 0.710578\n",
            "Iteration 42, loss = 1.17697136\n",
            "Validation score: 0.711071\n",
            "Iteration 43, loss = 1.16600295\n",
            "Validation score: 0.716820\n",
            "Iteration 44, loss = 1.15537412\n",
            "Validation score: 0.720598\n",
            "Iteration 45, loss = 1.14509963\n",
            "Validation score: 0.722733\n",
            "Iteration 46, loss = 1.13515941\n",
            "Validation score: 0.725033\n",
            "Iteration 47, loss = 1.12551359\n",
            "Validation score: 0.727497\n",
            "Iteration 48, loss = 1.11621460\n",
            "Validation score: 0.729796\n",
            "Iteration 49, loss = 1.10709397\n",
            "Validation score: 0.730946\n",
            "Iteration 50, loss = 1.09828425\n",
            "Validation score: 0.732917\n",
            "Iteration 51, loss = 1.08971079\n",
            "Validation score: 0.735053\n",
            "Iteration 52, loss = 1.08141290\n",
            "Validation score: 0.736859\n",
            "Iteration 53, loss = 1.07331725\n",
            "Validation score: 0.737845\n",
            "Iteration 54, loss = 1.06540585\n",
            "Validation score: 0.739159\n",
            "Iteration 55, loss = 1.05774942\n",
            "Validation score: 0.743430\n",
            "Iteration 56, loss = 1.05028504\n",
            "Validation score: 0.743594\n",
            "Iteration 57, loss = 1.04301203\n",
            "Validation score: 0.746386\n",
            "Iteration 58, loss = 1.03590004\n",
            "Validation score: 0.748522\n",
            "Iteration 59, loss = 1.02902258\n",
            "Validation score: 0.749507\n",
            "Iteration 60, loss = 1.02226838\n",
            "Validation score: 0.749343\n",
            "Iteration 61, loss = 1.01566995\n",
            "Validation score: 0.751150\n",
            "Iteration 62, loss = 1.00925489\n",
            "Validation score: 0.755256\n",
            "Iteration 63, loss = 1.00300600\n",
            "Validation score: 0.754271\n",
            "Iteration 64, loss = 0.99688749\n",
            "Validation score: 0.757227\n",
            "Iteration 65, loss = 0.99093246\n",
            "Validation score: 0.758541\n",
            "Iteration 66, loss = 0.98510924\n",
            "Validation score: 0.759034\n",
            "Iteration 67, loss = 0.97940174\n",
            "Validation score: 0.761662\n",
            "Iteration 68, loss = 0.97383430\n",
            "Validation score: 0.761991\n",
            "Iteration 69, loss = 0.96837912\n",
            "Validation score: 0.763469\n",
            "Iteration 70, loss = 0.96306066\n",
            "Validation score: 0.765769\n",
            "Iteration 71, loss = 0.95783286\n",
            "Validation score: 0.767740\n",
            "Iteration 72, loss = 0.95273305\n",
            "Validation score: 0.768725\n",
            "Iteration 73, loss = 0.94772958\n",
            "Validation score: 0.771682\n",
            "Iteration 74, loss = 0.94286595\n",
            "Validation score: 0.772011\n",
            "Iteration 75, loss = 0.93804390\n",
            "Validation score: 0.773653\n",
            "Iteration 76, loss = 0.93331464\n",
            "Validation score: 0.773325\n",
            "Iteration 77, loss = 0.92869261\n",
            "Validation score: 0.774639\n",
            "Iteration 78, loss = 0.92422148\n",
            "Validation score: 0.777267\n",
            "Iteration 79, loss = 0.91974878\n",
            "Validation score: 0.777760\n",
            "Iteration 80, loss = 0.91539317\n",
            "Validation score: 0.779895\n",
            "Iteration 81, loss = 0.91108623\n",
            "Validation score: 0.780223\n",
            "Iteration 82, loss = 0.90688962\n",
            "Validation score: 0.782359\n",
            "Iteration 83, loss = 0.90274567\n",
            "Validation score: 0.782852\n",
            "Iteration 84, loss = 0.89867988\n",
            "Validation score: 0.783673\n",
            "Iteration 85, loss = 0.89467521\n",
            "Validation score: 0.784494\n",
            "Iteration 86, loss = 0.89073850\n",
            "Validation score: 0.784658\n",
            "Iteration 87, loss = 0.88687711\n",
            "Validation score: 0.786958\n",
            "Iteration 88, loss = 0.88305621\n",
            "Validation score: 0.788272\n",
            "Iteration 89, loss = 0.87926802\n",
            "Validation score: 0.790407\n",
            "Iteration 90, loss = 0.87557077\n",
            "Validation score: 0.791229\n",
            "Iteration 91, loss = 0.87191952\n",
            "Validation score: 0.792050\n",
            "Iteration 92, loss = 0.86835515\n",
            "Validation score: 0.792871\n",
            "Iteration 93, loss = 0.86478605\n",
            "Validation score: 0.792707\n",
            "Iteration 94, loss = 0.86131876\n",
            "Validation score: 0.793693\n",
            "Iteration 95, loss = 0.85788630\n",
            "Validation score: 0.794842\n",
            "Iteration 96, loss = 0.85448165\n",
            "Validation score: 0.796978\n",
            "Iteration 97, loss = 0.85111729\n",
            "Validation score: 0.797470\n",
            "Iteration 98, loss = 0.84784344\n",
            "Validation score: 0.798456\n",
            "Iteration 99, loss = 0.84456882\n",
            "Validation score: 0.798949\n",
            "Iteration 100, loss = 0.84134895\n",
            "Validation score: 0.799770\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2021-10-16T09:54:22.292515Z",
          "iopub.status.idle": "2021-10-16T09:54:22.293197Z",
          "shell.execute_reply": "2021-10-16T09:54:22.292949Z",
          "shell.execute_reply.started": "2021-10-16T09:54:22.292922Z"
        },
        "id": "UnGrrGK2iVyI",
        "outputId": "4adfd1b3-2606-4f3b-fbcd-7fd35556e91a"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.93      0.96      0.95       255\n",
            "      arlatn       0.00      0.00      0.00         6\n",
            "          az       0.00      0.00      0.00         3\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         3\n",
            "          bs       0.00      0.00      0.00         4\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         3\n",
            "          de       0.00      0.00      0.00        21\n",
            "          dv       0.00      0.00      0.00         1\n",
            "          el       0.00      0.00      0.00         2\n",
            "          en       0.86      0.96      0.91      2358\n",
            "          es       0.77      0.92      0.84       738\n",
            "          et       0.00      0.00      0.00         7\n",
            "          eu       0.00      0.00      0.00         6\n",
            "          fa       0.00      0.00      0.00         3\n",
            "          fi       0.00      0.00      0.00         1\n",
            "          fr       0.00      0.00      0.00       114\n",
            "          gl       0.00      0.00      0.00         3\n",
            "          ha       0.00      0.00      0.00         2\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         3\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         4\n",
            "          ht       0.00      0.00      0.00         5\n",
            "          hu       0.00      0.00      0.00         6\n",
            "          id       0.64      0.79      0.71       345\n",
            "          is       0.00      0.00      0.00         6\n",
            "          it       0.00      0.00      0.00        50\n",
            "          ja       0.91      0.97      0.94      1297\n",
            "      jalatn       0.00      0.00      0.00         3\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         5\n",
            "          ko       0.00      0.00      0.00        50\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         4\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         3\n",
            "          mr       0.00      0.00      0.00         5\n",
            "          ms       0.00      0.00      0.00        17\n",
            "          ne       0.00      0.00      0.00         5\n",
            "          nl       0.00      0.00      0.00        27\n",
            "          no       0.00      0.00      0.00         3\n",
            "          pl       0.00      0.00      0.00        11\n",
            "          ps       0.00      0.00      0.00         9\n",
            "      pslatn       0.00      0.00      0.00         3\n",
            "          pt       0.88      0.65      0.75       388\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.90      0.89      0.89       110\n",
            "          si       0.00      0.00      0.00         1\n",
            "          sk       0.00      0.00      0.00         6\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         6\n",
            "          sr       0.00      0.00      0.00         3\n",
            "          su       0.00      0.00      0.00         4\n",
            "          sv       0.00      0.00      0.00         7\n",
            "          sw       0.00      0.00      0.00         4\n",
            "          ta       0.00      0.00      0.00         2\n",
            "      talatn       0.00      0.00      0.00         5\n",
            "          th       0.00      0.00      0.00        59\n",
            "          tl       0.00      0.00      0.00        50\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        90\n",
            "          uk       0.00      0.00      0.00         5\n",
            "         und       0.40      0.56      0.47       550\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         6\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         1\n",
            "          xh       0.00      0.00      0.00         2\n",
            "          yo       0.00      0.00      0.00         6\n",
            "        zhcn       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         6\n",
            "          zu       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.80      6765\n",
            "   macro avg       0.08      0.09      0.08      6765\n",
            "weighted avg       0.72      0.80      0.76      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9NJk_UluMvZ"
      },
      "source": [
        "### Configuration 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilsQFkyKuB-U",
        "outputId": "301684fa-ecde-44bf-8f4b-4ec7f0bf03e4"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.98300187\n",
            "Validation score: 0.339520\n",
            "Iteration 2, loss = 3.03748377\n",
            "Validation score: 0.339520\n",
            "Iteration 3, loss = 2.52303243\n",
            "Validation score: 0.339520\n",
            "Iteration 4, loss = 2.33395189\n",
            "Validation score: 0.339520\n",
            "Iteration 5, loss = 2.23689899\n",
            "Validation score: 0.339520\n",
            "Iteration 6, loss = 2.17713531\n",
            "Validation score: 0.341820\n",
            "Iteration 7, loss = 2.12898423\n",
            "Validation score: 0.431012\n",
            "Iteration 8, loss = 2.08270709\n",
            "Validation score: 0.502628\n",
            "Iteration 9, loss = 2.03630077\n",
            "Validation score: 0.518890\n",
            "Iteration 10, loss = 1.98986490\n",
            "Validation score: 0.521189\n",
            "Iteration 11, loss = 1.94401979\n",
            "Validation score: 0.521025\n",
            "Iteration 12, loss = 1.89970961\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.85725869\n",
            "Validation score: 0.519547\n",
            "Iteration 14, loss = 1.81703284\n",
            "Validation score: 0.519218\n",
            "Iteration 15, loss = 1.77893385\n",
            "Validation score: 0.518725\n",
            "Iteration 16, loss = 1.74274838\n",
            "Validation score: 0.520204\n",
            "Iteration 17, loss = 1.70825634\n",
            "Validation score: 0.522175\n",
            "Iteration 18, loss = 1.67517703\n",
            "Validation score: 0.526610\n",
            "Iteration 19, loss = 1.64329366\n",
            "Validation score: 0.538108\n",
            "Iteration 20, loss = 1.61260493\n",
            "Validation score: 0.546978\n",
            "Iteration 21, loss = 1.58296134\n",
            "Validation score: 0.560775\n",
            "Iteration 22, loss = 1.55433587\n",
            "Validation score: 0.575230\n",
            "Iteration 23, loss = 1.52672923\n",
            "Validation score: 0.591656\n",
            "Iteration 24, loss = 1.50018910\n",
            "Validation score: 0.606767\n",
            "Iteration 25, loss = 1.47468322\n",
            "Validation score: 0.618265\n",
            "Iteration 26, loss = 1.45025312\n",
            "Validation score: 0.623850\n",
            "Iteration 27, loss = 1.42696090\n",
            "Validation score: 0.627792\n",
            "Iteration 28, loss = 1.40474078\n",
            "Validation score: 0.635677\n",
            "Iteration 29, loss = 1.38355712\n",
            "Validation score: 0.640604\n",
            "Iteration 30, loss = 1.36343794\n",
            "Validation score: 0.645696\n",
            "Iteration 31, loss = 1.34436424\n",
            "Validation score: 0.649639\n",
            "Iteration 32, loss = 1.32621072\n",
            "Validation score: 0.653252\n",
            "Iteration 33, loss = 1.30893355\n",
            "Validation score: 0.657359\n",
            "Iteration 34, loss = 1.29252028\n",
            "Validation score: 0.663765\n",
            "Iteration 35, loss = 1.27691213\n",
            "Validation score: 0.671813\n",
            "Iteration 36, loss = 1.26202509\n",
            "Validation score: 0.678384\n",
            "Iteration 37, loss = 1.24780959\n",
            "Validation score: 0.681505\n",
            "Iteration 38, loss = 1.23421558\n",
            "Validation score: 0.686104\n",
            "Iteration 39, loss = 1.22117372\n",
            "Validation score: 0.688568\n",
            "Iteration 40, loss = 1.20867471\n",
            "Validation score: 0.693824\n",
            "Iteration 41, loss = 1.19669775\n",
            "Validation score: 0.697109\n",
            "Iteration 42, loss = 1.18512879\n",
            "Validation score: 0.701873\n",
            "Iteration 43, loss = 1.17395944\n",
            "Validation score: 0.705486\n",
            "Iteration 44, loss = 1.16320444\n",
            "Validation score: 0.708443\n",
            "Iteration 45, loss = 1.15284571\n",
            "Validation score: 0.710250\n",
            "Iteration 46, loss = 1.14277769\n",
            "Validation score: 0.715342\n",
            "Iteration 47, loss = 1.13301892\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.12355959\n",
            "Validation score: 0.720105\n",
            "Iteration 49, loss = 1.11441324\n",
            "Validation score: 0.723390\n",
            "Iteration 50, loss = 1.10550422\n",
            "Validation score: 0.726511\n",
            "Iteration 51, loss = 1.09684978\n",
            "Validation score: 0.729139\n",
            "Iteration 52, loss = 1.08842390\n",
            "Validation score: 0.731110\n",
            "Iteration 53, loss = 1.08023785\n",
            "Validation score: 0.732917\n",
            "Iteration 54, loss = 1.07225205\n",
            "Validation score: 0.734231\n",
            "Iteration 55, loss = 1.06448317\n",
            "Validation score: 0.735545\n",
            "Iteration 56, loss = 1.05690499\n",
            "Validation score: 0.737024\n",
            "Iteration 57, loss = 1.04955022\n",
            "Validation score: 0.738995\n",
            "Iteration 58, loss = 1.04233262\n",
            "Validation score: 0.740966\n",
            "Iteration 59, loss = 1.03536738\n",
            "Validation score: 0.743101\n",
            "Iteration 60, loss = 1.02851266\n",
            "Validation score: 0.745072\n",
            "Iteration 61, loss = 1.02183352\n",
            "Validation score: 0.745237\n",
            "Iteration 62, loss = 1.01530706\n",
            "Validation score: 0.747700\n",
            "Iteration 63, loss = 1.00895242\n",
            "Validation score: 0.748193\n",
            "Iteration 64, loss = 1.00274792\n",
            "Validation score: 0.751807\n",
            "Iteration 65, loss = 0.99668398\n",
            "Validation score: 0.751478\n",
            "Iteration 66, loss = 0.99078650\n",
            "Validation score: 0.752135\n",
            "Iteration 67, loss = 0.98500460\n",
            "Validation score: 0.753614\n",
            "Iteration 68, loss = 0.97932487\n",
            "Validation score: 0.756242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMtrpZF1pzjq"
      },
      "source": [
        "**The colab session crashed before we get the result after running for 10 hours.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwPK_skSyzA7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wDuqlBSDZd2"
      },
      "source": [
        "## hidden_layer_sizes=(500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarGO22CEKAB"
      },
      "source": [
        "### Configuration 9\n",
        "\n",
        "**We wanted to test the performance of a MLP being trained with adam and relu and one hidden layer with 500 neurons since, adam and relu performed better than sgd and tanh. We could see that the performance is similar to the same model with 100 neurons in the hidden layer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuK8Loq39fnj",
        "outputId": "e16588ac-ed93-47fb-e182-76e101ec990e"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(500), solver='adam', activation='relu', max_iter=50, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.89183017\n",
            "Validation score: 0.906866\n",
            "Iteration 2, loss = 0.17527408\n",
            "Validation score: 0.919514\n",
            "Iteration 3, loss = 0.07068142\n",
            "Validation score: 0.921649\n",
            "Iteration 4, loss = 0.03743430\n",
            "Validation score: 0.919842\n",
            "Iteration 5, loss = 0.02444688\n",
            "Validation score: 0.915572\n",
            "Iteration 6, loss = 0.01876033\n",
            "Validation score: 0.919678\n",
            "Iteration 7, loss = 0.01559447\n",
            "Validation score: 0.918528\n",
            "Iteration 8, loss = 0.01382175\n",
            "Validation score: 0.917214\n",
            "Iteration 9, loss = 0.01289217\n",
            "Validation score: 0.918857\n",
            "Iteration 10, loss = 0.01175382\n",
            "Validation score: 0.919842\n",
            "Iteration 11, loss = 0.01099969\n",
            "Validation score: 0.920992\n",
            "Iteration 12, loss = 0.01045910\n",
            "Validation score: 0.919514\n",
            "Iteration 13, loss = 0.00997286\n",
            "Validation score: 0.917378\n",
            "Iteration 14, loss = 0.00973240\n",
            "Validation score: 0.921156\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=500, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVzdww4E9ouh",
        "outputId": "28fa4245-497f-4f2d-d357-fd530c210646"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.98      0.98       299\n",
            "      arlatn       1.00      0.67      0.80         3\n",
            "          az       1.00      1.00      1.00         6\n",
            "          bg       1.00      1.00      1.00         4\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      0.80      0.89        10\n",
            "          ca       0.00      0.00      0.00         2\n",
            "          cs       1.00      1.00      1.00         6\n",
            "          cy       1.00      1.00      1.00         1\n",
            "          da       1.00      0.75      0.86         4\n",
            "          de       1.00      0.83      0.91        24\n",
            "          dv       1.00      1.00      1.00         7\n",
            "          el       1.00      1.00      1.00         4\n",
            "          en       0.94      0.96      0.95      2298\n",
            "          es       0.94      0.94      0.94       757\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         5\n",
            "          fa       1.00      0.25      0.40         4\n",
            "          fi       1.00      1.00      1.00         2\n",
            "          fr       0.96      0.82      0.88       117\n",
            "          gl       1.00      1.00      1.00         3\n",
            "          ha       1.00      1.00      1.00         2\n",
            "          he       1.00      0.71      0.83         7\n",
            "          hi       1.00      0.67      0.80         3\n",
            "      hilatn       1.00      0.67      0.80         6\n",
            "          hr       0.80      1.00      0.89         4\n",
            "          ht       1.00      1.00      1.00         4\n",
            "          hu       1.00      0.75      0.86         8\n",
            "          hy       1.00      1.00      1.00         2\n",
            "          id       0.88      0.89      0.88       365\n",
            "          is       1.00      1.00      1.00         4\n",
            "          it       0.97      0.81      0.88        42\n",
            "          ja       0.99      0.99      0.99      1252\n",
            "      jalatn       1.00      1.00      1.00         2\n",
            "          jv       0.00      0.00      0.00         2\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       0.98      0.85      0.91        54\n",
            "      kolatn       1.00      1.00      1.00         2\n",
            "          la       1.00      1.00      1.00         4\n",
            "          lv       1.00      1.00      1.00         9\n",
            "          mk       1.00      1.00      1.00         7\n",
            "          mn       1.00      1.00      1.00         6\n",
            "          mr       1.00      1.00      1.00         6\n",
            "          ms       0.38      0.21      0.27        14\n",
            "          ne       1.00      1.00      1.00         5\n",
            "          nl       1.00      0.82      0.90        17\n",
            "          no       1.00      1.00      1.00         7\n",
            "          pl       1.00      0.78      0.88        18\n",
            "          ps       1.00      1.00      1.00         7\n",
            "      pslatn       1.00      1.00      1.00         3\n",
            "          pt       0.93      0.91      0.92       362\n",
            "          ro       1.00      0.88      0.93         8\n",
            "          ru       0.98      0.96      0.97       109\n",
            "          si       1.00      1.00      1.00         6\n",
            "          sk       1.00      1.00      1.00         2\n",
            "          sq       1.00      1.00      1.00         2\n",
            "          sr       1.00      0.25      0.40         4\n",
            "          su       1.00      1.00      1.00         6\n",
            "          sv       1.00      1.00      1.00         5\n",
            "          sw       1.00      1.00      1.00         3\n",
            "          ta       1.00      1.00      1.00         6\n",
            "      talatn       1.00      1.00      1.00         5\n",
            "          th       0.98      0.93      0.96        60\n",
            "          tl       0.91      0.74      0.82        42\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.97      0.87      0.92        90\n",
            "          uk       1.00      0.86      0.92         7\n",
            "         und       0.65      0.71      0.68       576\n",
            "          ur       1.00      1.00      1.00         8\n",
            "      urlatn       1.00      0.50      0.67         6\n",
            "          vi       1.00      1.00      1.00         1\n",
            "          wo       1.00      1.00      1.00         3\n",
            "          xh       1.00      1.00      1.00         2\n",
            "          yo       1.00      1.00      1.00         4\n",
            "        zhcn       0.00      0.00      0.00         1\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.87      0.89      6765\n",
            "weighted avg       0.93      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    }
  ]
}