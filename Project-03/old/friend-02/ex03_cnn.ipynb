{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex03_cnn_final",
      "provenance": [],
      "collapsed_sections": [
        "1XVsAdL26At4",
        "kbbiUTk_6D5y",
        "zu03PG2b6Gz6",
        "ZoJ6DIns6JaR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Pocwx70WEo"
      },
      "source": [
        "# Exercise 3 - CNN for language classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw3hMp1D-lyq",
        "outputId": "7d71fbe6-a67a-4aab-8fea-29001e9efc10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from io import StringIO\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import bisect\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f09f85a3a38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beluhFMfCeB5"
      },
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctgR798REMmI",
        "outputId": "599c09e1-f2da-4439-a8bf-33c38aa5ae74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "import math\n",
        "from nltk.tokenize import word_tokenize\n",
        "!pip install emoji\n",
        "import emoji\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=6044d64ba738c03e8f3d4dc19734f50c137855b254393f33379c4dcc7be24090\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ptZdmGz1D68"
      },
      "source": [
        "# Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBfJ8WAeEI49"
      },
      "source": [
        "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
        "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFKlvxld2kG2"
      },
      "source": [
        "def load_dataset(url):\n",
        "    r = requests.get(url)\n",
        "    data = r.content.decode('utf8')\n",
        "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
        "    df.columns = ['tweet', 'label']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfc-9ExjEOfu"
      },
      "source": [
        "df_train_dev = load_dataset(url_train_dev)\n",
        "df_test = load_dataset(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dasHVYer0cAw"
      },
      "source": [
        "function to cut off the smallest classes that have less than 100 samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_xDIte2RTXk"
      },
      "source": [
        "def cutoff_small_classes(df, threshold=100):\n",
        "    sizes = df.groupby('label').size()\n",
        "    small_classes = sizes[sizes <= threshold].index.values.tolist()\n",
        "    \n",
        "    for ind, tweet in df.iterrows():\n",
        "        if tweet.label in small_classes:\n",
        "            tweet.label = 'other'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qhrCu3J0gLq"
      },
      "source": [
        "resample the training data such that each class has the same amount of samples (6000 samples in our case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghjjI-WMRTXq"
      },
      "source": [
        "def resample_training_set(df, n):\n",
        "    sizes = df.groupby('label').size().sort_values()\n",
        "    dfs = []\n",
        "    for class_ in sizes.keys():\n",
        "        dfs.append(resample(df[df.label == class_], n_samples=n))\n",
        "    return pd.concat(dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc1rtMBERTXw"
      },
      "source": [
        "cutoff_small_classes(df_train_dev, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Zv0eVpRTX1"
      },
      "source": [
        "resampled = resample_training_set(df_train_dev, 6000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbTvfDqT5m8C"
      },
      "source": [
        "resampled = resampled.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SjecaY07PbV",
        "outputId": "3e074b6d-e360-4845-d14d-4e17a2d7a338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "resampled['tweet'] = resampled['tweet'].astype('str')\n",
        "resampled['tweet'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3 hari ke arah puasa penuh . phhew'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGV6k5SVq7vi"
      },
      "source": [
        "class Vocabulary:\n",
        "    \"\"\"Assigns and keeps indices to (as well as counts of) a vocabulary \n",
        "    of tokens, which can be searched and updated\"\"\"\n",
        "\n",
        "    UNKNOWN_TOKEN = '<UNK>'\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        \n",
        "        # Building two dicts one that mapes tokens to indices and anither one that maps indices to tokens\n",
        "        self._token_to_idx = token_to_idx\n",
        "        self._idx_to_token = {idx: token for token, idx in self._token_to_idx.items()}\n",
        "\n",
        "        self.add_token(Vocabulary.UNKNOWN_TOKEN)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"adds a token to the vocab and creats an index for it\"\"\"\n",
        "        \n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"given a token it find the corresponding index\n",
        "        if the token is not in the vocab, it raises a key error\"\"\"\n",
        "\n",
        "        if token not in self._token_to_idx:\n",
        "            raise KeyError(\"the token (%s) is not in the Vocabulary\" % token)\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"gets a token given an index, if the index does not exists\n",
        "        it raises a key error\"\"\"\n",
        "\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "834GJe3DGWvw"
      },
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, df_test, preprocessor=None, cutoff=0, seq_len=300):\n",
        "        self.cutoff = cutoff\n",
        "        self._seq_len = seq_len\n",
        "\n",
        "        self.x_test = []\n",
        "        self.y_test = df_test.label\n",
        "\n",
        "        # prepare the test set, which will not be part of the vocabulary nor any other\n",
        "        # statistics\n",
        "        test_texts = df_test.tweet\n",
        "        for i in range(len(test_texts)):\n",
        "            if preprocessor:\n",
        "                sentence = \" \".join(preprocessor.preprocess(test_texts[i]))\n",
        "                n_grams = [sentence[i] for i in range(len(sentence))]\n",
        "            \n",
        "            # tweets that are longer than a certain maximum will be exluded\n",
        "            if len(n_grams) <= self._seq_len:\n",
        "                self.x_test.append(n_grams)\n",
        "            else:\n",
        "                self.x_test.append(n_grams[:200])\n",
        "\n",
        "        # loads the dataset and (after preprocessing) creates a list of tokens,\n",
        "        # arranged in texts (e.g., different reviews are regarded as different\n",
        "        # texts), thus preventing overlapping contexts between reviews/texts.\n",
        "        texts = df.tweet\n",
        "        self.labels = df.label\n",
        "        self._texts = []\n",
        "        self.max_token = []\n",
        "        for i in range(len(texts)):\n",
        "            if preprocessor:\n",
        "                sentence = \" \".join(preprocessor.preprocess(texts[i]))\n",
        "                n_grams = [sentence[i] for i in range(len(sentence))]\n",
        "\n",
        "            # tweets that are longer than a certain maximum will be exluded\n",
        "            if len(n_grams) <= self._seq_len:\n",
        "                self._texts.append(n_grams)\n",
        "            else:\n",
        "                self._texts.append(n_grams[:200])\n",
        "            \n",
        "            self.max_token.append(len(n_grams))\n",
        "            \n",
        "        # fills the sentences with 0 such that all have same length\n",
        "        self._padding_sentences()\n",
        "\n",
        "        # holds a counter for the tokens. used later for cutting off, and \n",
        "        # finding the most common words in the dataset\n",
        "        self.counter = Counter()\n",
        "        self._count()\n",
        "\n",
        "        # creates the Vocabulary (index)\n",
        "        self._unk_count = 0\n",
        "        self.vocabulary = self._create_vocabulary()\n",
        "\n",
        "        #self._texts = self._padding_sentences(self._texts)\n",
        "        self._token_to_idx()\n",
        "\n",
        "        # split the dataset into train and test\n",
        "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self._texts, self.labels, test_size=0.1)\n",
        "\n",
        "        self._encode_labels()\n",
        "\n",
        "        self.x_train = tf.convert_to_tensor(self.x_train)\n",
        "        self.x_val = tf.convert_to_tensor(self.x_val)\n",
        "        self.x_test = tf.convert_to_tensor(self.x_test)\n",
        "    \n",
        "    def switch_mode(self, new_mode):\n",
        "        self.mode = new_mode\n",
        "\n",
        "    def _count(self):\n",
        "        for text in self._texts:\n",
        "            self.counter.update(text)\n",
        "\n",
        "    def unknown_count(self):\n",
        "        return self._unk_count\n",
        "\n",
        "    def _create_vocabulary(self):\n",
        "        \"\"\"create vocabulary with all words of the dataset which appear more frequent than cutoff threshold\"\"\"\n",
        "        vocabulary = Vocabulary()\n",
        "        for i, text in enumerate(self._texts):\n",
        "            for j, token in enumerate(text):\n",
        "                if self.counter[token] < self.cutoff:\n",
        "                    self._texts[i][j] = Vocabulary.UNKNOWN_TOKEN\n",
        "                    self._unk_count += 1\n",
        "                else:\n",
        "                    vocabulary.add_token(token)\n",
        "        return vocabulary\n",
        "    \n",
        "    def _encode_labels(self):\n",
        "        \"\"\"first encode the labels and map them to numbers, then the labels\n",
        "        are converted into one-hot encoding\"\"\"\n",
        "        label_encoder = LabelEncoder()\n",
        "        label_one_hot = OneHotEncoder(sparse=False)\n",
        "\n",
        "        # fit encoder to train labels and transform those to numbers\n",
        "        y_train = label_encoder.fit_transform(self.y_train)\n",
        "\n",
        "        # overwrite unknown labels in the validation and test set\n",
        "        y_val = ['und' if s not in label_encoder.classes_ else s for s in self.y_val]\n",
        "        y_val = label_encoder.transform(y_val)\n",
        "\n",
        "        y_test = ['und' if s not in label_encoder.classes_ else s for s in self.y_test]\n",
        "        y_test = label_encoder.transform(y_test)\n",
        "\n",
        "        self.y_train = y_train.tolist()\n",
        "        self.y_val = y_val.tolist()\n",
        "        self.y_test = y_test.tolist()\n",
        "\n",
        "        self.test_labels_numbers = self.y_test\n",
        "        self.labels_encoded = list(label_encoder.classes_)\n",
        "\n",
        "        # transforming the encoded lables to one-hot format\n",
        "        self.y_train = np.array(self.y_train).reshape((len(self.y_train), 1))\n",
        "        self.y_val = np.array(self.y_val).reshape((len(self.y_val), 1))\n",
        "        self.y_test = np.array(self.y_test).reshape((len(self.y_test), 1))\n",
        "\n",
        "        self.y_train = label_one_hot.fit_transform(self.y_train)\n",
        "        self.y_val = label_one_hot.transform(self.y_val)\n",
        "        self.y_test = label_one_hot.transform(self.y_test)\n",
        "\n",
        "        self.y_train = tf.convert_to_tensor(self.y_train.tolist())\n",
        "        self.y_val = tf.convert_to_tensor(self.y_val.tolist())\n",
        "        self.y_test = tf.convert_to_tensor(self.y_test.tolist())\n",
        "   \n",
        "    def _padding_sentences(self):\n",
        "        # Each sentence which does not fulfill the required length\n",
        "        # it's padded with the index 0\n",
        "        for idx, el in enumerate(self._texts):\n",
        "            l = el\n",
        "            while len(l) < self._seq_len:\n",
        "                l.append(0)\n",
        "            self._texts[idx] = l\n",
        "        \n",
        "        for idx, el in enumerate(self.x_test):\n",
        "            l = el\n",
        "            while len(l) < self._seq_len:\n",
        "                l.append(0)\n",
        "            self.x_test[idx] = l\n",
        "\n",
        "    \n",
        "    def _token_to_idx(self):\n",
        "        \"\"\" this function replaces the words on the sentences with the respective \n",
        "        idx number from the vocab \"\"\"\n",
        "        for j, text in enumerate(self._texts):\n",
        "            for i, word in enumerate(text):\n",
        "                if not word == 0:\n",
        "                    idx = self.vocabulary.lookup_token(word)\n",
        "                    self._texts[j][i] = idx\n",
        "            self._texts[j] = text\n",
        "        \n",
        "        for j, text in enumerate(self.x_test):\n",
        "            for i, word in enumerate(text):\n",
        "                if not word == 0:\n",
        "                    try:\n",
        "                        idx = self.vocabulary.lookup_token(word)\n",
        "                    except KeyError:\n",
        "                        idx = 0\n",
        "                    self.x_test[j][i] = idx\n",
        "            self.x_test[j] = text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA27pOifTMEU"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "class Preprocessing:\n",
        "\n",
        "    EMOJI_PATTERN = emoji.get_emoji_regexp()\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
        "        self._tokens = None\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        self._text = text\n",
        "        self._text = self._remove_emojis(self._text)\n",
        "        self._text = self._remove_urls(self._text)\n",
        "        self._text = self._remove_hashtags(self._text)\n",
        "        self._text = self._remove_mentions(self._text)\n",
        "        self._text = self._clean_text(self._text)\n",
        "        return self.tknzr.tokenize(self._text)\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        # Removes special symbols and just keep\n",
        "        # words in lower or upper form\n",
        "        self._text = self._text.lower()\n",
        "        self._text = re.sub(r'[!.,-?\\'\\\"()/%@#\\d]+', '', self._text)\n",
        "        return self._text\n",
        "    \n",
        "    def _remove_emojis(self, text):\n",
        "        return Preprocessing.EMOJI_PATTERN.sub('', text)\n",
        "    \n",
        "    def _remove_urls(self, text):\n",
        "        return re.sub(r'https?://[\\S]+', '', text)\n",
        "    \n",
        "    def _remove_hashtags(self, text):\n",
        "        return re.sub(r'#[\\S]+', '', text)\n",
        "    \n",
        "    def _remove_mentions(self, text):\n",
        "        return re.sub(r'@[\\S]+', '', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D77AcoW00qcb"
      },
      "source": [
        "### create the dataset based on the three classes above: \n",
        "\n",
        "* vocabulary keeps count of the vocab (this time it is characters not words!)\n",
        "* TextDataset builds the dataset and converts the tweets to tensors\n",
        "* preprocessing class that preprocesses the tweets (explained in lapreport)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME_daurdu9q5"
      },
      "source": [
        "dataset = TextDataset(resampled, df_test, Preprocessing(), seq_len=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FceJBjqiXC-N",
        "outputId": "190dbd1e-c922-4c06-ed68-746bd8f6a594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(97200, 200), dtype=int32, numpy=\n",
              "array([[ 8,  3,  3, ...,  0,  0,  0],\n",
              "       [24,  6, 20, ...,  0,  0,  0],\n",
              "       [24,  6,  8, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [12, 11, 20, ...,  0,  0,  0],\n",
              "       [ 9,  4, 15, ...,  0,  0,  0],\n",
              "       [ 1,  6,  8, ...,  0,  0,  0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDQwVEAUnEly",
        "outputId": "2693b4c6-8376-4e6c-bca3-66079805ad0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(97200, 18), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vjDVPUKIjSh",
        "outputId": "fb4a8a08-3e9c-4d70-9ecf-4fd09e465c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.x_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10800, 200), dtype=int32, numpy=\n",
              "array([[  19,    3,    1, ...,    0,    0,    0],\n",
              "       [  12,    3,   20, ...,    0,    0,    0],\n",
              "       [  83,    5,   25, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  28,    5, 2200, ...,    0,    0,    0],\n",
              "       [  26,    6,   20, ...,    0,    0,    0],\n",
              "       [1008,    5, 1010, ...,    0,    0,    0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmc4BiuqIjac",
        "outputId": "e5802a46-72a1-4b46-e617-273c7de0bebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10800, 18), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUrhlXvPIjnl",
        "outputId": "3c773b55-950e-4601-daaa-3bd2527a8edf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.x_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13279, 200), dtype=int32, numpy=\n",
              "array([[  13,   11,    2, ...,    0,    0,    0],\n",
              "       [   0,    0,    0, ...,    0,    0,    0],\n",
              "       [  15,    3,    3, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,   15,    5, ...,    0,    0,    0],\n",
              "       [2411, 2643, 2613, ...,    0,    0,    0],\n",
              "       [   0,    0,    0, ...,    0,    0,    0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6yyeUe0IjtH",
        "outputId": "9854c114-f86e-41f7-dc02-5f5a9164dde4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13279, 18), dtype=float32, numpy=\n",
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsfqLPUW1a6e"
      },
      "source": [
        "here we can see that the index in the vocab actually only returns one char"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C17LYbF2JYLv",
        "outputId": "a3ff9af7-1fa8-49da-cf65-af11e87f672a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "dataset.vocabulary.lookup_index(1234)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'忘'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkfiZkNRpvAc"
      },
      "source": [
        "# 5 model combinations\n",
        "### We ran more than 5 models and included the most interesting ones in the report, the models below are to show how we did it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XVsAdL26At4"
      },
      "source": [
        "# Model 1 / 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1iiawjo74os",
        "outputId": "0ca328fd-aa14-45ff-c126-8b773b291c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is responsible for early stopping as was recommended\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Embedding(len(dataset.vocabulary), output_dim=32, input_length=200))\n",
        "model.add(layers.Reshape(target_shape=(200, 32, 1)))\n",
        "model.add(layers.Conv2D(kernel_size=2, filters=32, padding='same', activation='relu', strides=1))\n",
        "model.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model.add(layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', strides=1))\n",
        "model.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(200, activation='relu'))\n",
        "model.add(layers.Dense(18, activation='softmax')) \n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 32)           141664    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 200, 32, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 200, 32, 32)       160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 200, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 200, 32, 128)      36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 200, 32, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 819200)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               163840200 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 18)                3618      \n",
            "=================================================================\n",
            "Total params: 164,022,634\n",
            "Trainable params: 164,022,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKx6knQsHceH",
        "outputId": "7cb20b48-33ee-4a94-87d9-120396515680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(x = dataset.x_train, y = dataset.y_train, batch_size = 50, verbose=1, epochs=50, validation_data=(dataset.x_val, dataset.y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1944/1944 [==============================] - ETA: 0s - loss: 2.9400 - accuracy: 0.0555WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0131s). Check your callbacks.\n",
            "1944/1944 [==============================] - 162s 84ms/step - loss: 2.9400 - accuracy: 0.0555 - val_loss: 2.8922 - val_accuracy: 0.0534\n",
            "Epoch 2/50\n",
            "1944/1944 [==============================] - 162s 83ms/step - loss: 2.8921 - accuracy: 0.0544 - val_loss: 2.8912 - val_accuracy: 0.0563\n",
            "Epoch 3/50\n",
            "1944/1944 [==============================] - 162s 83ms/step - loss: 2.8919 - accuracy: 0.0558 - val_loss: 2.8908 - val_accuracy: 0.0566\n",
            "Epoch 4/50\n",
            "1944/1944 [==============================] - 162s 84ms/step - loss: 2.8917 - accuracy: 0.0551 - val_loss: 2.8924 - val_accuracy: 0.0554\n",
            "Epoch 5/50\n",
            "1944/1944 [==============================] - 162s 83ms/step - loss: 2.8917 - accuracy: 0.0549 - val_loss: 2.8917 - val_accuracy: 0.0566\n",
            "Epoch 6/50\n",
            "1944/1944 [==============================] - 162s 83ms/step - loss: 2.8917 - accuracy: 0.0551 - val_loss: 2.8910 - val_accuracy: 0.0554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc90d12e6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmHRdvjCjXwn",
        "outputId": "fbec26c7-0052-464a-e715-ecc58ec17e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(dataset.x_test, dataset.y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "415/415 [==============================] - 6s 14ms/step - loss: 2.8849 - accuracy: 0.0083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.884892225265503, 0.008283756673336029]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZZ04ARe4Kv"
      },
      "source": [
        "pred = np.argmax(model.predict(dataset.x_test), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbbiUTk_6D5y"
      },
      "source": [
        "# Model 2 / 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moSF_LORo7u3",
        "outputId": "60854705-9321-4d3e-e1fd-abcfe3ef69cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is responsible for early stopping as was recommended\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model2 = models.Sequential()\n",
        "\n",
        "model2.add(layers.Embedding(len(dataset.vocabulary), output_dim=32, input_length=200))\n",
        "model2.add(layers.Reshape(target_shape=(200, 32, 1)))\n",
        "model2.add(layers.Conv2D(kernel_size=2, filters=32, padding='same', activation='relu', strides=1))\n",
        "model2.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model2.add(layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', strides=1))\n",
        "model2.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(200, activation='relu'))\n",
        "model2.add(layers.Dense(18, activation='softmax')) \n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 32)           141664    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 200, 32, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 200, 32, 32)       160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 200, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 200, 32, 128)      36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 200, 32, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 819200)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               163840200 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 18)                3618      \n",
            "=================================================================\n",
            "Total params: 164,022,634\n",
            "Trainable params: 164,022,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_oxSofKo7vQ",
        "outputId": "8ba56248-3224-4a5d-be3d-974072d5330e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.fit(x = dataset.x_train, y = dataset.y_train, batch_size = 50, verbose=1, epochs=50, validation_data=(dataset.x_val, dataset.y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1944/1944 [==============================] - ETA: 0s - loss: 1.0090 - accuracy: 0.6815WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
            "1944/1944 [==============================] - 175s 90ms/step - loss: 1.0090 - accuracy: 0.6815 - val_loss: 0.5269 - val_accuracy: 0.8444\n",
            "Epoch 2/50\n",
            "1944/1944 [==============================] - 172s 89ms/step - loss: 0.4155 - accuracy: 0.8735 - val_loss: 0.3453 - val_accuracy: 0.8911\n",
            "Epoch 3/50\n",
            "1944/1944 [==============================] - 172s 89ms/step - loss: 0.2778 - accuracy: 0.9176 - val_loss: 0.2710 - val_accuracy: 0.9230\n",
            "Epoch 4/50\n",
            "1944/1944 [==============================] - 172s 88ms/step - loss: 0.2004 - accuracy: 0.9398 - val_loss: 0.1936 - val_accuracy: 0.9435\n",
            "Epoch 5/50\n",
            "1944/1944 [==============================] - 171s 88ms/step - loss: 0.1495 - accuracy: 0.9551 - val_loss: 0.1649 - val_accuracy: 0.9529\n",
            "Epoch 6/50\n",
            "1944/1944 [==============================] - 171s 88ms/step - loss: 0.1149 - accuracy: 0.9659 - val_loss: 0.1755 - val_accuracy: 0.9515\n",
            "Epoch 7/50\n",
            "1944/1944 [==============================] - 171s 88ms/step - loss: 0.0901 - accuracy: 0.9732 - val_loss: 0.1237 - val_accuracy: 0.9653\n",
            "Epoch 8/50\n",
            "1944/1944 [==============================] - 171s 88ms/step - loss: 0.0701 - accuracy: 0.9784 - val_loss: 0.1237 - val_accuracy: 0.9648\n",
            "Epoch 9/50\n",
            "1944/1944 [==============================] - 171s 88ms/step - loss: 0.0557 - accuracy: 0.9834 - val_loss: 0.1111 - val_accuracy: 0.9741\n",
            "Epoch 10/50\n",
            "1944/1944 [==============================] - 171s 88ms/step - loss: 0.0456 - accuracy: 0.9866 - val_loss: 0.1139 - val_accuracy: 0.9741\n",
            "Epoch 11/50\n",
            "1944/1944 [==============================] - 170s 88ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 0.1041 - val_accuracy: 0.9758\n",
            "Epoch 12/50\n",
            "1944/1944 [==============================] - 170s 88ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.1037 - val_accuracy: 0.9764\n",
            "Epoch 13/50\n",
            "1944/1944 [==============================] - 170s 87ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0990 - val_accuracy: 0.9801\n",
            "Epoch 14/50\n",
            "1944/1944 [==============================] - 170s 88ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.1077 - val_accuracy: 0.9801\n",
            "Epoch 15/50\n",
            "1944/1944 [==============================] - 170s 87ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.1104 - val_accuracy: 0.9788\n",
            "Epoch 16/50\n",
            "1944/1944 [==============================] - 170s 87ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1160 - val_accuracy: 0.9798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc90d21ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmxOVDhZo7va",
        "outputId": "3c579590-81f9-4b45-8d84-736984799825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.evaluate(dataset.x_test, dataset.y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "415/415 [==============================] - 6s 14ms/step - loss: 1.2013 - accuracy: 0.8471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2013276815414429, 0.847051739692688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6KzgXo6p7Zr"
      },
      "source": [
        "pred2 = np.argmax(model2.predict(dataset.x_test), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu03PG2b6Gz6"
      },
      "source": [
        "# Model 3 / 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih3M5c6W59Rz",
        "outputId": "39466d3e-0aa4-4f66-a947-5f3b09c9c051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is responsible for early stopping as was recommended\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model3 = models.Sequential()\n",
        "\n",
        "model3.add(layers.Embedding(len(dataset.vocabulary), output_dim=32, input_length=200))\n",
        "model3.add(layers.Reshape(target_shape=(200, 32, 1)))\n",
        "model3.add(layers.Conv2D(kernel_size=2, filters=32, padding='same', activation='relu', strides=1))\n",
        "#model3.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model3.add(layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', strides=1))\n",
        "#model3.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model3.add(layers.Flatten())\n",
        "model3.add(layers.Dense(200, activation='relu'))\n",
        "model3.add(layers.Dense(18, activation='softmax')) \n",
        "\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 200, 32)           141664    \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 200, 32, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 200, 32, 32)       160       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 200, 32, 128)      36992     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 819200)            0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 200)               163840200 \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 18)                3618      \n",
            "=================================================================\n",
            "Total params: 164,022,634\n",
            "Trainable params: 164,022,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1x923NG59Sj",
        "outputId": "e3b6292f-180b-47d9-e683-50028f26ca50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model3.fit(x = dataset.x_train, y = dataset.y_train, batch_size = 50, verbose=1, epochs=50, validation_data=(dataset.x_val, dataset.y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1944/1944 [==============================] - ETA: 0s - loss: 0.8676 - accuracy: 0.7320WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
            "1944/1944 [==============================] - 157s 81ms/step - loss: 0.8676 - accuracy: 0.7320 - val_loss: 0.3686 - val_accuracy: 0.8899\n",
            "Epoch 2/50\n",
            "1944/1944 [==============================] - 155s 80ms/step - loss: 0.2649 - accuracy: 0.9221 - val_loss: 0.2170 - val_accuracy: 0.9390\n",
            "Epoch 3/50\n",
            "1944/1944 [==============================] - 155s 80ms/step - loss: 0.1543 - accuracy: 0.9538 - val_loss: 0.1680 - val_accuracy: 0.9531\n",
            "Epoch 4/50\n",
            "1944/1944 [==============================] - 155s 80ms/step - loss: 0.0989 - accuracy: 0.9701 - val_loss: 0.1472 - val_accuracy: 0.9615\n",
            "Epoch 5/50\n",
            "1944/1944 [==============================] - 155s 80ms/step - loss: 0.0693 - accuracy: 0.9794 - val_loss: 0.1136 - val_accuracy: 0.9696\n",
            "Epoch 6/50\n",
            "1944/1944 [==============================] - 155s 79ms/step - loss: 0.0455 - accuracy: 0.9866 - val_loss: 0.1169 - val_accuracy: 0.9728\n",
            "Epoch 7/50\n",
            "1944/1944 [==============================] - 154s 79ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.1165 - val_accuracy: 0.9749\n",
            "Epoch 8/50\n",
            "1944/1944 [==============================] - 154s 79ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.1237 - val_accuracy: 0.9762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc90c66e208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sAr1SNN59Sx",
        "outputId": "4b1c3041-dd14-4fae-f69b-7c841018af73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model3.evaluate(dataset.x_test, dataset.y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "415/415 [==============================] - 5s 13ms/step - loss: 1.1168 - accuracy: 0.8431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1167963743209839, 0.8431357741355896]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4GCr0es59S8",
        "outputId": "0dfb2540-c1f8-4958-de05-4572b4a5d8fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred3 = np.argmax(model3.predict(dataset.x_test), axis=-1)\n",
        "pred3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 17,  2, ...,  3,  7, 17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoJ6DIns6JaR"
      },
      "source": [
        "# Model 4 / 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8eUHPcjCn46",
        "outputId": "4642903c-54af-41ce-d4c3-2003f96a017d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is responsible for early stopping as was recommended\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model4 = models.Sequential()\n",
        "\n",
        "model4.add(layers.Embedding(len(dataset.vocabulary), output_dim=32, input_length=200))\n",
        "model4.add(layers.Reshape(target_shape=(200, 32, 1)))\n",
        "model4.add(layers.Conv2D(kernel_size=5, filters=32, padding='same', activation='relu', strides=1))\n",
        "#model4.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model4.add(layers.Conv2D(kernel_size=5, filters=128, padding='same', activation='relu', strides=1))\n",
        "#model4.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model4.add(layers.Flatten())\n",
        "model4.add(layers.Dense(200, activation='relu'))\n",
        "model4.add(layers.Dense(18, activation='softmax')) \n",
        "\n",
        "model4.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 200, 32)           141664    \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 200, 32, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 200, 32, 32)       832       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 200, 32, 128)      102528    \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 819200)            0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 200)               163840200 \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 18)                3618      \n",
            "=================================================================\n",
            "Total params: 164,088,842\n",
            "Trainable params: 164,088,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLj0lscdCn6N",
        "outputId": "8b8a03b1-e25f-4ee6-83b0-b023fedf88f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model4.fit(x = dataset.x_train, y = dataset.y_train, batch_size = 50, verbose=1, epochs=50, validation_data=(dataset.x_val, dataset.y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1944/1944 [==============================] - ETA: 0s - loss: 0.8954 - accuracy: 0.7139WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0193s). Check your callbacks.\n",
            "1944/1944 [==============================] - 190s 98ms/step - loss: 0.8954 - accuracy: 0.7139 - val_loss: 0.4571 - val_accuracy: 0.8626\n",
            "Epoch 2/50\n",
            "1944/1944 [==============================] - 189s 97ms/step - loss: 0.3341 - accuracy: 0.9012 - val_loss: 0.2629 - val_accuracy: 0.9220\n",
            "Epoch 3/50\n",
            "1944/1944 [==============================] - 188s 97ms/step - loss: 0.1933 - accuracy: 0.9433 - val_loss: 0.1830 - val_accuracy: 0.9456\n",
            "Epoch 4/50\n",
            "1944/1944 [==============================] - 187s 96ms/step - loss: 0.1209 - accuracy: 0.9640 - val_loss: 0.1334 - val_accuracy: 0.9631\n",
            "Epoch 5/50\n",
            "1944/1944 [==============================] - 187s 96ms/step - loss: 0.0783 - accuracy: 0.9767 - val_loss: 0.1173 - val_accuracy: 0.9665\n",
            "Epoch 6/50\n",
            "1944/1944 [==============================] - 187s 96ms/step - loss: 0.0532 - accuracy: 0.9841 - val_loss: 0.1056 - val_accuracy: 0.9747\n",
            "Epoch 7/50\n",
            "1944/1944 [==============================] - 187s 96ms/step - loss: 0.0351 - accuracy: 0.9904 - val_loss: 0.0990 - val_accuracy: 0.9775\n",
            "Epoch 8/50\n",
            "1944/1944 [==============================] - 187s 96ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0966 - val_accuracy: 0.9781\n",
            "Epoch 9/50\n",
            "1944/1944 [==============================] - 186s 96ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.1025 - val_accuracy: 0.9794\n",
            "Epoch 10/50\n",
            "1944/1944 [==============================] - 186s 96ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.0956 - val_accuracy: 0.9838\n",
            "Epoch 11/50\n",
            "1944/1944 [==============================] - 187s 96ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.1247 - val_accuracy: 0.9776\n",
            "Epoch 12/50\n",
            "1944/1944 [==============================] - 186s 96ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.1080 - val_accuracy: 0.9819\n",
            "Epoch 13/50\n",
            "1944/1944 [==============================] - 186s 96ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1061 - val_accuracy: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc90cdf0748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpR1Oij1Cn7T",
        "outputId": "c969ed04-d9e3-4ef0-c58c-00c3ebfaedbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model4.evaluate(dataset.x_test, dataset.y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "415/415 [==============================] - 8s 19ms/step - loss: 1.3276 - accuracy: 0.8464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3275991678237915, 0.8464492559432983]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtJ3ke9u6Mbj"
      },
      "source": [
        "# Model 5 / 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PPh70a9nfZM",
        "outputId": "6d4b3627-74c0-43f7-a72e-b662782943b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this is responsible for early stopping as was recommended\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model5 = models.Sequential()\n",
        "\n",
        "model5.add(layers.Embedding(len(dataset.vocabulary), output_dim=32, input_length=200))\n",
        "model5.add(layers.Reshape(target_shape=(200, 32, 1)))\n",
        "model5.add(layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', strides=1))\n",
        "model5.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model5.add(layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', strides=1))\n",
        "model5.add(layers.MaxPool2D(strides=1, padding='same'))\n",
        "model5.add(layers.Flatten())\n",
        "model5.add(layers.Dense(200, activation='relu'))\n",
        "model5.add(layers.Dense(18, activation='softmax')) \n",
        "\n",
        "model5.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 32)           142208    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 200, 32, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 200, 32, 32)       320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 200, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 200, 32, 128)      36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 200, 32, 128)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 819200)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               163840200 \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 18)                3618      \n",
            "=================================================================\n",
            "Total params: 164,023,338\n",
            "Trainable params: 164,023,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdQ-cGiknfZv",
        "outputId": "a0266b36-9362-4ae5-e7e5-b57eb0a23e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model5.fit(x = dataset.x_train, y = dataset.y_train, batch_size = 100, verbose=1, epochs=50, validation_data=(dataset.x_val, dataset.y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "972/972 [==============================] - ETA: 0s - loss: 1.2713 - accuracy: 0.5921WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0497s). Check your callbacks.\n",
            "972/972 [==============================] - 231s 237ms/step - loss: 1.2713 - accuracy: 0.5921 - val_loss: 0.7764 - val_accuracy: 0.7365\n",
            "Epoch 2/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.6014 - accuracy: 0.8110 - val_loss: 0.4643 - val_accuracy: 0.8569\n",
            "Epoch 3/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.4130 - accuracy: 0.8742 - val_loss: 0.3478 - val_accuracy: 0.8956\n",
            "Epoch 4/50\n",
            "972/972 [==============================] - 230s 236ms/step - loss: 0.3069 - accuracy: 0.9077 - val_loss: 0.2812 - val_accuracy: 0.9137\n",
            "Epoch 5/50\n",
            "972/972 [==============================] - 230s 236ms/step - loss: 0.2387 - accuracy: 0.9280 - val_loss: 0.2240 - val_accuracy: 0.9365\n",
            "Epoch 6/50\n",
            "972/972 [==============================] - 230s 236ms/step - loss: 0.1917 - accuracy: 0.9416 - val_loss: 0.1883 - val_accuracy: 0.9444\n",
            "Epoch 7/50\n",
            "972/972 [==============================] - 230s 236ms/step - loss: 0.1545 - accuracy: 0.9534 - val_loss: 0.1646 - val_accuracy: 0.9506\n",
            "Epoch 8/50\n",
            "972/972 [==============================] - 230s 236ms/step - loss: 0.1251 - accuracy: 0.9627 - val_loss: 0.1513 - val_accuracy: 0.9560\n",
            "Epoch 9/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.1012 - accuracy: 0.9695 - val_loss: 0.1478 - val_accuracy: 0.9625\n",
            "Epoch 10/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0828 - accuracy: 0.9752 - val_loss: 0.1468 - val_accuracy: 0.9597\n",
            "Epoch 11/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0685 - accuracy: 0.9796 - val_loss: 0.1465 - val_accuracy: 0.9606\n",
            "Epoch 12/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0574 - accuracy: 0.9828 - val_loss: 0.1195 - val_accuracy: 0.9708\n",
            "Epoch 13/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0470 - accuracy: 0.9859 - val_loss: 0.1176 - val_accuracy: 0.9736\n",
            "Epoch 14/50\n",
            "972/972 [==============================] - 231s 237ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.1243 - val_accuracy: 0.9730\n",
            "Epoch 15/50\n",
            "972/972 [==============================] - 231s 237ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.1207 - val_accuracy: 0.9763\n",
            "Epoch 16/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.1155 - val_accuracy: 0.9783\n",
            "Epoch 17/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.1180 - val_accuracy: 0.9779\n",
            "Epoch 18/50\n",
            "972/972 [==============================] - 230s 237ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.1266 - val_accuracy: 0.9773\n",
            "Epoch 19/50\n",
            "972/972 [==============================] - 231s 237ms/step - loss: 0.0185 - accuracy: 0.9950 - val_loss: 0.1272 - val_accuracy: 0.9794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f09655befd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ZmkycWnfZ5",
        "outputId": "2fcb3635-37ae-45e2-a2d8-475f957e85ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model5.evaluate(dataset.x_test, dataset.y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "415/415 [==============================] - 15s 35ms/step - loss: 1.2893 - accuracy: 0.8602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2892601490020752, 0.8601551055908203]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cB2HdMpUjJt"
      },
      "source": [
        "# Create Confusion Matrix\n",
        "\n",
        "We created the confusion matrix for model 4. We create two different confusion matrices to be able to see which labels get confused most often. All of the interpretation can be found in the lab report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUwonGkGCn76",
        "outputId": "6d9a4013-a62e-4c5c-9bcf-1200d53e269f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred4 = np.argmax(model4.predict(dataset.x_test), axis=-1)\n",
        "pred4.tolist() # the labels that we got from the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 17,  2, ..., 12,  7, 17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWr5uYVpAKMR",
        "outputId": "9fe98b1a-91c5-4116-fab0-116c715e08f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.array(dataset.test_labels_numbers) # the actual labels in numbers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 17,  2, ...,  3,  7, 17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySe3RqzQuF1g"
      },
      "source": [
        "true_labels = dataset.test_labels_numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AemK_NxKCYdm",
        "outputId": "dd4d8851-0155-4377-897b-ef0b8fe3ce39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.labels_encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ar',\n",
              " 'de',\n",
              " 'en',\n",
              " 'es',\n",
              " 'fr',\n",
              " 'id',\n",
              " 'it',\n",
              " 'ja',\n",
              " 'ko',\n",
              " 'ms',\n",
              " 'nl',\n",
              " 'other',\n",
              " 'pt',\n",
              " 'ru',\n",
              " 'th',\n",
              " 'tl',\n",
              " 'tr',\n",
              " 'und']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOQzbMtuQjjX"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLXF43HWrcyT"
      },
      "source": [
        "mapping the classes to their number representation that we created in the dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dccowc_8t6jS"
      },
      "source": [
        "labels = {}\n",
        "for idx, label in enumerate(dataset.labels_encoded):\n",
        "    labels[str(idx)] = label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcdaqilrrXsD"
      },
      "source": [
        "Converting the classes in the list to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGY24aouRfkZ"
      },
      "source": [
        "p4 = pred4.tolist()\n",
        "for idx, c in enumerate(p4):\n",
        "    p4[idx] = labels[str(c)]\n",
        "\n",
        "for idx, c in enumerate(true_labels):\n",
        "    true_labels[idx] = labels[str(c)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfhflG8Arsn7"
      },
      "source": [
        "It is difficult to properly interpret the figures as they use the numbers instead of the labels, but we can see that not many classes got confused in general. Below we have a solution to be able to interpret it better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcOGc0UFQhnm",
        "outputId": "9e8824e4-8e8c-4a7c-d0a0-7f45c6b3ec9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "conf_mx = confusion_matrix(true_labels, p4, labels=dataset.labels_encoded)\n",
        "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAO50lEQVR4nO3df8ydZX3H8feHPjxFigiMiULZqotIlKmYalDmBmIM08b6x7Jo5oLThGg2RcNmUJOZ/TWjxh/JFkkDKJmExSCiwV8wZjRLJg6xKtBOnVYsgsW4iVFp6dPv/jinW62n7XPOue9zTnu9X0nT8+M+1/c6z4/Pc933ue/rSlUhqV3HzbsDkubLEJAaZwhIjTMEpMYZAlLjDAGpcXMPgSSXJvnPJN9NclUP7Z+d5ItJ7ktyb5Iruq4xrLMmydeT3NpT+6ckuSnJ9iTbkryghxpvHX6N7klyY5ITOmjzuiS7ktxzwGOnJbk9yXeG/5/aQ433Dr9W30zyySSndF3jgOeuTFJJTu+6/SRvGr6Pe5O8Z9L2D2euIZBkDfCPwB8DzwBeneQZHZfZC1xZVc8ALgD+socaAFcA23pod78PAZ+vqnOBZ3ddK8lZwJuBjVV1HrAGeFUHTX8UuPSgx64C7qiqpwF3DO93XeN24LyqehbwbeDtPdQgydnAS4H7u24/ycXAZuDZVfVM4H1T1hhp3iOB5wPfrarvVdUe4J8ZvOnOVNWDVXX38PbPGfzynNVljSTrgZcD13TZ7gHtPwH4Q+BagKraU1X/00OpJeBxSZaAE4EfTdtgVX0Z+OlBD28Grh/evh54Zdc1quq2qto7vPsVYH3XNYY+ALwNmOqsu0O0/0bg3VW1e7jNrmlqHMq8Q+As4IcH3N9Jx7+gB0qyATgfuLPjpj/I4AdhX8ft7vcU4GHgI8NdjmuSrOuyQFU9wOAvzf3Ag8DPquq2Lmsc4IyqenB4+yHgjJ7q7Pc64HNdN5pkM/BAVX2j67aHzgFelOTOJF9K8rw+isw7BGYmyUnAJ4C3VNUjHba7CdhVVV/rqs0RloDnAh+uqvOBXzD9EPrXDPfLNzMInDOBdUle02WNUWpw3npv564neSeDXcIbOm73ROAdwN922e5BloDTGOzG/g3w8STpusi8Q+AB4OwD7q8fPtapJMczCIAbqurmjpu/EHhFkh0MdmdenORjHdfYCeysqv0jmJsYhEKXXgJ8v6oerqrHgJuBF3ZcY78fJ3kywPD/Xoa5SV4LbAL+rLq/SOb3GATmN4bf+/XA3Ume1GGNncDNNfBVBiPNiQ8+Hsq8Q+A/gKcleUqSZQYHoj7dZYFhcl4LbKuq93fZNkBVvb2q1lfVBgb9/9eq6vQvaFU9BPwwydOHD10C3NdlDQa7ARckOXH4NbuE/g50fhq4bHj7MuBTXRdIcimDXbRXVNUvu26/qr5VVU+sqg3D7/1O4LnD71VXbgEuBkhyDrAM/KTD9geqaq7/gJcxOHr7X8A7e2j/DxgMN78JbB3+e1lP7+Ui4Nae2n4OcNfwfdwCnNpDjb8DtgP3AP8ErO2gzRsZHGN4jMEvyuuB32LwqcB3gH8BTuuhxncZHG/a/z2/uusaBz2/Azi94/ewDHxs+P24G3hxHz9bGXZAUqPmvTsgac4MAalxhoDUOENAapwhIDVuIUIgyeXWWIwax8J7sMZ4FiIEgN7fqDUWpn1rLFiNRQkBSXMy05OF1qxZU0tLS7/x+MrKCmvWrPmNx/fs2TOLbklNqKqRFx/95m9kj5aWljjzzDNXvf2OHTv664wkYMrdgb6nBpPUv4lDYEZTg0nq2TQjgd6nBpPUv2lCYKZTg0nqR+8HBocnO1wOjPwEQNJ8TTMSWNXUYFW1pao2VtVGQ0BaPNOEQO9Tg0nq38S7A1W1N8lfAV9gsFDFdVV1b2c9kzQTUx0TqKrPAp/tqC+S5mCmpw0nGavYJFOsO2eiNNqhThv2AiKpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNW6mU46Pa5KLgcZ9zUknnTR2jd27d4+1/XHHjZ+1x8KaC5NcADauSb62KysrPfTk14373if5WV+3bt2qt/3Vr351yOccCUiNMwSkxk2z7sDZSb6Y5L4k9ya5osuOSZqNaY4J7AWurKq7kzwe+FqS26vqvo76JmkGJh4JVNWDVXX38PbPgW247oB01OnkmECSDcD5wJ1dtCdpdqb+iDDJScAngLdU1SMjnv+/xUckLZ6pJhpNcjxwK/CFqnr/KrbvfRZQzxNYHJ4nsHqzOE9gZWWl24lGM3iX1wLbVhMAkhbTNMcELgT+HHhxkq3Dfy/rqF+SZmSaFYj+Deh/vCepVwu9+MiENcbaftOmTWPX+MxnPjPW9vv27Ru7hlZn7dq1Y79m3GM6i2qc4yH79u1z8RFJoxkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1Lhj7gKicU0yKcXy8vJY2z/66KNj19DqTDJxySx/5heJFxBJGskQkBo3dQgkWZPk60lu7aJDkmari5HAFQzWHJB0FJoqBJKsB14OXNNNdyTN2rQjgQ8CbwOcP0s6Sk0z5fgmYFdVfe0I212e5K4kd01aS1J/Jj5PIMnfM5hyfC9wAnAycHNVveYwr1m4D2g9T+Do5nkCq3eo8wQ6OVkoyUXAX1fVYafuNQTUNUNg9TxZSNJInjbsSOCo5khg9XrdHVitWYTAuL/Us1gY5Nxzzx37Ndu3b++hJ8eeRQ2BWSxIumbNmlVvu7Ky4u6ApNEMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGrcMXcB0bgW9QKURbwQSkc3LyCSNJIhIDVu2inHT0lyU5LtSbYleUFXHZM0G0tTvv5DwOer6k+SLAMndtAnSTM0zWzDTwC2Ak+tVTbigcHV88CgutbHgcGnAA8DHxmuRXhNknVTtCdpDqYJgSXgucCHq+p84BfAVQdv5OIj0mKbZnfgScBXqmrD8P6LgKuq6uWHeY27A6vk7oC61vnuQFU9BPwwydOHD10C3Ddpe5LmY6ozBpM8h8GKxMvA94C/qKr/Psz2jgRWyZGAutbMugPjMgTUikOFwLTnCRz1FnU1mnF/qa+++uqxa7zhDW8Y+zVaHOP8ATvcz7mnDUuNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcc1fRdiy5eXlsbbfs2dPTz3RLLj4iKSRDAGpcdMuPvLWJPcmuSfJjUlO6KpjkmZj4hBIchbwZmBjVZ0HrAFe1VXHJM3GtLsDS8DjkiwxWH3oR9N3SdIsTTPb8APA+4D7gQeBn1XVbV11TNJsTLM7cCqwmcFKRGcC65K8ZsR2Lj4iLbBpdgdeAny/qh6uqseAm4EXHrxRVW2pqo1VtXGKWpJ6Mk0I3A9ckOTEDKY9vQTY1k23JM3KNMcE7gRuAu4GvjVsa0tH/ZI0I5423DBPG26LKxDN0aKucqS2eO2ApJEMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1LileXegBV4HoEXmSEBqnCEgNe6IIZDkuiS7ktxzwGOnJbk9yXeG/5/abzcl9WU1I4GPApce9NhVwB1V9TTgjuF9SUehI4ZAVX0Z+OlBD28Grh/evh54Zcf9kjQjkx4TOKOqHhzefgg4o6P+SJqxqT8irKo63LRhSS4HLp+2jqR+TDoS+HGSJwMM/991qA1dd0BabJOGwKeBy4a3LwM+1U13JM3aEWcbTnIjcBFwOvBj4F3ALcDHgd8BfgD8aVUdfPBwVFueOifNiVOOS41zynFJIxkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGpc84uPrF27duzX7N69u4eeaBIbNmwY+zU7duzovB/zkIy8KHCkw10t7EhAapwhIDVu0sVH3ptke5JvJvlkklP67aakvky6+MjtwHlV9Szg28DbO+6XpBmZaPGRqrqtqvYO734FWN9D3yTNQBfHBF4HfK6DdiTNwVQfESZ5J7AXuOEw27j4iLTAJg6BJK8FNgGX1GE+hKyqLcCW4WucbVhaMBOFQJJLgbcBf1RVv+y2S5JmaTUfEd4I/Dvw9CQ7k7we+Afg8cDtSbYmubrnfkrqyRFHAlX16hEPX9tDXyTNgWcMSo1zGTI15+STTx5r+0ceeaSnnsyWy5BJGskQkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjfPaAekIlpeXx37Nnj17eujJdLx2QNJIhoDUuIkWHznguSuTVJLT++mepL5NuvgISc4GXgrc33GfJM3QRIuPDH2AwWSjHuyTjmITHRNIshl4oKq+0XF/JM3Y2FOOJzkReAeDXYHVbO/iI9ICW9V5Akk2ALdW1XlJfh+4A9i/3sB64EfA86vqoSO0466DjjrH+nkCY48EqupbwBP330+yA9hYVT+ZuHeS5mbSxUckHSM8bVg6gmN9d8AzBqXGORKYgWRkAB/WLL8v6t5xx43393Xfvn099eT/ORKQNJIhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGjf2fAIan9cBtGfcawFOOOGEsWs8+uijY79mFEcCUuMMAalxEy8+kuRNSbYnuTfJe/rroqQ+TbT4SJKLgc3As6vqmcD7uu+apFmYdPGRNwLvrqrdw2129dA3STMw6TGBc4AXJbkzyZeSPK/LTkmanUk/IlwCTgMuAJ4HfDzJU2vEZ2EuPiIttklHAjuBm2vgq8A+YOTKxFW1pao2VtXGSTspqT+ThsAtwMUASc4BlgEXH5GOQkfcHRguPnIRcHqSncC7gOuA64YfG+4BLhu1KyBp8TnluLQAZnHasFOOSxrpmLuA6Pjjjx9r+0lGQisrK2Ntv7Q0/pf5scceG/s1x4Jxv1bjfi9gMS/omuRioAsvvHDV227duvWQzzkSkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMbN+irCh4EfjHjqdPqfj8Aai9G+NeZT43er6rdHPTHTEDiUJHf1PfOQNRajfWssXg13B6TGGQJS4xYlBLZYY2FqHAvvwRpjWIhjApLmZ1FGApLmxBCQGmcISI0zBKTGGQJS4/4XcPAl+EDW2owAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5zLyJpFSyev"
      },
      "source": [
        "def create_better_confusion_matrix(pred, true):\n",
        "    conf_mx = confusion_matrix(true, pred, labels=dataset.labels_encoded, normalize=\"true\")\n",
        "    np.fill_diagonal(conf_mx, 0)\n",
        "    \n",
        "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "    plt.show()\n",
        "    \n",
        "    return conf_mx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm5Tlh48T_yv",
        "outputId": "29c64737-6900-4fc9-f475-38ff08b76fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "ncm = create_better_confusion_matrix(p4, true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8t9xUVsUxoU"
      },
      "source": [
        "As the above matrices are not very clear because they use the numbers instead of the class labels we created the following fucntion:\n",
        "The following function enabels us to see which label got confused with which other how many times (as percentage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azd8ou2BTBt6",
        "outputId": "320b0f1d-5896-4fcb-9693-f3c04c0b2ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for ind, label in enumerate(dataset.labels_encoded):\n",
        "    most = dataset.labels_encoded[np.argmax(ncm[ind, :])]\n",
        "    val = np.max(ncm[ind, :])\n",
        "    print(f'{label}\\t~~\\t{most}\\t({val*100:.2f}%)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ar\t~~\tko\t(0.19%)\n",
            "de\t~~\ten\t(18.00%)\n",
            "en\t~~\tund\t(3.89%)\n",
            "es\t~~\tpt\t(7.59%)\n",
            "fr\t~~\tes\t(14.29%)\n",
            "id\t~~\tund\t(6.12%)\n",
            "it\t~~\tes\t(25.00%)\n",
            "ja\t~~\tund\t(1.17%)\n",
            "ko\t~~\tund\t(5.45%)\n",
            "ms\t~~\tid\t(67.74%)\n",
            "nl\t~~\ten\t(27.91%)\n",
            "other\t~~\tar\t(0.00%)\n",
            "pt\t~~\tes\t(17.02%)\n",
            "ru\t~~\tund\t(0.82%)\n",
            "th\t~~\tar\t(0.00%)\n",
            "tl\t~~\tid\t(29.21%)\n",
            "tr\t~~\tid\t(8.62%)\n",
            "und\t~~\ten\t(6.79%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXqPJA5_u-Vp"
      },
      "source": [
        "# TALOS\n",
        "in this part we use talos to search for the best model and create the heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4pj4waqCEnX",
        "outputId": "d09470b6-9afc-409f-c703-b454d65adea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -c 'import talos' || pip install talos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-11-06 14:39:16.282067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP41wqiNvHQ7"
      },
      "source": [
        "in the following cells we set up the model and the parameters for talos to use, note that the model is exactly the same as the models above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKCy3ONILsW7"
      },
      "source": [
        "from talos import Scan\n",
        "from talos import Reporting\n",
        "from tensorflow.keras import callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyeWXeWQgGpX"
      },
      "source": [
        "callback = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto',\n",
        "    baseline=None, restore_best_weights=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhvcMIT0-WmK"
      },
      "source": [
        "p = {'optimizer': ['Adam', 'RMSprop'],\n",
        "     'batch_size': [100],\n",
        "     'strides': [1],\n",
        "     'padding': ['same'],\n",
        "     'kernel_size': [2, 3],\n",
        "     'filters': [32, 64, 128],\n",
        "     'epochs': [30]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_-D84uH-E8V"
      },
      "source": [
        "def model(x_train, y_train, x_val, y_val, params):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Embedding(len(dataset.vocabulary),\n",
        "                            output_dim=32, input_length=200))\n",
        "    model.add(layers.Reshape(target_shape=(200, 32, 1)))\n",
        "    model.add(layers.Conv2D(activation='relu',\n",
        "                            strides=params['strides'], \n",
        "                            padding=params['padding'],\n",
        "                            kernel_size=params['kernel_size'],\n",
        "                            filters=params['filters']\n",
        "                            ))\n",
        "    model.add(layers.MaxPool2D(strides=params['strides'], \n",
        "                            padding=params['padding'],))\n",
        "    model.add(layers.Conv2D(activation='relu',\n",
        "                            strides=params['strides'], \n",
        "                            padding=params['padding'],\n",
        "                            kernel_size=params['kernel_size'],\n",
        "                            filters=params['filters']\n",
        "                            ))\n",
        "    model.add(layers.MaxPool2D(strides=params['strides'], \n",
        "                            padding=params['padding'],))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(200, activation='relu'))\n",
        "    model.add(layers.Dense(18, activation='softmax'))\n",
        "\n",
        "    \n",
        "    model.compile(optimizer=params['optimizer'], \n",
        "                            loss='categorical_crossentropy', \n",
        "                            metrics=['accuracy'],)\n",
        "    \n",
        "    history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    batch_size=params['batch_size'],\n",
        "                    epochs=params['epochs'],\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[callback])\n",
        "    \n",
        "    \n",
        "    return history, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqG-4PCt-E82",
        "outputId": "8f4034b0-b6a3-482d-97df-d25c29187abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scan = Scan(dataset.x_train, \n",
        "     dataset.y_train, \n",
        "     model=model, \n",
        "     params=p,\n",
        "     print_params=True, \n",
        "     reduction_metric=\"val_loss\",\n",
        "     experiment_name='lang_class',\n",
        "     x_val=dataset.x_val,\n",
        "     y_val=dataset.y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 32, 'kernel_size': 2, 'optimizer': 'Adam', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.8183WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
            "972/972 [==============================] - 44s 45ms/step - loss: 0.5836 - accuracy: 0.8183 - val_loss: 0.2049 - val_accuracy: 0.9401\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 44s 45ms/step - loss: 0.1306 - accuracy: 0.9615 - val_loss: 0.1040 - val_accuracy: 0.9709\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 45s 46ms/step - loss: 0.0645 - accuracy: 0.9801 - val_loss: 0.0910 - val_accuracy: 0.9762\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 45s 46ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.0865 - val_accuracy: 0.9803\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 46s 47ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.0971 - val_accuracy: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 1/12 [03:51<42:30, 231.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 32, 'kernel_size': 2, 'optimizer': 'RMSprop', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.7851WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_test_batch_end` time: 0.0075s). Check your callbacks.\n",
            "972/972 [==============================] - 55s 57ms/step - loss: 0.6796 - accuracy: 0.7851 - val_loss: 0.2071 - val_accuracy: 0.9367\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 55s 57ms/step - loss: 0.1423 - accuracy: 0.9567 - val_loss: 0.1188 - val_accuracy: 0.9683\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 55s 57ms/step - loss: 0.0664 - accuracy: 0.9798 - val_loss: 0.1050 - val_accuracy: 0.9750\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 55s 57ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.0970 - val_accuracy: 0.9806\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 55s 57ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1019 - val_accuracy: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 2/12 [08:29<40:56, 245.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'optimizer': 'Adam', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.7838WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
            "972/972 [==============================] - 49s 51ms/step - loss: 0.6752 - accuracy: 0.7838 - val_loss: 0.2057 - val_accuracy: 0.9422\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 50s 51ms/step - loss: 0.1232 - accuracy: 0.9620 - val_loss: 0.1418 - val_accuracy: 0.9583\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 50s 51ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0974 - val_accuracy: 0.9744\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 50s 51ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 0.0942 - val_accuracy: 0.9793\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 50s 51ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0917 - val_accuracy: 0.9822\n",
            "Epoch 6/30\n",
            "972/972 [==============================] - 50s 51ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.1102 - val_accuracy: 0.9806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 3/12 [13:30<39:18, 262.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'optimizer': 'RMSprop', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.7908WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
            "972/972 [==============================] - 57s 59ms/step - loss: 0.6584 - accuracy: 0.7908 - val_loss: 0.1869 - val_accuracy: 0.9425\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 57s 58ms/step - loss: 0.1254 - accuracy: 0.9620 - val_loss: 0.0934 - val_accuracy: 0.9722\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 57s 59ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.0898 - val_accuracy: 0.9802\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 56s 58ms/step - loss: 0.0290 - accuracy: 0.9919 - val_loss: 0.0848 - val_accuracy: 0.9823\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 57s 58ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.1049 - val_accuracy: 0.9855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 4/12 [18:16<35:53, 269.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 64, 'kernel_size': 2, 'optimizer': 'Adam', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.7595WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0197s). Check your callbacks.\n",
            "972/972 [==============================] - 91s 94ms/step - loss: 0.7600 - accuracy: 0.7595 - val_loss: 0.2369 - val_accuracy: 0.9299\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 91s 93ms/step - loss: 0.1587 - accuracy: 0.9524 - val_loss: 0.1238 - val_accuracy: 0.9648\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 91s 94ms/step - loss: 0.0738 - accuracy: 0.9768 - val_loss: 0.0986 - val_accuracy: 0.9744\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 91s 94ms/step - loss: 0.0463 - accuracy: 0.9853 - val_loss: 0.0901 - val_accuracy: 0.9804\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 91s 94ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0949 - val_accuracy: 0.9790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 5/12 [25:53<37:59, 325.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 64, 'kernel_size': 2, 'optimizer': 'RMSprop', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7912WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0199s). Check your callbacks.\n",
            "972/972 [==============================] - 104s 107ms/step - loss: 0.6764 - accuracy: 0.7912 - val_loss: 0.1848 - val_accuracy: 0.9434\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 104s 107ms/step - loss: 0.1166 - accuracy: 0.9651 - val_loss: 0.1105 - val_accuracy: 0.9682\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 104s 107ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0847 - val_accuracy: 0.9804\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 104s 107ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 0.0859 - val_accuracy: 0.9823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 6/12 [32:51<35:20, 353.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'optimizer': 'Adam', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.7661WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0240s). Check your callbacks.\n",
            "972/972 [==============================] - 102s 105ms/step - loss: 0.7377 - accuracy: 0.7661 - val_loss: 0.2812 - val_accuracy: 0.9161\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 101s 104ms/step - loss: 0.1845 - accuracy: 0.9430 - val_loss: 0.1562 - val_accuracy: 0.9524\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 101s 104ms/step - loss: 0.0952 - accuracy: 0.9688 - val_loss: 0.1270 - val_accuracy: 0.9642\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 101s 104ms/step - loss: 0.0638 - accuracy: 0.9795 - val_loss: 0.1249 - val_accuracy: 0.9682\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 101s 104ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.1371 - val_accuracy: 0.9678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 7/12 [41:21<33:21, 400.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'optimizer': 'RMSprop', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.8224WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0221s). Check your callbacks.\n",
            "972/972 [==============================] - 116s 119ms/step - loss: 0.5683 - accuracy: 0.8224 - val_loss: 0.1460 - val_accuracy: 0.9563\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 116s 119ms/step - loss: 0.0905 - accuracy: 0.9723 - val_loss: 0.0811 - val_accuracy: 0.9780\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 116s 119ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 0.0870 - val_accuracy: 0.9817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 8/12 [47:10<25:39, 384.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 128, 'kernel_size': 2, 'optimizer': 'Adam', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.7954 - accuracy: 0.7476WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0635s). Check your callbacks.\n",
            "972/972 [==============================] - 203s 209ms/step - loss: 0.7954 - accuracy: 0.7476 - val_loss: 0.2658 - val_accuracy: 0.9169\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 202s 208ms/step - loss: 0.1746 - accuracy: 0.9475 - val_loss: 0.1481 - val_accuracy: 0.9587\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 203s 209ms/step - loss: 0.0832 - accuracy: 0.9747 - val_loss: 0.1312 - val_accuracy: 0.9641\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 203s 209ms/step - loss: 0.0540 - accuracy: 0.9835 - val_loss: 0.1282 - val_accuracy: 0.9673\n",
            "Epoch 5/30\n",
            "972/972 [==============================] - 203s 209ms/step - loss: 0.0329 - accuracy: 0.9901 - val_loss: 0.1068 - val_accuracy: 0.9761\n",
            "Epoch 6/30\n",
            "972/972 [==============================] - 203s 209ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.1122 - val_accuracy: 0.9786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 9/12 [1:07:32<31:48, 636.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 128, 'kernel_size': 2, 'optimizer': 'RMSprop', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.8159WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0636s). Check your callbacks.\n",
            "972/972 [==============================] - 231s 237ms/step - loss: 0.5951 - accuracy: 0.8159 - val_loss: 0.1729 - val_accuracy: 0.9549\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 230s 236ms/step - loss: 0.0969 - accuracy: 0.9705 - val_loss: 0.0878 - val_accuracy: 0.9768\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 229s 236ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 0.0718 - val_accuracy: 0.9826\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 228s 235ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0897 - val_accuracy: 0.9848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 10/12 [1:22:53<24:03, 721.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 128, 'kernel_size': 3, 'optimizer': 'Adam', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.7408WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0561s). Check your callbacks.\n",
            "972/972 [==============================] - 198s 204ms/step - loss: 0.7998 - accuracy: 0.7408 - val_loss: 0.3966 - val_accuracy: 0.8808\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 196s 202ms/step - loss: 0.2769 - accuracy: 0.9139 - val_loss: 0.2200 - val_accuracy: 0.9314\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 196s 202ms/step - loss: 0.1388 - accuracy: 0.9567 - val_loss: 0.1340 - val_accuracy: 0.9610\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 196s 202ms/step - loss: 0.0915 - accuracy: 0.9703 - val_loss: 0.1340 - val_accuracy: 0.9637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 11/12 [1:36:03<12:22, 742.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'epochs': 30, 'filters': 128, 'kernel_size': 3, 'optimizer': 'RMSprop', 'padding': 'same', 'strides': 1}\n",
            "Epoch 1/30\n",
            "972/972 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.7925WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0559s). Check your callbacks.\n",
            "972/972 [==============================] - 225s 231ms/step - loss: 0.6788 - accuracy: 0.7925 - val_loss: 0.1425 - val_accuracy: 0.9596\n",
            "Epoch 2/30\n",
            "972/972 [==============================] - 223s 230ms/step - loss: 0.0884 - accuracy: 0.9734 - val_loss: 0.0745 - val_accuracy: 0.9784\n",
            "Epoch 3/30\n",
            "972/972 [==============================] - 223s 230ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.0637 - val_accuracy: 0.9837\n",
            "Epoch 4/30\n",
            "972/972 [==============================] - 223s 229ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0818 - val_accuracy: 0.9857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [1:51:02<00:00, 555.19s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8X8vZVoikV7"
      },
      "source": [
        "## Analyzing the talos run and creating the heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63c7qvw-E9A"
      },
      "source": [
        "from talos import Deploy, Analyze"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix1dHRgD7qcM"
      },
      "source": [
        "a = Analyze('/content/lang_class/110620170629.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bUA3joT7qpR",
        "outputId": "c2e00168-fed1-467a-f956-a433606415ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        }
      },
      "source": [
        "a.plot_corr(metric='val_accuracy', exclude=[])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Verdana'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RG3lBUDjOWP"
      },
      "source": [
        "## extracting the parameters for the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaFj3PRR7qr9",
        "outputId": "aadfb928-18d9-4063-b234-a6f6c43a2979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a.best_params(metric='val_accuracy', exclude=[], n=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 0.9944958686828612, 100, 30, 1, 128, 'same',\n",
              "        0.019772926345467567, 0.08177616447210312, 'RMSprop', 3, 0]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}